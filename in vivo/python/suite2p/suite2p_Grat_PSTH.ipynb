{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grating Stimulus analysis (Panda extraction / consolidation)\n",
    "Tobias Rose 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "%matplotlib widget\n",
    "#%matplotlib qt\n",
    "import seaborn as sns\n",
    "sns.set()  # set plot styles\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path, PureWindowsPath, PurePosixPath\n",
    "from scipy.signal import convolve\n",
    "from scipy.stats import zscore, rankdata\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "# from scipy.stats import zscore ### Cave! scipy zscore does not handle NaN!\n",
    "from ScanImageTiffReader import ScanImageTiffReader\n",
    "from helpers import parse_SI_header as pSI #own\n",
    "from tqdm import notebook\n",
    "\n",
    "import rastermap as rm\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aux loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_auxdata(filename):    \n",
    "    \"\"\" Loads .lvd aux data file - Pieter Goltstein 2020\"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        # Reset file index\n",
    "        f.seek(0)\n",
    "        # Get meta data\n",
    "        samplingfreq = np.fromfile(f, dtype='>f8', count=1)\n",
    "        print(\"Aux sampling frequency = {}Hz\".format(samplingfreq))\n",
    "        n_channels = int(np.fromfile(f, dtype='>f8', count=1))\n",
    "        print(\"# channels = {}\".format(n_channels))\n",
    "        timestamp = np.fromfile(f, dtype='>f8', count=1)\n",
    "        print(\"timestamp = {}\".format(timestamp))\n",
    "        max_input = np.fromfile(f, dtype='>f8', count=1)\n",
    "        print(\"max input = {} V\".format(max_input))\n",
    "        # Read aux data\n",
    "        auxdata = np.fromfile(f, dtype='>f8')\n",
    "        n_datapoints = int(auxdata.shape[0]/n_channels)\n",
    "        print(\"number of aux datapoints = {}\".format(n_datapoints))\n",
    "        auxdata = np.reshape(auxdata,(n_datapoints,n_channels))\n",
    "        return auxdata, samplingfreq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frame extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_times(auxdata, Frames_chan):\n",
    "    \"\"\" extracts frame onset times \"\"\"\n",
    "    len_aux = len(auxdata)\n",
    "    pos = np.argwhere(auxdata[0:,Frames_chan] > 0.75 * np.max(auxdata[range(0,len_aux),Frames_chan ])) # work on diff of indices rather than on raw diff to prevent multi-smaple detection in up/ downstrokes\n",
    "    diffpos = np.argwhere(np.diff(pos[0:,0]) > 1)\n",
    "    frame_times = pos[diffpos,0]\n",
    "    \n",
    "    if  len(frame_times)==0:\n",
    "        print('get_frame_times WARNING: no frames found')\n",
    "        frame_times = 1;\n",
    "        return frame_times\n",
    "    \n",
    "    # find onset of first frame\n",
    "    pos_first = np.argwhere(auxdata[0:,Frames_chan] < 0.5 * np.max(auxdata[range(0,len_aux), Frames_chan]))\n",
    "    diffpos_first = np.argwhere(np.diff(pos_first[0:,0]) > 1)\n",
    "    frame_times = np.append(diffpos_first[0], frame_times)\n",
    "    \n",
    "    return frame_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General stimulus bound extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stimIDs(auxdata, stimops):\n",
    "    \"\"\" extracts Stim onset times \"\"\"\n",
    "    \n",
    "    Frames_chan = stimops['Frames_chan']\n",
    "    Stims_chan = stimops['Stims_chan']\n",
    "    eye1_chan = stimops['eye1_chan']\n",
    "    eye2_chan = stimops['eye2_chan']\n",
    "    level = stimops['level']\n",
    "    minsample_delta = stimops['minsample_delta']\n",
    "    extract_stim = stimops['extract_stimID']\n",
    "\n",
    "    frame_times         = get_frame_times(auxdata,Frames_chan)\n",
    "    frame_times_level   = frame_times[range(0,len(frame_times),level)]\n",
    "\n",
    "\n",
    "    StimOn = auxdata[frame_times_level, Stims_chan]>0.8\n",
    "\n",
    "    # generate cleaned eye binaries\n",
    "    Eye1On = auxdata[frame_times_level,eye1_chan]*-1+ np.max(auxdata[frame_times_level,eye1_chan])>0.8\n",
    "    Eye2On = auxdata[frame_times_level,eye2_chan]>0.8\n",
    "    Eye2On[-1] = 1 \n",
    "    bino = Eye1On & Eye2On\n",
    "\n",
    "    Eye1On_only = Eye1On != bino\n",
    "    Eye2On_only = Eye2On != bino\n",
    "    Eye1On_only[-1] = False\n",
    "    Eye2On_only[-1] = False\n",
    "    bino[0] = False\n",
    "    bino[-1] = False\n",
    "\n",
    "    # generate cleaned bino binary\n",
    "    bino_onsets_temp  = np.argwhere(np.diff(np.multiply(bino, 1)) > 0)\n",
    "    bino_offsets_temp = np.argwhere(np.diff(np.multiply(bino, 1)) < 0)\n",
    "\n",
    "    bino_onsets  = bino_onsets_temp[np.argwhere(bino_offsets_temp[0:,0] - bino_onsets_temp[0:,0] > minsample_delta)]\n",
    "    bino_offsets = bino_offsets_temp[np.argwhere(bino_offsets_temp[0:,0] - bino_onsets_temp[0:,0] > minsample_delta)]                              \n",
    "\n",
    "    bino_clean = np.full(( len(frame_times_level)), False) \n",
    "\n",
    "    for i in range(len(bino_onsets)):\n",
    "        bino_clean[range(bino_onsets[i,0,0], bino_offsets[i,0,0])] = True\n",
    "\n",
    "    # extract stim on and offsets\n",
    "    stim_onsets_temp  = np.argwhere(np.diff(np.multiply(StimOn, 1)) > 0)\n",
    "    stim_offsets_temp = np.argwhere(np.diff(np.multiply(StimOn, 1)) < 0)\n",
    "\n",
    "    stim_on  = np.argwhere(np.diff(stim_onsets_temp[0:,0]) > minsample_delta) + 1\n",
    "    stim_off = np.argwhere(np.diff(stim_offsets_temp[0:,0]) > minsample_delta)\n",
    "\n",
    "    stim_on  = np.append(0, stim_on)\n",
    "    stim_off = np.append(stim_off, len(stim_offsets_temp) - 1)\n",
    "\n",
    "    stim_onsets  = stim_onsets_temp[stim_on]\n",
    "    stim_offsets = stim_offsets_temp[stim_off]\n",
    "\n",
    "    ids = { \n",
    "            'Contra':   [np.intersect1d(stim_onsets, np.argwhere(Eye1On_only)), np.intersect1d(stim_offsets, np.argwhere(Eye1On_only))],\n",
    "            'Ipsi': [np.intersect1d(stim_onsets, np.argwhere(Eye2On_only)), np.intersect1d(stim_offsets, np.argwhere(Eye2On_only))],\n",
    "            'Bino':   [np.intersect1d(stim_onsets, np.argwhere(bino_clean)), np.intersect1d(stim_offsets, np.argwhere(bino_clean))],\n",
    "            'FrameTimes_level': frame_times_level,\n",
    "            'FrameTimes':       frame_times,\n",
    "            }\n",
    "\n",
    "    ContraStim = []\n",
    "    IpsiStim = []\n",
    "    BinoStim = []\n",
    "\n",
    "    if extract_stim:\n",
    "        for trial, val in enumerate(ids['Contra'][0]):\n",
    "            ContraStim.append(np.median(auxdata[frame_times_level, Stims_chan][ids['Contra'][0][trial]:ids['Contra'][1][trial]]))\n",
    "            IpsiStim.append(np.median(auxdata[frame_times_level, Stims_chan][ids['Ipsi'][0][trial]:ids['Ipsi'][1][trial]]))\n",
    "            BinoStim.append(np.median(auxdata[frame_times_level, Stims_chan][ids['Bino'][0][trial]:ids['Bino'][1][trial]]))\n",
    "\n",
    "        C_Stim = np.round(np.array(ContraStim)*10)/10\n",
    "        I_Stim = np.round(np.array(IpsiStim)*10)/10\n",
    "        B_Stim = np.round(np.array(BinoStim)*10)/10\n",
    "\n",
    "        NumStim = len(np.unique(C_Stim))\n",
    "        TotStim = len(C_Stim)\n",
    "        TrialNum = int(TotStim / NumStim)\n",
    "        StimIDs_Contra = rankdata(C_Stim, 'dense')\n",
    "        StimIDs_Ipsi = rankdata(I_Stim, 'dense')\n",
    "        StimIDs_Bino = rankdata(B_Stim, 'dense')\n",
    "\n",
    "        ids.update({ \n",
    "                'NumStim':       NumStim,\n",
    "                'TotStim':       TotStim,\n",
    "                'TotTrialNum':      TrialNum,\n",
    "                'StimID_Contra':      StimIDs_Contra,\n",
    "                'StimID_Ipsi':        StimIDs_Ipsi,\n",
    "                'StimID_Bino':        StimIDs_Bino,\n",
    "                'StimDirs_Contra':    StimIDs_Contra / NumStim * 360,\n",
    "                'StimDirs_Ipsi':      StimIDs_Ipsi / NumStim * 360,\n",
    "                'StimDirs_Bino':      StimIDs_Bino / NumStim * 360\n",
    "                    })\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### on-the-fly panda function definition of zscore that handles NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score(df): return (df-df.mean())/df.std(ddof=0)\n",
    "# def m_mean(df): return df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-specific folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.platform == \"darwin\":\n",
    "    ### Mac - command + k in finder; smb://10G.ISI01.neuro.mpg.de/archive_bonhoeffer_group$/David Laubender\n",
    "    main_root = '/Volumes/David Laubender/Data/imaging data/DL_191024_6/ImagingData/' #location of original data\n",
    "    adata     = '/Volumes/David Laubender/adata' #location of saved analyzed data\n",
    "    ftemp     = '/Users/trose/Data/temp' #fast disk (local ssd for s2p binary files) \n",
    "    ftiff     = '/Users/trose/Data/s2p_tiff' #fast disk folder for concatenated tiffs (if needed)\n",
    "    xlpath    = 'LGNexperiments.xlsx' \n",
    "elif sys.platform == \"win32\":\n",
    "#     main_root = 'I:/David Laubender/Data/imaging data/DL_191106_2/ImagingData' #location of original data\n",
    "    main_root = 'I:/David Laubender/Data/imaging data/DL_191024_6/ImagingData' #location of original data    \n",
    "    adata     = 'I:/David Laubender/adata' #location of saved analyzed data\n",
    "    ftemp     = 'C:/temp/trose/suite2ptemp' #fast disk (local ssd for s2p binary files  \n",
    "    ftiff     = 'C:/temp/trose/s2p_tiff' #fast disk folder for concatenated tiffs (if needed)\n",
    "    xlpath    = 'LGNexperiments.xlsx' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read excel file into panda dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(xlpath, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split comments column into Layer and elevation columns and drop mixed column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Layer', 'Elevation']] = df.comments.str.rsplit(',', expand = True)\n",
    "df = df.drop(['comments'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  boolean combination of search strings (here: Grating stim only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[(df['experiment type'] == 'euler' ) & (df['Layer'] == 'L1')]\n",
    "# load_df = df[(df['experiment type'] == 'euler' ) & (df['Layer'] == 'L1') & (df['Elevation']==' positive degrees')]\n",
    "#load_df = df[(df['experiment type'] == 'euler' ) & (df['Layer'] == 'L4')]\n",
    "\n",
    "load_df = df[(df['experiment type'] == 'grating' )]\n",
    "exp=list(map(str,load_df.experiment))\n",
    "main_root=list(map(str,load_df.folder))\n",
    "# list(main_root)\n",
    "# list(exp)\n",
    "#exp = [exp[0]]\n",
    "#main_root = [main_root[0]]\n",
    "#main_root_old = main_root[0]\n",
    "\n",
    "if sys.platform == \"darwin\":\n",
    "    main_root_mac = []\n",
    "    for idx, val in enumerate(exp):\n",
    "        main_root_mac.append(str(Path('/Volumes/', *PureWindowsPath(main_root[idx]).parts[1:])))\n",
    "    main_root = main_root_mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I:\\\\David Laubender\\\\Data\\\\imaging data\\\\DL_191024_6\\\\ImagingData\\\\2019-12-01',\n",
       " 'I:\\\\David Laubender\\\\Data\\\\imaging data\\\\DL_191024_6\\\\ImagingData\\\\2019-12-01',\n",
       " 'I:\\\\David Laubender\\\\Data\\\\imaging data\\\\DL_191024_6\\\\ImagingData\\\\2019-12-04',\n",
       " 'I:\\\\David Laubender\\\\Data\\\\imaging data\\\\DL_191024_6\\\\ImagingData\\\\2019-12-04',\n",
       " 'I:\\\\David Laubender\\\\Data\\\\imaging data\\\\DL_191024_6\\\\ImagingData\\\\2019-12-08',\n",
       " 'I:\\\\David Laubender\\\\Data\\\\imaging data\\\\DL_191024_6\\\\ImagingData\\\\2019-12-08',\n",
       " 'I:\\\\David Laubender\\\\Data\\\\imaging data\\\\DL_191024_6\\\\ImagingData\\\\2019-12-18',\n",
       " 'I:\\\\David Laubender\\\\Data\\\\imaging data\\\\DL_191024_6\\\\ImagingData\\\\2019-12-18',\n",
       " 'I:\\\\David Laubender\\\\Data\\\\imaging data\\\\DL_191024_4\\\\ImagingData\\\\2019-11-26',\n",
       " 'I:\\\\David Laubender\\\\Data\\\\imaging data\\\\DL_191024_4\\\\ImagingData\\\\2019-11-26',\n",
       " 'I:\\\\David Laubender\\\\Data\\\\imaging data\\\\DL_191024_4\\\\ImagingData\\\\2019-11-29',\n",
       " 'I:\\\\David Laubender\\\\Data\\\\imaging data\\\\DL_191024_4\\\\ImagingData\\\\2019-11-29',\n",
       " 'I:\\\\David Laubender\\\\Data\\\\imaging data\\\\DL_191106_1\\\\ImagingData\\\\2019-12-16',\n",
       " 'I:\\\\David Laubender\\\\Data\\\\imaging data\\\\DL_191106_1\\\\ImagingData\\\\2019-12-16',\n",
       " 'I:\\\\David Laubender\\\\Data\\\\imaging data\\\\DL_191106_2\\\\ImagingData\\\\2019-12-14',\n",
       " 'I:\\\\David Laubender\\\\Data\\\\imaging data\\\\DL_191106_2\\\\ImagingData\\\\2019-12-14',\n",
       " 'I:\\\\David Laubender\\\\Data\\\\imaging data\\\\DL_191106_2\\\\ImagingData\\\\2019-12-17',\n",
       " 'I:\\\\David Laubender\\\\Data\\\\imaging data\\\\DL_191106_2\\\\ImagingData\\\\2019-12-17',\n",
       " 'I:\\\\David Laubender\\\\Data\\\\imaging data\\\\DL_191106_2\\\\ImagingData\\\\2020-01-22',\n",
       " 'I:\\\\David Laubender\\\\Data\\\\imaging data\\\\DL_191106_2\\\\ImagingData\\\\2020-01-22',\n",
       " 'I:\\\\David Laubender\\\\Data\\\\imaging data\\\\DL_191106_2\\\\ImagingData\\\\2019-12-21',\n",
       " 'I:\\\\David Laubender\\\\Data\\\\imaging data\\\\DL_191106_2\\\\ImagingData\\\\2019-12-21',\n",
       " 'I:\\\\David Laubender\\\\Data\\\\imaging data\\\\DL_191106_4\\\\ImagingData\\\\2019-12-07',\n",
       " 'I:\\\\David Laubender\\\\Data\\\\imaging data\\\\DL_191106_4\\\\ImagingData\\\\2019-12-07',\n",
       " 'I:\\\\David Laubender\\\\Data\\\\imaging data\\\\DL_191106_4\\\\ImagingData\\\\2019-12-10',\n",
       " 'I:\\\\David Laubender\\\\Data\\\\imaging data\\\\DL_191106_4\\\\ImagingData\\\\2019-12-10',\n",
       " 'I:\\\\David Laubender\\\\Data\\\\imaging data\\\\DL_191106_4\\\\ImagingData\\\\2019-12-19',\n",
       " 'I:\\\\David Laubender\\\\Data\\\\imaging data\\\\DL_191106_4\\\\ImagingData\\\\2019-12-19',\n",
       " 'I:\\\\David Laubender\\\\Data\\\\imaging data\\\\DL_191024_6\\\\ImagingData\\\\2020-02-06',\n",
       " 'I:\\\\David Laubender\\\\Data\\\\imaging data\\\\DL_191106_4\\\\ImagingData\\\\2020-02-07']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp = ['62283', '62284', '62285', '62286', '62287', '62288', '62289', '62290']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp = ['62336']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcfd624126ca4de78dc66f9742c2d20e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "adata_s2ppath = []\n",
    "adata_tiffpath = []\n",
    "aux_files = []\n",
    "single_tiff_file =[]\n",
    "experimentator = []\n",
    "mouse = []\n",
    "date = []\n",
    "experiment = []\n",
    "\n",
    "for idx, val in notebook.tqdm(enumerate(exp)):\n",
    "    s2pdir = list(Path(main_root[idx]).rglob('suite2p_exp'+val+'/')) #recursive\n",
    "    tifffile = list(Path(os.path.join(*Path(s2pdir[0]).parts[0:-3], 'ImagingData', Path(s2pdir[0]).parts[-2])).glob('exp'+val+'*.tif')) #recursive search over main_root    \n",
    "    experimentator.append(Path(s2pdir[0]).parts[-7])\n",
    "    mouse.append(Path(s2pdir[0]).parts[-4])\n",
    "    date.append(Path(s2pdir[0]).parts[-2])\n",
    "    experiment.append(val)\n",
    "    Layer = load_df[load_df['experiment'] == int(val)]['Layer'].str.strip().to_numpy()\n",
    "    Elevation = load_df[load_df['experiment'] == int(val)]['Elevation'].str.strip().to_numpy()\n",
    "    try:\n",
    "        adata_s2ppath.append(os.path.join(s2pdir[0], 'suite2p', 'combined'))\n",
    "        adata_tiffpath.append(os.path.dirname(s2pdir[0]))\n",
    "        aux_files.append(*Path(os.path.join(*Path(s2pdir[0]).parts[0:-3], 'data', Path(s2pdir[0]).parts[-2])).glob('exp'+val+'*.lvd'))\n",
    "        single_tiff_file.append(str(tifffile[0]))\n",
    "    except:\n",
    "        print(val + ' not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parse first tiff of exp for imaging specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ScanImageTiffReader(single_tiff_file[0]) as reader:\n",
    "    header = (reader.description(0))\n",
    "    mov_dim = (reader.shape())\n",
    "    \n",
    "level = pSI.parse_SI_header_level(header)\n",
    "zoom = pSI.parse_SI_header_zoom(header)\n",
    "framerate = pSI.parse_SI_header_FrameRate(header)\n",
    "channels = pSI.parse_SI_header_Channels(header)\n",
    "volumes = pSI.parse_SI_header_Volumes(header)\n",
    "frames = pSI.parse_SI_header_Frames(header)\n",
    "frames_per_file = pSI.parse_SI_header_FramesPerFile(header)\n",
    "#start_time = pSI.parse_SI_header_StartTime(header)\n",
    "\n",
    "# account for multilevel acq where frames is 1\n",
    "if frames < volumes:\n",
    "    frames = volumes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract grating stim timebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimops = {\n",
    "    'Frames_chan': 3,\n",
    "    'Stims_chan': 7,\n",
    "    'eye1_chan': 16,\n",
    "    'eye2_chan': 17,\n",
    "    'level': level, # extract from SI file in the future\n",
    "    'minsample_delta': 10, \n",
    "    'extract_stimID': True\n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('Grat_ids.pkl', 'rb') as handle:\n",
    "#    ids = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#auxdata = ids[0]['auxdata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#level = dataframe['SI_level'].to_numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46677d8ce38e4e95b747467a3db6070b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I:\\David Laubender\\Data\\imaging data\\DL_191024_6\\data\\2019-12-01\\exp62283_DL_0013.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912011e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 12491520\n",
      "extracting stimIDs\n",
      "I:\\David Laubender\\Data\\imaging data\\DL_191024_6\\data\\2019-12-01\\exp62286_DL_0022.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912012e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 12361984\n",
      "extracting stimIDs\n",
      "I:\\David Laubender\\Data\\imaging data\\DL_191024_6\\data\\2019-12-04\\exp62289_DL_0023.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912041e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 12359936\n",
      "extracting stimIDs\n",
      "I:\\David Laubender\\Data\\imaging data\\DL_191024_6\\data\\2019-12-04\\exp62292_DL_0033.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912041e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 12361984\n",
      "extracting stimIDs\n",
      "I:\\David Laubender\\Data\\imaging data\\DL_191024_6\\data\\2019-12-08\\exp62305_DL_0014.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912081e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 12228352\n",
      "extracting stimIDs\n",
      "I:\\David Laubender\\Data\\imaging data\\DL_191024_6\\data\\2019-12-08\\exp62307_DL_0031.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912081e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 12230656\n",
      "extracting stimIDs\n",
      "I:\\David Laubender\\Data\\imaging data\\DL_191024_6\\data\\2019-12-18\\exp62360_DL_0013.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912181e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 12228608\n",
      "extracting stimIDs\n",
      "I:\\David Laubender\\Data\\imaging data\\DL_191024_6\\data\\2019-12-18\\exp62363_DL_0022.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912181e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 12230912\n",
      "extracting stimIDs\n",
      "I:\\David Laubender\\Data\\imaging data\\DL_191024_4\\data\\2019-11-26\\exp62258_DL_0014.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01911262e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 12493056\n",
      "extracting stimIDs\n",
      "I:\\David Laubender\\Data\\imaging data\\DL_191024_4\\data\\2019-11-26\\exp62261_DL_0022.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01911262e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 12494080\n",
      "extracting stimIDs\n",
      "I:\\David Laubender\\Data\\imaging data\\DL_191024_4\\data\\2019-11-29\\exp62266_DL_0016.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01911291e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 12492544\n",
      "extracting stimIDs\n",
      "I:\\David Laubender\\Data\\imaging data\\DL_191024_4\\data\\2019-11-29\\exp62269_DL_0029.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01911292e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 12493824\n",
      "extracting stimIDs\n",
      "I:\\David Laubender\\Data\\imaging data\\DL_191106_1\\data\\2019-12-16\\exp62348_DL_0032.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912161e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 12230400\n",
      "extracting stimIDs\n",
      "I:\\David Laubender\\Data\\imaging data\\DL_191106_1\\data\\2019-12-16\\exp62351_DL_0041.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912161e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 12231424\n",
      "extracting stimIDs\n",
      "I:\\David Laubender\\Data\\imaging data\\DL_191106_2\\data\\2019-12-14\\exp62335_DL_0023.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912141e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 12228608\n",
      "extracting stimIDs\n",
      "I:\\David Laubender\\Data\\imaging data\\DL_191106_2\\data\\2019-12-14\\exp62338_DL_0037.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912141e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 12230912\n",
      "extracting stimIDs\n",
      "I:\\David Laubender\\Data\\imaging data\\DL_191106_2\\data\\2019-12-17\\exp62354_DL_0012.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912171e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 12228608\n",
      "extracting stimIDs\n",
      "I:\\David Laubender\\Data\\imaging data\\DL_191106_2\\data\\2019-12-17\\exp62356_DL_0022.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912171e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 12230656\n",
      "extracting stimIDs\n",
      "I:\\David Laubender\\Data\\imaging data\\DL_191106_2\\data\\2020-01-22\\exp62399_DL_0016.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.02001221e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 12229376\n",
      "extracting stimIDs\n",
      "I:\\David Laubender\\Data\\imaging data\\DL_191106_2\\data\\2020-01-22\\exp62402_DL_0023.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.02001221e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 12230400\n",
      "extracting stimIDs\n",
      "I:\\David Laubender\\Data\\imaging data\\DL_191106_2\\data\\2019-12-21\\exp62378_DL_0014.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912211e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 12228608\n",
      "extracting stimIDs\n",
      "I:\\David Laubender\\Data\\imaging data\\DL_191106_2\\data\\2019-12-21\\exp62381_DL_0028.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912211e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 12231680\n",
      "extracting stimIDs\n",
      "I:\\David Laubender\\Data\\imaging data\\DL_191106_4\\data\\2019-12-07\\exp62299_DL_0020.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912071e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 12229376\n",
      "extracting stimIDs\n",
      "I:\\David Laubender\\Data\\imaging data\\DL_191106_4\\data\\2019-12-07\\exp62302_DL_0031.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912071e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 12230656\n",
      "extracting stimIDs\n",
      "I:\\David Laubender\\Data\\imaging data\\DL_191106_4\\data\\2019-12-10\\exp62317_DL_0017.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912101e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 12228864\n",
      "extracting stimIDs\n",
      "I:\\David Laubender\\Data\\imaging data\\DL_191106_4\\data\\2019-12-10\\exp62320_DL_0029.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912101e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 12230656\n",
      "extracting stimIDs\n",
      "I:\\David Laubender\\Data\\imaging data\\DL_191106_4\\data\\2019-12-19\\exp62366_DL_0017.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912191e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 12229120\n",
      "extracting stimIDs\n",
      "I:\\David Laubender\\Data\\imaging data\\DL_191106_4\\data\\2019-12-19\\exp62369_DL_0028.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912191e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 12231424\n",
      "extracting stimIDs\n",
      "I:\\David Laubender\\Data\\imaging data\\DL_191024_6\\data\\2020-02-06\\exp62416_DL_0023.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.02002062e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 12163328\n",
      "extracting stimIDs\n",
      "I:\\David Laubender\\Data\\imaging data\\DL_191106_4\\data\\2020-02-07\\exp62419_DL_0013.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.02002071e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 12161280\n",
      "extracting stimIDs\n",
      "\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "ids = {}\n",
    "for idx, val in notebook.tqdm(enumerate(exp)):\n",
    "    aux_filename = str(aux_files[idx])\n",
    "    print(aux_filename)\n",
    "    [auxdata, aux_samplingfreq] = load_auxdata(aux_filename)\n",
    "    print('extracting stimIDs')\n",
    "    ids[idx] = get_stimIDs(auxdata, stimops)\n",
    "    ids[idx]['aux_filename'] = aux_filename\n",
    "    if idx == 0:\n",
    "        ids[idx]['auxdata'] = auxdata\n",
    "    else:\n",
    "        ids[idx]['auxdata'] = []\n",
    "    ids[idx]['aux_samplingfreq'] = aux_samplingfreq\n",
    "    ids[idx]['framerate_auxderived'] = aux_samplingfreq / np.median(np.diff(ids[idx]['FrameTimes']))\n",
    "print('DONE!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot aux_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### raw aux plus stimbounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only works if all auxdaa is put into ids dictionary (not with the first slice only)\n",
    "#fig = plt.figure(figsize=(8,6))\n",
    "#jump = 0\n",
    "#for idx, val in enumerate(exp):\n",
    "#    plt.subplot(len(exp)*3 +1 ,1,idx+jump+1)\n",
    "#    plotdata = ids[idx]['auxdata'][ids[idx]['FrameTimes_level'],stimops['Stims_chan']]\n",
    "#    plt.plot(plotdata), plt.ylabel('Stims_chan') \n",
    "#    plt.vlines([ids[idx]['Ipsi'][0]],-1,6, 'r')\n",
    "#    plt.vlines([ids[idx]['Ipsi'][1]],-1,6, 'r')\n",
    "#    plt.vlines([ids[idx]['Contra'][0]],-1,6, 'b')\n",
    "#    plt.vlines([ids[idx]['Contra'][1]],-1,6, 'b')\n",
    "#    plt.vlines([ids[idx]['Bino'][0]],-1,6, 'k')\n",
    "#    plt.vlines([ids[idx]['Bino'][1]],-1,6, 'k')\n",
    "#    plt.subplot(len(exp)*3+1 ,1,idx+jump+2)\n",
    "#    plt.plot(ids[idx]['auxdata'][ids[idx]['FrameTimes_level'],stimops['eye1_chan']]), plt.ylabel('eye1_chan') \n",
    "#    plt.subplot(len(exp)*3+1 ,1,idx+jump+3)\n",
    "#    plt.plot(ids[idx]['auxdata'][ids[idx]['FrameTimes_level'],stimops['eye2_chan']]), plt.ylabel('eye2_chan') \n",
    "#    plt.show()\n",
    "#    jump = jump+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig = plt.figure(figsize=(8,6))\n",
    "#plt.subplot(1,1,1)\n",
    "#plt.plot(ids[idx]['auxdata'][:,stimops['Stims_chan']]), plt.ylabel('Stims_chan') \n",
    "#plt.vlines(ids[idx]['FrameTimes_level'][ids[idx]['Ipsi'][0]],-1,6, 'r')\n",
    "#plt.vlines(ids[idx]['FrameTimes_level'][ids[idx]['Ipsi'][1]],-1,6, 'k')\n",
    "## plt.vlines(ids['Ipsi'][1],-1,6, 'r')\n",
    "## plt.vlines(ids['Contra'][0],-1,6, 'b')\n",
    "## plt.vlines(ids['Contra'][1],-1,6, 'b')\n",
    "## plt.vlines(ids['Bino'][0],-1,6, 'k')\n",
    "## plt.vlines(ids['Bino'][1],-1,6, 'k')\n",
    "## plt.subplot(3,1,2)\n",
    "## plt.plot(auxdata[ids['FrameTimes_level'],stimops['eye1_chan']]), plt.ylabel('eye1_chan') \n",
    "## plt.subplot(3,1,3)\n",
    "## plt.plot(auxdata[ids['FrameTimes_level'],stimops['eye2_chan']]), plt.ylabel('eye2_chan') \n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ids and auxdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('Grat_ids.pkl', 'rb') as handle:\n",
    "#    ids = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxdata = ids[0]['auxdata']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make PSTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca6fe9924bcc41b696d7111f787ff73a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "F = {}\n",
    "Fneu = {}\n",
    "spks = {}\n",
    "stat = {}\n",
    "ops = {}\n",
    "iscell = {}\n",
    "\n",
    "for idx, val in notebook.tqdm(enumerate(exp)):\n",
    "    F[idx] = np.load(os.path.join(adata_s2ppath[idx],'F.npy'))\n",
    "    Fneu[idx] = np.load(os.path.join(adata_s2ppath[idx],'Fneu.npy'))\n",
    "    spks[idx] = np.load(os.path.join(adata_s2ppath[idx],'spks.npy'))\n",
    "#     stat[idx] = np.load(os.path.join(adata_s2ppath[0],'stat.npy'), allow_pickle=True)\n",
    "#     ops[idx] = np.load(os.path.join(adata_s2ppath[0],'ops.npy'), allow_pickle=True).item()\n",
    "    iscell[idx] = np.load(os.path.join(adata_s2ppath[idx],'iscell.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop non-cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92847ca72dac4f399cbcdccdb6d900e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp62283 dropped 173 non-boutons (out of 1065)\n",
      "exp62286 dropped 648 non-boutons (out of 963)\n",
      "exp62289 dropped 573 non-boutons (out of 1058)\n",
      "exp62292 dropped 469 non-boutons (out of 725)\n",
      "exp62305 dropped 453 non-boutons (out of 738)\n",
      "exp62307 dropped 479 non-boutons (out of 1016)\n",
      "exp62360 dropped 447 non-boutons (out of 720)\n",
      "exp62363 dropped 451 non-boutons (out of 679)\n",
      "exp62258 dropped 266 non-boutons (out of 1207)\n",
      "exp62261 dropped 741 non-boutons (out of 1235)\n",
      "exp62266 dropped 478 non-boutons (out of 1180)\n",
      "exp62269 dropped 263 non-boutons (out of 503)\n",
      "exp62348 dropped 471 non-boutons (out of 944)\n",
      "exp62351 dropped 275 non-boutons (out of 398)\n",
      "exp62335 dropped 489 non-boutons (out of 1012)\n",
      "exp62338 dropped 281 non-boutons (out of 473)\n",
      "exp62354 dropped 334 non-boutons (out of 578)\n",
      "exp62356 dropped 358 non-boutons (out of 910)\n",
      "exp62399 dropped 426 non-boutons (out of 793)\n",
      "exp62402 dropped 330 non-boutons (out of 532)\n",
      "exp62378 dropped 454 non-boutons (out of 684)\n",
      "exp62381 dropped 273 non-boutons (out of 430)\n",
      "exp62299 dropped 683 non-boutons (out of 1039)\n",
      "exp62302 dropped 336 non-boutons (out of 571)\n",
      "exp62317 dropped 651 non-boutons (out of 1064)\n",
      "exp62320 dropped 330 non-boutons (out of 484)\n",
      "exp62366 dropped 348 non-boutons (out of 482)\n",
      "exp62369 dropped 419 non-boutons (out of 611)\n",
      "exp62416 dropped 663 non-boutons (out of 1210)\n",
      "exp62419 dropped 847 non-boutons (out of 1261)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, val in notebook.tqdm(enumerate(exp)):\n",
    "    old_len = len(F[idx])\n",
    "    F[idx] = F[idx][iscell[idx][:,0]==1,:]\n",
    "    Fneu[idx] =Fneu[idx][iscell[idx][:,0]==1,:]\n",
    "    spks[idx] = spks[idx][iscell[idx][:,0]==1,:]\n",
    "    print('exp' + val + ' dropped ' + str(old_len - len(F[idx])) + ' non-boutons (out of ' + str(old_len) + ')' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PANDAS: generate seaborn-compatible, stimulus-chopped long-form pandas and plot (maybe not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['Ipsi', 'Contra', 'Bino'] #ids.keys()\n",
    "stimDir_categories = ['StimDirs_Ipsi', 'StimDirs_Contra', 'StimDirs_Bino'] #ids.keys()\n",
    "stimID_categories = ['StimID_Ipsi', 'StimID_Contra', 'StimID_Bino'] #ids.keys()\n",
    "\n",
    "\n",
    "ncells = {}\n",
    "prestim = {}\n",
    "poststim = {}\n",
    "prestim_frames = {}\n",
    "poststim_frames = {}\n",
    "\n",
    "for idx, val in enumerate(exp):\n",
    "    ncells[idx] = F[idx].shape[0]\n",
    "    prestim[idx]  = 1 / (ids[idx]['framerate_auxderived']  / level) * 15 #seconds before stimulus\n",
    "    poststim[idx] = 1 / (ids[idx]['framerate_auxderived']  / level) * 15 #seconds after stimulus\n",
    "\n",
    "    prestim_frames[idx] = np.round(prestim[idx]  * (ids[idx]['framerate_auxderived']  / level))\n",
    "    poststim_frames[idx] = np.round(prestim[idx]  * (ids[idx]['framerate_auxderived']  / level))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f47fcdb23048e5b0df5a6bfcb27690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=892.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c0ce0455d8341d882b435523a17ed47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=315.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0de21387604c4fd6a37a1af59946c9b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=485.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0cb4d21bba7428c9f3c2959ebe2e87f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=256.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2923f7e02df84677aa00980b3b067d44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=285.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50cd5ad987ec4cf9950ff39b53c51812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=537.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f566b5f089f49f8a12d716be21444a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=273.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d575e713563a4085875b9d4eba18ca72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=228.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "555035a914394a84870d80d22cb19844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=941.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf8982470b548d79298a0de6bcb8d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=494.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e4bbad49ee34ded8df0c6f38e835419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=702.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f3487a678034d3ab5feba303d8c3aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=240.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3621d8b20ec456d9b99afafbf283540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=473.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "285c9ac4d6f64b7bb9fa0a38a772d32a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=123.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03aba6d5e9784a41b49b448e2c5ed036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=523.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a4f9d241d04115accc41e2e9011e1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=192.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d8201ae3b6243e89d65b5f970273ea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=244.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e090e1e24141ce87fb00e582b472f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=552.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1f8fe2a351f412196d99da9d1ca2651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=367.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc0b2a29ba324de2a221ee313a4b68bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=202.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aaed28edc404362b23f7cff788b9552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=230.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7c176387e7f403189ac38d4d733df20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=157.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "729d84b3c5ca43b4be69d7dbccae7b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=356.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e41a964fbd1e430ba136a36888932fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=235.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa5dc582d799400da34352f39caea9b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=413.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "475bbaa07ec44282b806d575ec39da53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=154.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed51c67c4604e8eb73a3272904588a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=134.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12aef174b0b44536935d1031713f0b22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=192.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20e1de82d55e4f04926021c42e01ea11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=547.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4990973861854fcdb7cd20f125799b36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=414.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "dataframe = []\n",
    "maxlength = np.empty(3 * len(exp))\n",
    "jump = 0;\n",
    "\n",
    "for idx, val in enumerate(exp):\n",
    "# allocate PSTH array\n",
    "    maxlength[jump + idx] = np.int(np.ceil(np.diff(ids[idx][\"Contra\"][:], axis = 0).mean() + prestim_frames[idx] + poststim_frames[idx]))\n",
    "    maxlength[jump + idx + 1 ] = np.int(np.ceil(np.diff(ids[idx][\"Ipsi\"][:], axis = 0).mean() + prestim_frames[idx] + poststim_frames[idx]))\n",
    "    maxlength[jump + idx + 2 ] = np.int(np.ceil(np.diff(ids[idx][\"Bino\"][:], axis = 0).mean() + prestim_frames[idx] + poststim_frames[idx]))\n",
    "    jump = jump + 2\n",
    "\n",
    "maxlength = np.int(np.max(maxlength))\n",
    "# for cell in tqdm(np.random.randint(0,ncells,5)):\n",
    "\n",
    "cellglob = 0\n",
    "data_dict = {}\n",
    "i = 0\n",
    "\n",
    "\n",
    "for idx, expval in enumerate(exp):\n",
    "    #print(cellglob)\n",
    "    for cell in notebook.tqdm(range(ncells[idx])):\n",
    "        cat = 0\n",
    "        for category in categories:            \n",
    "            for trial, val in enumerate(ids[idx][category][0]):\n",
    "                aligned_F = np.empty((1,maxlength)).squeeze()\n",
    "                aligned_F.fill(np.NaN)\n",
    "                aligned_Fneu = np.empty((1,maxlength)).squeeze()\n",
    "                aligned_Fneu.fill(np.NaN)\n",
    "                aligned_spks = np.empty((1,maxlength)).squeeze()\n",
    "                aligned_spks.fill(np.NaN)\n",
    "                aligned_stimdata = np.empty((1,maxlength)).squeeze()\n",
    "                aligned_stimdata.fill(np.NaN)\n",
    "                slice_range = np.arange(ids[idx][category][0][trial].astype(int)-prestim_frames[idx].astype(int),ids[idx][category][1][trial].astype(int)+poststim_frames[idx].astype(int))\n",
    "                aligned_stimdata[0:len(slice_range)] = auxdata[ids[idx]['FrameTimes_level'][slice_range],stimops['Stims_chan']]\n",
    "                aligned_F[0:len(slice_range)] = F[idx][cell,slice_range]\n",
    "                aligned_Fneu[0:len(slice_range)] = Fneu[idx][cell,slice_range]\n",
    "                aligned_spks[0:len(slice_range)] = spks[idx][cell,slice_range]\n",
    "\n",
    "                time = np.arange(0, aligned_F.shape[0] * 1 / (ids[idx]['framerate_auxderived'] / level), 1 / (ids[idx]['framerate_auxderived'] / level) ) - prestim[idx]\n",
    "                aux_time = np.arange(0, aligned_stimdata.shape[0] * 1 / (ids[idx]['framerate_auxderived'] / level), 1 / (ids[idx]['framerate_auxderived'] / level)  ) - prestim[idx]\n",
    "\n",
    "                layer = load_df[load_df['experiment'] == int(expval)]['Layer'].to_numpy(),\n",
    "\n",
    "                data_dict[i] = {\n",
    "                                        'experimentator': experimentator[0],\n",
    "                                        'mouse': mouse[0],\n",
    "                                        'date': date[0],\n",
    "                                        'experiment': experiment[0],\n",
    "                                        'cell': cellglob,\n",
    "                                        'layer': Layer[0],\n",
    "                                        'elevation': Elevation[0],\n",
    "                                        'time': time,\n",
    "                                        'auxtime':aux_time,\n",
    "                                        'aux_files': aux_files[0],\n",
    "                                        'aligned_stimdata': aligned_stimdata,\n",
    "                                        'trial':trial,\n",
    "                                        'Stimulus_direction': ids[idx][stimDir_categories[cat]][trial],\n",
    "                                        'Stimulus_ID': ids[idx][stimID_categories[cat]][trial],\n",
    "                                        'Number_of_stims': ids[idx]['NumStim'],\n",
    "                                        'Number_of_trials': ids[idx]['TotTrialNum'],\n",
    "                                        'aligned_F': aligned_F,\n",
    "                                        'aligned_spks': aligned_spks,\n",
    "                                        'aligned_Fneu': aligned_Fneu,\n",
    "                                        'category': category,\n",
    "                                        'adata_s2ppath': adata_s2ppath[0],\n",
    "                                        'SI_level': level,\n",
    "                                        'SI_zoom': zoom,\n",
    "                                        'SI_framerate': framerate,\n",
    "                                        'SI_framerate_aux_derived': ids[idx]['framerate_auxderived'][0],\n",
    "                                        'SI_channels': channels,\n",
    "                                        'SI_volumes': volumes,\n",
    "                                        'SI_frames': frames,\n",
    "                                        'SI_frames_per_file': frames_per_file,\n",
    "                                        'SI_tiffpath': adata_tiffpath[0],\n",
    "                                        'SI_single_tiff_file': single_tiff_file[0]\n",
    "                                        }\n",
    "                i += 1\n",
    "            cat += 1\n",
    "        cellglob += 1\n",
    "\n",
    "dataframe = pd.DataFrame.from_dict(data_dict, orient = 'index') #MUCH faster than df.append or df.concat! But it does not throw each timepoint in a different row\n",
    "\n",
    "del data_dict\n",
    "del F\n",
    "del Fneu\n",
    "del spks\n",
    "del iscell\n",
    "\n",
    "# EXPLODING to single line - SLOW!\n",
    "dataframe = dataframe.apply(pd.Series.explode).reset_index(drop=True) #exploding this takes time, though...\n",
    "\n",
    "# Converting and downcasting object columns to float32\n",
    "columns = ['time',\n",
    "           'aligned_F',\n",
    "           'aligned_spks',\n",
    "           'aligned_Fneu']\n",
    "dataframe[columns] = dataframe[columns].apply(pd.to_numeric, errors='coerce', downcast = 'float')\n",
    "\n",
    "# Convert data column to daaetime\n",
    "#dataframe['date'] =  pd.to_datetime(dataframe['date'])\n",
    "\n",
    "# TODO\n",
    "# EXTRACT ODI SIG ETC HE`RE!\n",
    "# - include Fneu, dF/F (-Fneu), reconvolved\n",
    "# - functionalize\n",
    "# - aggregate over all recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save dataframe here\n",
    "dataframe.to_pickle('layer1_and_4_mac_grat_exp_all_new_dat_sprestim.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save stim Ids here\n",
    "with open('Grat_ids_new.pkl', 'wb') as handle:\n",
    "    pickle.dump(ids, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'Simple' one-liners to get trial averages over all cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allcells_Ipsi_stim1 = dataframe[(dataframe['category'] == 'Bino') & (dataframe['Stimulus_ID'] == 12) & (dataframe['cell'] == 10)].groupby(['time', 'cell'], as_index=False).aligned_spks.mean().pivot(index = 'time', columns='cell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allcells_Ipsi_stim1 = dataframe[(dataframe['category'] == 'Bino') & (dataframe['Stimulus_ID'] == 12)].groupby(['time', 'cell'], as_index=False).aligned_spks.mean().pivot(index = 'time', columns='cell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.loc[0].Number_of_stims                                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,6))\n",
    "\n",
    "with sns.axes_style('white'):\n",
    "    #plt.subplot(2,3,1)\n",
    "    plt.imshow(allcells_Ipsi_stim1.T, vmax = 2, vmin = 0.5, aspect = 'auto', cmap = 'Reds')c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concatenate all stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contra_concat = []\n",
    "ipsi_concat = []\n",
    "bino_concat = []\n",
    "\n",
    "for stimid in notebook.tqdm(range(dataframe.loc[0].Number_of_stims)):\n",
    "    allcells_Contra_stim = dataframe[(dataframe['category'] == 'Contra') & (dataframe['Stimulus_ID'] == stimid + 1)].groupby(['time', 'cell'], as_index=False).aligned_spks.mean().pivot(index = 'time', columns='cell').to_numpy()\n",
    "    contra_concat.append(allcells_Contra_stim)\n",
    "    allcells_Ipsi_stim = dataframe[(dataframe['category'] == 'Ipsi') & (dataframe['Stimulus_ID'] == stimid + 1)].groupby(['time', 'cell'], as_index=False).aligned_spks.mean().pivot(index = 'time', columns='cell').to_numpy()\n",
    "    ipsi_concat.append(allcells_Ipsi_stim)\n",
    "    allcells_Bino_stim = dataframe[(dataframe['category'] == 'Bino') & (dataframe['Stimulus_ID'] == stimid + 1)].groupby(['time', 'cell'], as_index=False).aligned_spks.mean().pivot(index = 'time', columns='cell').to_numpy()\n",
    "    bino_concat.append(allcells_Bino_stim)\n",
    "\n",
    "contra_concat_np = np.array(contra_concat)\n",
    "ipsi_concat_np = np.array(ipsi_concat)\n",
    "bino_concat_np = np.array(bino_concat)\n",
    "\n",
    "res = contra_concat_np.shape\n",
    "contra_concat_np = contra_concat_np.reshape(res[0]*res[1],res[2])\n",
    "ipsi_concat_np = ipsi_concat_np.reshape(res[0]*res[1],res[2])\n",
    "bino_concat_np = bino_concat_np.reshape(res[0]*res[1],res[2])\n",
    "all_concat_np = np.concatenate((contra_concat_np, ipsi_concat_np, bino_concat_np), axis = 0)\n",
    "\n",
    "contra_concat_np[np.isnan(contra_concat_np)] = 0\n",
    "ipsi_concat_np[np.isnan(ipsi_concat_np)] = 0\n",
    "bino_concat_np[np.isnan(bino_concat_np)] = 0\n",
    "all_concat_np[np.isnan(all_concat_np)] = 0\n",
    "\n",
    "\n",
    "contra_concat_np_zscored = z_score(contra_concat_np)\n",
    "ipsi_concat_np_zscored = z_score(ipsi_concat_np)\n",
    "bino_concat_np_zscored= z_score(bino_concat_np)\n",
    "all_concat_np_zscored= z_score(all_concat_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,6))\n",
    "\n",
    "with sns.axes_style('white'):\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(contra_concat_np_zscored.T, vmax = 2, vmin = -.5, aspect = 'auto', cmap = 'Blues')\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(ipsi_concat_np_zscored.T, vmax = 2, vmin = -.5, aspect = 'auto', cmap = 'Reds')\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(bino_concat_np_zscored.T, vmax = 2, vmin = -.5, aspect = 'auto', cmap = 'gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rastermap sortings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "model_ipsi = rm.mapping.Rastermap(n_components=1).fit(ipsi_concat_np_zscored.T)\n",
    "model_contra = rm.mapping.Rastermap(n_components=1).fit(contra_concat_np_zscored.T)\n",
    "model_bino = rm.mapping.Rastermap(n_components=1).fit(bino_concat_np_zscored.T)\n",
    "model_all = rm.mapping.Rastermap(n_components=1).fit(all_concat_np_zscored.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### sort neurons and smooth across neurons \n",
    "smooth = True\n",
    "timesmooth = True\n",
    "\n",
    "if smooth:\n",
    "    isort = np.argsort(model_all.embedding[:,0])   \n",
    "    Sm_ipsi = gaussian_filter1d(ipsi_concat_np_zscored.T[isort,:], np.minimum(3,int(ipsi_concat_np_zscored.shape[0]*0.005)), axis=0)\n",
    "    # isort = np.argsort(model_contra.embedding[:,0])\n",
    "    Sm_contra = gaussian_filter1d(contra_concat_np_zscored.T[isort,:], np.minimum(3,int(contra_concat_np_zscored.shape[0]*0.005)), axis=0)\n",
    "    # isort = np.argsort(model_bino.embedding[:,0])\n",
    "    Sm_bino = gaussian_filter1d(bino_concat_np_zscored.T[isort,:], np.minimum(3,int(bino_concat_np_zscored.shape[0]*0.005)), axis=0)\n",
    "    Sm_all  = gaussian_filter1d(all_concat_np_zscored.T[isort,:], np.minimum(3,int(all_concat_np_zscored.shape[0]*0.005)), axis=0)\n",
    "#     Sm_all= sp_all.T[isort,:]\n",
    "else:\n",
    "    isort = np.argsort(model_bino.embedding[:,0])\n",
    "    Sm_ipsi = sp_ipsi.T[isort,:]\n",
    "    # isort = np.argsort(model_contra.embedding[:,0])\n",
    "    Sm_contra = sp_contra.T[isort,:]\n",
    "    # isort = np.argsort(model_bino.embedding[:,0])\n",
    "    Sm_bino = sp_bino.T[isort,:]\n",
    "    Sm_all  = sp_all.T[isort,:]\n",
    "    \n",
    "if timesmooth:\n",
    "    sigma = 1\n",
    "# (optional) smooth in time\n",
    "    Sm_contra = gaussian_filter1d(Sm_contra, sigma, axis=1)\n",
    "    Sm_ipsi = gaussian_filter1d(Sm_ipsi, sigma, axis=1)\n",
    "    Sm_bino = gaussian_filter1d(Sm_bino, sigma, axis=1)\n",
    "    Sm_all = gaussian_filter1d(Sm_all, sigma, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,6))\n",
    "\n",
    "with sns.axes_style('white'):\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(Sm_contra, vmax = 2, vmin = -0.5, aspect = 'auto', cmap = 'Blues')\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(Sm_ipsi, vmax = 2, vmin = -0.5, aspect = 'auto', cmap = 'Reds')\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(Sm_bino, vmax = 2, vmin = -0.5, aspect = 'auto', cmap = 'gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,6))\n",
    "\n",
    "with sns.axes_style('white'):\n",
    "    plt.subplot(1,1,1)\n",
    "    plt.imshow(Sm_all, vmax = 3, vmin = -0.5, aspect = 'auto', cmap = 'gray_r')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### auxdata and timebase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_range = np.arange(ids[0]['Ipsi'][0][1].astype(int)-prestim_frames[0].astype(int),ids[0]['Ipsi'][1][1].astype(int)+poststim_frames[0].astype(int)+1)\n",
    "# slice_range = np.arange(ids[category][0][trial].astype(int)-prestim_frames.astype(int),ids[category][1][trial].astype(int)+poststim_frames.astype(int))\n",
    "\n",
    "aligned_stimdata = auxdata[ids[0]['FrameTimes_level'][slice_range],stimops['Stims_chan']]\n",
    "# aligned_stimdata_concat = np.tile(auxdata[ids['FrameTimes_level'][slice_range],stimops['Stims_chan']], (0,3))\n",
    "aux_time = np.arange(0, aligned_stimdata.shape[0] * 1 / (ids[0]['framerate_auxderived'] / level), 1 / (ids[0]['framerate_auxderived'] / level) ) - prestim[0]\n",
    "\n",
    "aligned_stimdata_full = ids[0]['auxdata'][ids[0]['FrameTimes_level'][slice_range[0]]:ids[0]['FrameTimes_level'][slice_range[-1]],stimops['Stims_chan']]\n",
    "aligned_stimdata_full_concat = np.tile(aligned_stimdata_full, (1,3)).T\n",
    "\n",
    "aux_time_full = np.arange(0, aligned_stimdata_full.shape[0] * 1 / ids[0]['aux_samplingfreq'] , 1 / ids[0]['aux_samplingfreq']    ) - prestim[0]\n",
    "aux_time_full_concat = np.arange(0, aligned_stimdata_full_concat.shape[0] * 1 / ids[0]['aux_samplingfreq'] , 1 / ids[0]['aux_samplingfreq']   ) - prestim[0]\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(aux_time, aligned_stimdata)\n",
    "# plt.plot(aux_time_full_concat, aligned_stimdata_full_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seperately sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### view neuron sorting\n",
    "\n",
    "# aligned_stimdata = auxdata[ids['FrameTimes_level'][slice_range][0]:ids['FrameTimes_level'][slice_range][-1],stimops['Stims_chan']]\n",
    "# aux_time = np.arange(0, aligned_stimdata.shape[0] * 1 / aux_samplingfreq, 1 / aux_samplingfreq  ) - prestim\n",
    "\n",
    "fs = ids[0]['framerate_auxderived'] / level\n",
    "vmin_glob = -.5\n",
    "vmax_glob = 2.5\n",
    "ncells = cellglob \n",
    "with sns.axes_style('white'):\n",
    "    xl = [-prestim[0],Sm_contra.shape[1]/fs-prestim[0]]\n",
    "    \n",
    "    fig8 = plt.figure(figsize=(20,16), constrained_layout=True)\n",
    "    gs1 = fig8.add_gridspec(nrows=8, ncols=3)\n",
    "    \n",
    "    fig8.add_subplot(gs1[1:, :-2])      \n",
    "    fig8_ax=plt.imshow(Sm_contra, vmin=vmin_glob,vmax=vmax_glob,aspect='auto',extent=[-prestim[0],Sm_contra.shape[1]/fs-prestim[0], 0,Sm_contra.shape[0]], cmap = 'Blues')\n",
    "    plt.xlabel('time (s)', fontsize=18)    \n",
    "    \n",
    "    plt.vlines([prestim_frames[0] / fs-prestim[0], maxlength / fs - poststim_frames[0] / fs -prestim[0] ],0,ncells-1, 'k')\n",
    "    plt.ylabel('boutons', fontsize=18)     \n",
    "        \n",
    "    f8_ax2 = fig8.add_subplot(gs1[1:, 1:-1])\n",
    "    ax=plt.imshow(Sm_ipsi, vmin=vmin_glob,vmax=vmax_glob,aspect='auto',extent=[-prestim[0],Sm_ipsi.shape[1]/fs-prestim[0], 0,Sm_ipsi.shape[0]], cmap = 'Reds')\n",
    "    plt.xlabel('time (s)', fontsize=18)\n",
    "    \n",
    "    plt.vlines([prestim_frames[0] / fs-prestim[0], maxlength / fs - poststim_frames[0] / fs -prestim[0] ],0,ncells-1, 'k')\n",
    "        \n",
    "    f8_ax3 = fig8.add_subplot(gs1[1:, 2:])\n",
    "    ax=plt.imshow(Sm_bino, vmin=vmin_glob,vmax=vmax_glob,aspect='auto',extent=[-prestim[0],Sm_bino.shape[1]/fs-prestim[0], 0,Sm_bino.shape[0]], cmap = 'gray_r')\n",
    "    plt.xlabel('time (s)', fontsize=18)\n",
    "    \n",
    "    plt.vlines([prestim_frames[0] / fs-prestim[0], maxlength / fs - poststim_frames[0] / fs -prestim[0]],0,ncells-1, 'k')\n",
    "\n",
    "#    plt.colorbar(label='deconvolved F [a.u.]')\n",
    "   \n",
    "    f8_ax4 = fig8.add_subplot(gs1[:1, :-2])    \n",
    "    plt.plot(aux_time_full, aligned_stimdata_full, 'k')\n",
    "#     plt.vlines([prestim_frames / fs-prestim, maxlength / fs - poststim_frames / fs -prestim],0,4, 'k')\n",
    "    f8_ax4.set_xlim(*xl)\n",
    "    f8_ax4.axis('off')\n",
    "    plt.title('Contra')\n",
    "    \n",
    "    f8_ax5 = fig8.add_subplot(gs1[:1, 1:-1])\n",
    "    plt.plot(aux_time_full, aligned_stimdata_full, 'k')\n",
    "    f8_ax5.set_xlim(*xl)\n",
    "    f8_ax5.axis('off')\n",
    "    plt.title('Ipsi')\n",
    "\n",
    "    \n",
    "    f8_ax6 = fig8.add_subplot(gs1[:1, 2:])\n",
    "    plt.plot(aux_time_full, aligned_stimdata_full, 'k')\n",
    "    f8_ax6.set_xlim(*xl)\n",
    "    f8_ax6.axis('off')\n",
    "    plt.title('Bino')    \n",
    "    \n",
    "#     plt.tight_layout()           \n",
    "    plt.suptitle('z-scored deconvolved Chirp PSTHs - rastermap embedding (sorted on Bino, smoothened over boutons) - exp' + exp[0])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('separate.eps', format='eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concatenated figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### view neuron sorting\n",
    "\n",
    "# aligned_stimdata = auxdata[ids['FrameTimes_level'][slice_range][0]:ids['FrameTimes_level'][slice_range][-1],stimops['Stims_chan']]\n",
    "# aux_time = np.arange(0, aligned_stimdata.shape[0] * 1 / aux_samplingfreq, 1 / aux_samplingfreq  ) - prestim\n",
    "\n",
    "fs = ids[0]['framerate_auxderived'] / level\n",
    "vmin_glob = -.5\n",
    "vmax_glob = 2.5\n",
    "\n",
    "with sns.axes_style('white'):\n",
    "    xl = [-prestim[0],Sm_all.shape[1]/fs - prestim[0]]\n",
    "    \n",
    "    fig9 = plt.figure(figsize=(20,20), constrained_layout=True)\n",
    "    \n",
    "    gs1 = fig9.add_gridspec(nrows=12, ncols=3)\n",
    "    \n",
    "    fig9.add_subplot(gs1[1:, :])      \n",
    "    fig9_ax=plt.imshow(Sm_all, vmin=vmin_glob,vmax=vmax_glob,aspect='auto',extent=[-prestim[0],Sm_all.shape[1]/fs-prestim[0], 0,Sm_all.shape[0]], cmap = 'gray_r')\n",
    "    plt.xlabel('time (s)', fontsize=18)    \n",
    "    \n",
    "#     plt.vlines([prestim_frames / fs-prestim, maxlength / fs - poststim_frames / fs -prestim ],0,ncells-1, 'k')\n",
    "    plt.ylabel('boutons', fontsize=18)     \n",
    "    \n",
    "    plt.vlines([aux_time_full[-1],  +aux_time_full[-1] *2 + poststim[0]],0,ncells-1, 'r')\n",
    "    plt.vlines([prestim_frames[0] / fs-prestim[0], maxlength / fs - poststim_frames[0] / fs -prestim[0]],0,ncells-1, 'b')\n",
    "    \n",
    "    plt.vlines([aux_time_full[-1] + (prestim_frames[0] / fs),  aux_time_full[-1] + (maxlength / fs - poststim_frames[0] / fs ) ],0,ncells-1, 'b')\n",
    "    plt.vlines([2 * aux_time_full[-1] + (prestim_frames[0] / fs) + prestim[0],  2 * aux_time_full[-1] + (maxlength / fs - poststim_frames[0] / fs ) + prestim[0]],0,ncells-1, 'b')\n",
    "#     plt.plot(aux_time_full_concat, aligned_stimdata_full_concat, 'k')\n",
    "    \n",
    "#     plt.colorbar(label='deconvolved F [zscored]')\n",
    "#     plt.colorbar(label='deconvolved F [a.u.]')\n",
    "   \n",
    "    f9_ax4 = fig9.add_subplot(gs1[:1, :])    \n",
    "    plt.plot(aux_time_full_concat, aligned_stimdata_full_concat, 'k')\n",
    "#     plt.vlines([prestim_frames / fs-prestim, maxlength / fs - poststim_frames / fs -prestim],0,4, 'k')\n",
    "    f9_ax4.set_xlim(*xl)\n",
    "    f9_ax4.axis('off')\n",
    "#     plt.title('Contra                                    Ipsi                                    Bino')\n",
    "    plt.text(aux_time_full[-1] / 2 - 2, 5 , 'Contra', fontsize=16)\n",
    "    plt.text(aux_time_full[-1] * 1.5-2, 5 , 'Ipsi', fontsize=16)\n",
    "    plt.text(aux_time_full[-1] * 2.5-2, 5 , 'Bino', fontsize=16)   \n",
    "    \n",
    "#     plt.tight_layout()           \n",
    "    plt.suptitle('z-scored deconvolved F - Chirp PSTHs - rastermap embedding (smoothened over boutons) - exp' + exp[0])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('all.eps', format='eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMF on PSTHs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = 29\n",
    "compstr = ['Comp ' + str(idx) for idx in range(components)]\n",
    "\n",
    "nmf = NMF(n_components=components, solver=\"mu\")\n",
    "\n",
    "# sp_all[sp_all < 0] = 0\n",
    "sp_contra[sp_contra < 0] = 0\n",
    "\n",
    "W = nmf.fit_transform(sp_contra.T)\n",
    " \n",
    "H = nmf.components_\n",
    "\n",
    "comp_df_H = pd.DataFrame(H.T, columns=compstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sm_all = nmf.inverse_transform(W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = components\n",
    "cols = int(np.ceil(components / rows))\n",
    "\n",
    "fig, axs = plt.subplots(rows,cols, figsize=(15, rows*2), facecolor='w', edgecolor='k')\n",
    "# fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "\n",
    "k = 0\n",
    "\n",
    "for ax, d in zip(axs.ravel(), H):\n",
    "    k += 1\n",
    "    ax.plot(time, d)\n",
    "#     ax.plot(d)\n",
    "    ax.set_title('component' + str(k))\n",
    "    ax.vlines([prestim_frames[0] / fs-prestim[0], maxlength / fs - poststim_frames[0] / fs -prestim[0]],0,4, 'k')\n",
    "# plt.figure() \n",
    "# for x in \n",
    "# sns.heatmap(data = comp_df_H.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style('white'):\n",
    "    \n",
    "    xl = [-prestim[0],Sm_all.shape[1]/fs - prestim[0]]\n",
    "    \n",
    "    fig10 = plt.figure(figsize=(20,20), constrained_layout=True)\n",
    "    \n",
    "    gs1 = fig10.add_gridspec(nrows=12, ncols=3)\n",
    "    \n",
    "    fig10.add_subplot(gs1[1:, :])      \n",
    "    fig10_ax=plt.imshow(Sm_all, vmin=vmin_glob,vmax=vmax_glob,aspect='auto',extent=[-prestim[0],Sm_all.shape[1]/fs-prestim[0], 0,Sm_all.shape[0]], cmap = 'gray_r')\n",
    "    plt.xlabel('time (s)', fontsize=18)    \n",
    "    \n",
    "#     plt.vlines([prestim_frames / fs-prestim, maxlength / fs - poststim_frames / fs -prestim ],0,ncells-1, 'k')\n",
    "    plt.ylabel('boutons', fontsize=18)     \n",
    "    \n",
    "    plt.vlines([aux_time_full[-1],  +aux_time_full[-1] *2 + poststim[0]],0,ncells-1, 'r')\n",
    "    plt.vlines([prestim_frames[0] / fs-prestim[0], maxlength / fs - poststim_frames[0] / fs -prestim[0]],0,ncells-1, 'b')\n",
    "    \n",
    "    plt.vlines([aux_time_full[-1] + (prestim_frames[0] / fs),  aux_time_full[-1] + (maxlength / fs - poststim_frames[0] / fs ) ],0,ncells-1, 'b')\n",
    "    plt.vlines([2 * aux_time_full[-1] + (prestim_frames[0] / fs) + prestim[0],  2 * aux_time_full[-1] + (maxlength / fs - poststim_frames[0] / fs ) + prestim[0]],0,ncells-1, 'b')\n",
    "#     plt.plot(aux_time_full_concat, aligned_stimdata_full_concat, 'k')\n",
    "    \n",
    "#     plt.colorbar(label='deconvolved F [zscored]')\n",
    "#    plt.colorbar(label='deconvolved F [a.u.]')\n",
    "   \n",
    "    f10_ax4 = fig10.add_subplot(gs1[:1, :])    \n",
    "    plt.plot(aux_time_full_concat, aligned_stimdata_full_concat, 'k')\n",
    "#     plt.vlines([prestim_frames / fs-prestim, maxlength / fs - poststim_frames / fs -prestim],0,4, 'k')\n",
    "    f10_ax4.set_xlim(*xl)\n",
    "    f10_ax4.axis('off')\n",
    "#     plt.title('Contra                                    Ipsi                                    Bino')\n",
    "    plt.text(aux_time_full[-1] / 2 - 2, 5 , 'Contra', fontsize=16)\n",
    "    plt.text(aux_time_full[-1] * 1.5-2, 5 , 'Ipsi', fontsize=16)\n",
    "    plt.text(aux_time_full[-1] * 2.5-2, 5 , 'Bino', fontsize=16)  \n",
    "    \n",
    "#     plt.tight_layout()           \n",
    "    plt.suptitle('z-scored deconvolved F - Chirp PSTHs - rastermap embedding (smoothened over boutons) - exp' + exp[0])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rastermap embedding exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = rm.mapping.Rastermap(n_components=2, n_X=40,  nPC=400, init='pca')\n",
    "embedding = model_contra.fit_transform(sp_contra.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(embedding*40)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding[isort]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = sp_contra.T\n",
    "\n",
    "NN, NT = S.shape \n",
    "\n",
    "# reshape and sum S across neurons to get \"components\"\n",
    "nc = 100\n",
    "NC = int(np.floor(NN / nc))\n",
    "Sp = np.reshape(S[isort][:nc*NC], (NC, nc, NT))\n",
    "Sp = Sp.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sp = np.reshape(S[isort][:nc*NC], (NC, nc, NT))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S[isort][:nc*NC].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results here\n",
    "cmap = plt.get_cmap('gist_ncar')\n",
    "cmap = cmap(np.linspace(0,.97,32))\n",
    "cmap = cmap[np.random.permutation(32),:]\n",
    "plt.figure(figsize=(6,6))\n",
    "# each point is colored based on stimulus identity\n",
    "istim = np.ones(len(sp_ipsi.T), dtype = 'int')\n",
    "plt.scatter(out2[:,0],out2[:,1],color=cmap[istim,:],marker='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(melted_aux[[:,0]], melted_aux[[0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_aux.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Panda convert to long form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted = dataframe.melt(id_vars=['category', 'time', 'trial', 'cell'], value_vars=['aligned_F'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### generating trial numpy array from single cell and condition\n",
    "\n",
    "arr = melted.loc[(melted.loc[:,'trial'] < 8) & (melted.loc[:,'cell'] == 1) & (melted.loc[:,'category'] == 'Bino'),'value'].to_numpy()\n",
    "arr = arr.reshape(8,maxlength)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Panda slicing examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot single cell including individual trials and means - seaborn and other\n",
    "\n",
    "# generating trial dataframe from single cell and condtion - SINGLE TRIAL\n",
    "subselected_orig = melted.loc[(melted.loc[:,'trial'] == 1) & (melted.loc[:,'cell'] == 1) & (melted.loc[:,'category'] == 'Contra'),['time', 'value', 'trial']]\n",
    "\n",
    "# generating trial dataframe from single cell and condtion - ALL TRIALS\n",
    "subselected_orig = melted.loc[(melted.loc[:,'cell'] == 1) & (melted.loc[:,'category'] == 'Contra'),['time', 'value', 'trial']]\n",
    "\n",
    "# reshape ('pivot') to index over time and have single trial columns\n",
    "subselected = subselected_orig.pivot(index = 'time', columns='trial', values='value')\n",
    "\n",
    "# reshape ('pivot') to index over time and have single trial columns - zscore on the fly\n",
    "# subselected = subselected_orig.pivot(index = 'time', columns='trial', values='value').transform((lambda x : zscore(x)))\n",
    "\n",
    "subselected = (subselected - subselected.mean())/subselected.std(ddof=0)\n",
    "\n",
    "# generate mean from that\n",
    "\n",
    "subselected_mean = subselected.mean(axis = 1)\n",
    "\n",
    "# plot seaborn original frame and pivoted mean and trials next to eachother\n",
    "fig = plt.figure()\n",
    "plt.subplot(1,3,1)\n",
    "sns.lineplot(x = 'time', y = 'value', data = subselected, ci = 'sd')\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(subselected, 'k')\n",
    "plt.plot(subselected_mean, 'r')\n",
    "plt.subplot(1,3,3)\n",
    "# sns.heatmap(subselected, cmap = 'cubehelix')\n",
    "plt.imshow(subselected.T, aspect = 'auto',  cmap = 'cubehelix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subselected = subselected_orig.pivot(index = 'time', columns='trial', values='value')\n",
    "subselected = (subselected - subselected.mean())/subselected.std(ddof=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot all trials of a single cell concatenated\n",
    "\n",
    "fig = plt.figure()\n",
    "melted.loc[(melted.loc[:,'cell'] == 1) & (melted.loc[:,'category'] == 'Contra'),'value'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "sns.set()\n",
    "with sns.axes_style('white'):\n",
    "#     plt.imshow(arr, aspect = 'auto',  cmap = 'cubehelix')\n",
    "    sns.heatmap(subselected_orig, cmap = 'cubehelix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot individual cells as line plots and group by condition\n",
    "\n",
    "g = sns.FacetGrid(melted, col='category', hue='category', row='cell', sharey='row', margin_titles=True)\n",
    "g.map(sns.lineplot, 'time', 'value', ci='sd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.clf()\n",
    "g = sns.relplot(x=\"time\", y=\"value\",\n",
    "                 col=\"category\", row = 'cell', hue=\"category\", style=\"category\",\n",
    "                 kind=\"line\", data=melted, estimator=None, facet_kws={'sharey': True, 'sharex': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show cells\n",
    "im = np.zeros((ops['Ly'], ops['Lx']))\n",
    "ncells = len(stat)\n",
    "\n",
    "for n in range(0,ncells):\n",
    "    ypix = stat[n]['ypix'][~stat[n]['overlap']]\n",
    "    xpix = stat[n]['xpix'][~stat[n]['overlap']]\n",
    "    im[ypix,xpix] = n+1\n",
    "fig = plt.figure(figsize=(7,4))\n",
    "plt.imshow(im)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops['tau'] = .7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show mean image\n",
    "fig = plt.figure(figsize=(8,3))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(ops[\"meanImg\"])\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(ops[\"meanImgE\"])\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(ops[\"Vcorr\"])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops['tau'] = 0.5\n",
    "bouton = 11;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efilt = np.exp(- np.linspace(0,50,200) / (ops['tau'] * ops['fs']))\n",
    "#efilt /= efilt.sum()\n",
    "sout = convolve(spks[bouton,:], efilt)\n",
    "sout = sout[:spks.shape[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,4))\n",
    "plt.plot(F[bouton]-Fneu[bouton] * .7)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sout)\n",
    "plt.tight_layout()\n",
    "plt.show\n",
    "#plt.plot(F[10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(spks[11])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "plt.imshow(spks[:100, :5000], vmax = 3, vmin = -0.5, aspect='auto', cmap = 'gray_r')\n",
    "plt.title('sample of the neural data matrix')\n",
    "plt.ylabel('boutons') \n",
    "plt.xlabel('time [samples]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToDo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- batch run different deconvolution settings using this code snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute deconvolution\n",
    "from suite2p import dcnv\n",
    "import numpy as np\n",
    "\n",
    "tau = 1.0 # timescale of indicator\n",
    "fs = 30.0 # sampling rate in Hz\n",
    "neucoeff = 0.7 # neuropil coefficient\n",
    "# for computing and subtracting baseline\n",
    "baseline = 'maximin' # take the running max of the running min after smoothing with gaussian\n",
    "sig_baseline = 10.0 # in bins, standard deviation of gaussian with which to smooth\n",
    "win_baseline = 60.0 # in seconds, window in which to compute max/min filters\n",
    "\n",
    "ops = {'tau': tau, 'fs': fs, 'neucoeff': neucoeff,\n",
    "       'baseline': baseline, 'sig_baseline': sig_baseline, 'win_baseline': win_baseline}\n",
    "\n",
    "# load traces and subtract neuropil\n",
    "F = np.load('F.npy')\n",
    "Fneu = np.load('Fneu.npy')\n",
    "Fc = F - ops['neucoeff'] * Fneu\n",
    "\n",
    "# baseline operation\n",
    "Fc = dcnv.preprocess(Fc, ops)\n",
    "\n",
    "# get spikes\n",
    "spks = dcnv.oasis(Fc, ops)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
