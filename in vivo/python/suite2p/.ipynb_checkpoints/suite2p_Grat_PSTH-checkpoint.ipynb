{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grating Stimulus analysis (Panda extraction / consolidation)\n",
    "Tobias Rose 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "#%matplotlib widget\n",
    "%matplotlib qt\n",
    "import seaborn as sns\n",
    "sns.set()  # set plot styles\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path, PureWindowsPath, PurePosixPath\n",
    "from scipy.signal import convolve\n",
    "from scipy.stats import zscore, rankdata\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "# from scipy.stats import zscore ### Cave! scipy zscore does not handle NaN!\n",
    "from ScanImageTiffReader import ScanImageTiffReader\n",
    "from helpers import parse_SI_header as pSI #own\n",
    "from tqdm import notebook\n",
    "\n",
    "import rastermap as rm\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aux loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_auxdata(filename):    \n",
    "    \"\"\" Loads .lvd aux data file - Pieter Goltstein 2020\"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        # Reset file index\n",
    "        f.seek(0)\n",
    "        # Get meta data\n",
    "        samplingfreq = np.fromfile(f, dtype='>f8', count=1)\n",
    "        print(\"Aux sampling frequency = {}Hz\".format(samplingfreq))\n",
    "        n_channels = int(np.fromfile(f, dtype='>f8', count=1))\n",
    "        print(\"# channels = {}\".format(n_channels))\n",
    "        timestamp = np.fromfile(f, dtype='>f8', count=1)\n",
    "        print(\"timestamp = {}\".format(timestamp))\n",
    "        max_input = np.fromfile(f, dtype='>f8', count=1)\n",
    "        print(\"max input = {} V\".format(max_input))\n",
    "        # Read aux data\n",
    "        auxdata = np.fromfile(f, dtype='>f8')\n",
    "        n_datapoints = int(auxdata.shape[0]/n_channels)\n",
    "        print(\"number of aux datapoints = {}\".format(n_datapoints))\n",
    "        auxdata = np.reshape(auxdata,(n_datapoints,n_channels))\n",
    "        return auxdata, samplingfreq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frame extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_times(auxdata, Frames_chan):\n",
    "    \"\"\" extracts frame onset times \"\"\"\n",
    "    len_aux = len(auxdata)\n",
    "    pos = np.argwhere(auxdata[0:,Frames_chan] > 0.75 * np.max(auxdata[range(0,len_aux),Frames_chan ])) # work on diff of indices rather than on raw diff to prevent multi-smaple detection in up/ downstrokes\n",
    "    diffpos = np.argwhere(np.diff(pos[0:,0]) > 1)\n",
    "    frame_times = pos[diffpos,0]\n",
    "    \n",
    "    if  len(frame_times)==0:\n",
    "        print('get_frame_times WARNING: no frames found')\n",
    "        frame_times = 1;\n",
    "        return frame_times\n",
    "    \n",
    "    # find onset of first frame\n",
    "    pos_first = np.argwhere(auxdata[0:,Frames_chan] < 0.5 * np.max(auxdata[range(0,len_aux), Frames_chan]))\n",
    "    diffpos_first = np.argwhere(np.diff(pos_first[0:,0]) > 1)\n",
    "    frame_times = np.append(diffpos_first[0], frame_times)\n",
    "    \n",
    "    return frame_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General stimulus bound extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stimIDs(auxdata, stimops):\n",
    "    \"\"\" extracts Stim onset times \"\"\"\n",
    "    \n",
    "    Frames_chan = stimops['Frames_chan']\n",
    "    Stims_chan = stimops['Stims_chan']\n",
    "    eye1_chan = stimops['eye1_chan']\n",
    "    eye2_chan = stimops['eye2_chan']\n",
    "    level = stimops['level']\n",
    "    minsample_delta = stimops['minsample_delta']\n",
    "    extract_stim = stimops['extract_stimID']\n",
    "\n",
    "    frame_times         = get_frame_times(auxdata,Frames_chan)\n",
    "    frame_times_level   = frame_times[range(0,len(frame_times),level)]\n",
    "\n",
    "\n",
    "    StimOn = auxdata[frame_times_level, Stims_chan]>0.8\n",
    "\n",
    "    # generate cleaned eye binaries\n",
    "    Eye1On = auxdata[frame_times_level,eye1_chan]*-1+ np.max(auxdata[frame_times_level,eye1_chan])>0.8\n",
    "    Eye2On = auxdata[frame_times_level,eye2_chan]>0.8\n",
    "    Eye2On[-1] = 1 \n",
    "    bino = Eye1On & Eye2On\n",
    "\n",
    "    Eye1On_only = Eye1On != bino\n",
    "    Eye2On_only = Eye2On != bino\n",
    "    Eye1On_only[-1] = False\n",
    "    Eye2On_only[-1] = False\n",
    "    bino[0] = False\n",
    "    bino[-1] = False\n",
    "\n",
    "    # generate cleaned bino binary\n",
    "    bino_onsets_temp  = np.argwhere(np.diff(np.multiply(bino, 1)) > 0)\n",
    "    bino_offsets_temp = np.argwhere(np.diff(np.multiply(bino, 1)) < 0)\n",
    "\n",
    "    bino_onsets  = bino_onsets_temp[np.argwhere(bino_offsets_temp[0:,0] - bino_onsets_temp[0:,0] > minsample_delta)]\n",
    "    bino_offsets = bino_offsets_temp[np.argwhere(bino_offsets_temp[0:,0] - bino_onsets_temp[0:,0] > minsample_delta)]                              \n",
    "\n",
    "    bino_clean = np.full(( len(frame_times_level)), False) \n",
    "\n",
    "    for i in range(len(bino_onsets)):\n",
    "        bino_clean[range(bino_onsets[i,0,0], bino_offsets[i,0,0])] = True\n",
    "\n",
    "    # extract stim on and offsets\n",
    "    stim_onsets_temp  = np.argwhere(np.diff(np.multiply(StimOn, 1)) > 0)\n",
    "    stim_offsets_temp = np.argwhere(np.diff(np.multiply(StimOn, 1)) < 0)\n",
    "\n",
    "    stim_on  = np.argwhere(np.diff(stim_onsets_temp[0:,0]) > minsample_delta) + 1\n",
    "    stim_off = np.argwhere(np.diff(stim_offsets_temp[0:,0]) > minsample_delta)\n",
    "\n",
    "    stim_on  = np.append(0, stim_on)\n",
    "    stim_off = np.append(stim_off, len(stim_offsets_temp) - 1)\n",
    "\n",
    "    stim_onsets  = stim_onsets_temp[stim_on]\n",
    "    stim_offsets = stim_offsets_temp[stim_off]\n",
    "\n",
    "    ids = { \n",
    "            'Contra':   [np.intersect1d(stim_onsets, np.argwhere(Eye1On_only)), np.intersect1d(stim_offsets, np.argwhere(Eye1On_only))],\n",
    "            'Ipsi': [np.intersect1d(stim_onsets, np.argwhere(Eye2On_only)), np.intersect1d(stim_offsets, np.argwhere(Eye2On_only))],\n",
    "            'Bino':   [np.intersect1d(stim_onsets, np.argwhere(bino_clean)), np.intersect1d(stim_offsets, np.argwhere(bino_clean))],\n",
    "            'FrameTimes_level': frame_times_level,\n",
    "            'FrameTimes':       frame_times,\n",
    "            }\n",
    "\n",
    "    ContraStim = []\n",
    "    IpsiStim = []\n",
    "    BinoStim = []\n",
    "\n",
    "    if extract_stim:\n",
    "        for trial, val in enumerate(ids['Contra'][0]):\n",
    "            ContraStim.append(np.median(auxdata[frame_times_level, Stims_chan][ids['Contra'][0][trial]:ids['Contra'][1][trial]]))\n",
    "            IpsiStim.append(np.median(auxdata[frame_times_level, Stims_chan][ids['Ipsi'][0][trial]:ids['Ipsi'][1][trial]]))\n",
    "            BinoStim.append(np.median(auxdata[frame_times_level, Stims_chan][ids['Bino'][0][trial]:ids['Bino'][1][trial]]))\n",
    "\n",
    "        C_Stim = np.round(np.array(ContraStim)*10)/10\n",
    "        I_Stim = np.round(np.array(IpsiStim)*10)/10\n",
    "        B_Stim = np.round(np.array(BinoStim)*10)/10\n",
    "\n",
    "        NumStim = len(np.unique(C_Stim))\n",
    "        TotStim = len(C_Stim)\n",
    "        TrialNum = int(TotStim / NumStim)\n",
    "        StimIDs_Contra = rankdata(C_Stim, 'dense')\n",
    "        StimIDs_Ipsi = rankdata(I_Stim, 'dense')\n",
    "        StimIDs_Bino = rankdata(B_Stim, 'dense')\n",
    "\n",
    "        ids.update({ \n",
    "                'NumStim':       NumStim,\n",
    "                'TotStim':       TotStim,\n",
    "                'TotTrialNum':      TrialNum,\n",
    "                'StimID_Contra':      StimIDs_Contra,\n",
    "                'StimID_Ipsi':        StimIDs_Ipsi,\n",
    "                'StimID_Bino':        StimIDs_Bino,\n",
    "                'StimDirs_Contra':    StimIDs_Contra / NumStim * 360,\n",
    "                'StimDirs_Ipsi':      StimIDs_Ipsi / NumStim * 360,\n",
    "                'StimDirs_Bino':      StimIDs_Bino / NumStim * 360\n",
    "                    })\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### on-the-fly panda function definition of zscore that handles NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score(df): return (df-df.mean())/df.std(ddof=0)\n",
    "# def m_mean(df): return df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-specific folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.platform == \"darwin\":\n",
    "    ### Mac - command + k in finder; smb://10G.ISI01.neuro.mpg.de/archive_bonhoeffer_group$/David Laubender\n",
    "    main_root = '/Volumes/David Laubender/Data/imaging data/DL_191024_6/ImagingData/' #location of original data\n",
    "    adata     = '/Volumes/David Laubender/adata' #location of saved analyzed data\n",
    "    ftemp     = '/Users/trose/Data/temp' #fast disk (local ssd for s2p binary files) \n",
    "    ftiff     = '/Users/trose/Data/s2p_tiff' #fast disk folder for concatenated tiffs (if needed)\n",
    "    xlpath    = 'LGNexperiments.xlsx' \n",
    "elif sys.platform == \"win32\":\n",
    "#     main_root = 'I:/David Laubender/Data/imaging data/DL_191106_2/ImagingData' #location of original data\n",
    "    main_root = 'I:/David Laubender/Data/imaging data/DL_191024_6/ImagingData' #location of original data    \n",
    "    adata     = 'I:/David Laubender/adata' #location of saved analyzed data\n",
    "    ftemp     = 'C:/temp/trose/suite2ptemp' #fast disk (local ssd for s2p binary files  \n",
    "    ftiff     = 'C:/temp/trose/s2p_tiff' #fast disk folder for concatenated tiffs (if needed)\n",
    "    xlpath    = 'LGNexperiments.xlsx' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read excel file into panda dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(xlpath, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split comments column into Layer and elevation columns and drop mixed column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Layer', 'Elevation']] = df.comments.str.rsplit(',', expand = True)\n",
    "df = df.drop(['comments'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  boolean combination of search strings (here: Grating stim only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[(df['experiment type'] == 'euler' ) & (df['Layer'] == 'L1')]\n",
    "# load_df = df[(df['experiment type'] == 'euler' ) & (df['Layer'] == 'L1') & (df['Elevation']==' positive degrees')]\n",
    "#load_df = df[(df['experiment type'] == 'euler' ) & (df['Layer'] == 'L4')]\n",
    "\n",
    "load_df = df[(df['experiment type'] == 'grating' )]\n",
    "exp=list(map(str,load_df.experiment))\n",
    "main_root=list(map(str,load_df.folder))\n",
    "# list(main_root)\n",
    "# list(exp)\n",
    "#exp = [exp[0]]\n",
    "#main_root = [main_root[0]]\n",
    "#main_root_old = main_root[0]\n",
    "\n",
    "if sys.platform == \"darwin\":\n",
    "    main_root_mac = []\n",
    "    for idx, val in enumerate(exp):\n",
    "        main_root_mac.append(str(Path('/Volumes/', *PureWindowsPath(main_root[idx]).parts[1:])))\n",
    "    main_root = main_root_mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp = ['62283', '62284', '62285', '62286', '62287', '62288', '62289', '62290']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp = ['62336']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db390c4ce70245b1af2935a6aafb9bdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "adata_s2ppath = []\n",
    "adata_tiffpath = []\n",
    "aux_files = []\n",
    "single_tiff_file =[]\n",
    "experimentator = []\n",
    "mouse = []\n",
    "date = []\n",
    "experiment = []\n",
    "\n",
    "for idx, val in notebook.tqdm(enumerate(exp)):\n",
    "    s2pdir = list(Path(main_root[idx]).rglob('suite2p_exp'+val+'/')) #recursive\n",
    "    tifffile = list(Path(os.path.join(*Path(s2pdir[0]).parts[0:-3], 'ImagingData', Path(s2pdir[0]).parts[-2])).glob('exp'+val+'*.tif')) #recursive search over main_root    \n",
    "    experimentator.append(Path(s2pdir[0]).parts[-7])\n",
    "    mouse.append(Path(s2pdir[0]).parts[-4])\n",
    "    date.append(Path(s2pdir[0]).parts[-2])\n",
    "    experiment.append(val)\n",
    "    Layer = load_df[load_df['experiment'] == int(val)]['Layer'].str.strip().to_numpy()\n",
    "    Elevation = load_df[load_df['experiment'] == int(val)]['Elevation'].str.strip().to_numpy()\n",
    "    try:\n",
    "        adata_s2ppath.append(os.path.join(s2pdir[0], 'suite2p', 'combined'))\n",
    "        adata_tiffpath.append(os.path.dirname(s2pdir[0]))\n",
    "        aux_files.append(*Path(os.path.join(*Path(s2pdir[0]).parts[0:-3], 'data', Path(s2pdir[0]).parts[-2])).glob('exp'+val+'*.lvd'))\n",
    "        single_tiff_file.append(str(tifffile[0]))\n",
    "    except:\n",
    "        print(val + ' not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parse first tiff of exp for imaging specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ScanImageTiffReader(single_tiff_file[0]) as reader:\n",
    "    header = (reader.description(0))\n",
    "    mov_dim = (reader.shape())\n",
    "    \n",
    "level = pSI.parse_SI_header_level(header)\n",
    "zoom = pSI.parse_SI_header_zoom(header)\n",
    "framerate = pSI.parse_SI_header_FrameRate(header)\n",
    "channels = pSI.parse_SI_header_Channels(header)\n",
    "volumes = pSI.parse_SI_header_Volumes(header)\n",
    "frames = pSI.parse_SI_header_Frames(header)\n",
    "frames_per_file = pSI.parse_SI_header_FramesPerFile(header)\n",
    "\n",
    "# account for multilevel acq where frames is 1\n",
    "if frames < volumes:\n",
    "    frames = volumes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract grating stim timebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimops = {\n",
    "    'Frames_chan': 3,\n",
    "    'Stims_chan': 7,\n",
    "    'eye1_chan': 16,\n",
    "    'eye2_chan': 17,\n",
    "    'level': level, # extract from SI file in the future\n",
    "    'minsample_delta': 10, \n",
    "    'extract_stimID': True\n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('Grat_ids.pkl', 'rb') as handle:\n",
    "#    ids = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#auxdata = ids[0]['auxdata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#level = dataframe['SI_level'].to_numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = {}\n",
    "for idx, val in notebook.tqdm(enumerate(exp)):\n",
    "    aux_filename = str(aux_files[idx])\n",
    "    print(aux_filename)\n",
    "    [auxdata, aux_samplingfreq] = load_auxdata(aux_filename)\n",
    "    print('extracting stimIDs')\n",
    "    ids[idx] = get_stimIDs(auxdata, stimops)\n",
    "    ids[idx]['aux_filename'] = aux_filename\n",
    "    if idx == 0:\n",
    "        ids[idx]['auxdata'] = auxdata\n",
    "    else:\n",
    "        ids[idx]['auxdata'] = []\n",
    "    ids[idx]['aux_samplingfreq'] = aux_samplingfreq\n",
    "    ids[idx]['framerate_auxderived'] = aux_samplingfreq / np.median(np.diff(ids[idx]['FrameTimes']))\n",
    "print('DONE!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot aux_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### raw aux plus stimbounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# only works if all auxdaa is put into ids dictionary (not with the first slice only)\n",
    "#fig = plt.figure(figsize=(8,6))\n",
    "#jump = 0\n",
    "#for idx, val in enumerate(exp):\n",
    "#    plt.subplot(len(exp)*3 +1 ,1,idx+jump+1)\n",
    "#    plotdata = ids[idx]['auxdata'][ids[idx]['FrameTimes_level'],stimops['Stims_chan']]\n",
    "#    plt.plot(plotdata), plt.ylabel('Stims_chan') \n",
    "#    plt.vlines([ids[idx]['Ipsi'][0]],-1,6, 'r')\n",
    "#    plt.vlines([ids[idx]['Ipsi'][1]],-1,6, 'r')\n",
    "#    plt.vlines([ids[idx]['Contra'][0]],-1,6, 'b')\n",
    "#    plt.vlines([ids[idx]['Contra'][1]],-1,6, 'b')\n",
    "#    plt.vlines([ids[idx]['Bino'][0]],-1,6, 'k')\n",
    "#    plt.vlines([ids[idx]['Bino'][1]],-1,6, 'k')\n",
    "#    plt.subplot(len(exp)*3+1 ,1,idx+jump+2)\n",
    "#    plt.plot(ids[idx]['auxdata'][ids[idx]['FrameTimes_level'],stimops['eye1_chan']]), plt.ylabel('eye1_chan') \n",
    "#    plt.subplot(len(exp)*3+1 ,1,idx+jump+3)\n",
    "#    plt.plot(ids[idx]['auxdata'][ids[idx]['FrameTimes_level'],stimops['eye2_chan']]), plt.ylabel('eye2_chan') \n",
    "#    plt.show()\n",
    "#    jump = jump+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#fig = plt.figure(figsize=(8,6))\n",
    "#plt.subplot(1,1,1)\n",
    "#plt.plot(ids[idx]['auxdata'][:,stimops['Stims_chan']]), plt.ylabel('Stims_chan') \n",
    "#plt.vlines(ids[idx]['FrameTimes_level'][ids[idx]['Ipsi'][0]],-1,6, 'r')\n",
    "#plt.vlines(ids[idx]['FrameTimes_level'][ids[idx]['Ipsi'][1]],-1,6, 'k')\n",
    "## plt.vlines(ids['Ipsi'][1],-1,6, 'r')\n",
    "## plt.vlines(ids['Contra'][0],-1,6, 'b')\n",
    "## plt.vlines(ids['Contra'][1],-1,6, 'b')\n",
    "## plt.vlines(ids['Bino'][0],-1,6, 'k')\n",
    "## plt.vlines(ids['Bino'][1],-1,6, 'k')\n",
    "## plt.subplot(3,1,2)\n",
    "## plt.plot(auxdata[ids['FrameTimes_level'],stimops['eye1_chan']]), plt.ylabel('eye1_chan') \n",
    "## plt.subplot(3,1,3)\n",
    "## plt.plot(auxdata[ids['FrameTimes_level'],stimops['eye2_chan']]), plt.ylabel('eye2_chan') \n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ids and auxdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Grat_ids.pkl', 'rb') as handle:\n",
    "    ids = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxdata = ids[0]['auxdata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make PSTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb9bc30a5db14ea1b4d57ba44f3fc70a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "F = {}\n",
    "Fneu = {}\n",
    "spks = {}\n",
    "stat = {}\n",
    "ops = {}\n",
    "iscell = {}\n",
    "\n",
    "for idx, val in notebook.tqdm(enumerate(exp)):\n",
    "    F[idx] = np.load(os.path.join(adata_s2ppath[idx],'F.npy'))\n",
    "    Fneu[idx] = np.load(os.path.join(adata_s2ppath[idx],'Fneu.npy'))\n",
    "    spks[idx] = np.load(os.path.join(adata_s2ppath[idx],'spks.npy'))\n",
    "#     stat[idx] = np.load(os.path.join(adata_s2ppath[0],'stat.npy'), allow_pickle=True)\n",
    "#     ops[idx] = np.load(os.path.join(adata_s2ppath[0],'ops.npy'), allow_pickle=True).item()\n",
    "    iscell[idx] = np.load(os.path.join(adata_s2ppath[idx],'iscell.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop non-cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb7037d977a4c568ae7489f443395bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp62283 dropped 173 non-boutons (out of 1065)\n",
      "exp62286 dropped 648 non-boutons (out of 963)\n",
      "exp62289 dropped 573 non-boutons (out of 1058)\n",
      "exp62292 dropped 469 non-boutons (out of 725)\n",
      "exp62305 dropped 453 non-boutons (out of 738)\n",
      "exp62307 dropped 479 non-boutons (out of 1016)\n",
      "exp62360 dropped 447 non-boutons (out of 720)\n",
      "exp62363 dropped 451 non-boutons (out of 679)\n",
      "exp62258 dropped 266 non-boutons (out of 1207)\n",
      "exp62261 dropped 741 non-boutons (out of 1235)\n",
      "exp62266 dropped 478 non-boutons (out of 1180)\n",
      "exp62269 dropped 263 non-boutons (out of 503)\n",
      "exp62348 dropped 471 non-boutons (out of 944)\n",
      "exp62351 dropped 275 non-boutons (out of 398)\n",
      "exp62335 dropped 489 non-boutons (out of 1012)\n",
      "exp62338 dropped 281 non-boutons (out of 473)\n",
      "exp62354 dropped 334 non-boutons (out of 578)\n",
      "exp62356 dropped 358 non-boutons (out of 910)\n",
      "exp62399 dropped 426 non-boutons (out of 793)\n",
      "exp62402 dropped 330 non-boutons (out of 532)\n",
      "exp62378 dropped 454 non-boutons (out of 684)\n",
      "exp62381 dropped 273 non-boutons (out of 430)\n",
      "exp62299 dropped 683 non-boutons (out of 1039)\n",
      "exp62302 dropped 336 non-boutons (out of 571)\n",
      "exp62317 dropped 651 non-boutons (out of 1064)\n",
      "exp62320 dropped 330 non-boutons (out of 484)\n",
      "exp62366 dropped 348 non-boutons (out of 482)\n",
      "exp62369 dropped 419 non-boutons (out of 611)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, val in notebook.tqdm(enumerate(exp)):\n",
    "    old_len = len(F[idx])\n",
    "    F[idx] = F[idx][iscell[idx][:,0]==1,:]\n",
    "    Fneu[idx] =Fneu[idx][iscell[idx][:,0]==1,:]\n",
    "    spks[idx] = spks[idx][iscell[idx][:,0]==1,:]\n",
    "    print('exp' + val + ' dropped ' + str(old_len - len(F[idx])) + ' non-boutons (out of ' + str(old_len) + ')' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PANDAS: generate seaborn-compatible, stimulus-chopped long-form pandas and plot (maybe not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['Ipsi', 'Contra', 'Bino'] #ids.keys()\n",
    "stimDir_categories = ['StimDirs_Ipsi', 'StimDirs_Contra', 'StimDirs_Bino'] #ids.keys()\n",
    "stimID_categories = ['StimID_Ipsi', 'StimID_Contra', 'StimID_Bino'] #ids.keys()\n",
    "\n",
    "\n",
    "ncells = {}\n",
    "prestim = {}\n",
    "poststim = {}\n",
    "prestim_frames = {}\n",
    "poststim_frames = {}\n",
    "\n",
    "for idx, val in enumerate(exp):\n",
    "    ncells[idx] = F[idx].shape[0]\n",
    "    prestim[idx]  = 1 / (ids[idx]['framerate_auxderived']  / level) * 5 #seconds before stimulus\n",
    "    poststim[idx] = 1 / (ids[idx]['framerate_auxderived']  / level) * 5 #seconds after stimulus\n",
    "\n",
    "    prestim_frames[idx] = np.round(prestim[idx]  * (ids[idx]['framerate_auxderived']  / level))\n",
    "    poststim_frames[idx] = np.round(prestim[idx]  * (ids[idx]['framerate_auxderived']  / level))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "dataframe = []\n",
    "maxlength = np.empty(3 * len(exp))\n",
    "jump = 0;\n",
    "\n",
    "for idx, val in enumerate(exp):\n",
    "# allocate PSTH array\n",
    "    maxlength[jump + idx] = np.int(np.ceil(np.diff(ids[idx][\"Contra\"][:], axis = 0).mean() + prestim_frames[idx] + poststim_frames[idx]))\n",
    "    maxlength[jump + idx + 1 ] = np.int(np.ceil(np.diff(ids[idx][\"Ipsi\"][:], axis = 0).mean() + prestim_frames[idx] + poststim_frames[idx]))\n",
    "    maxlength[jump + idx + 2 ] = np.int(np.ceil(np.diff(ids[idx][\"Bino\"][:], axis = 0).mean() + prestim_frames[idx] + poststim_frames[idx]))\n",
    "    jump = jump + 2\n",
    "\n",
    "maxlength = np.int(np.max(maxlength))\n",
    "# for cell in tqdm(np.random.randint(0,ncells,5)):\n",
    "\n",
    "cellglob = 0\n",
    "data_dict = {}\n",
    "i = 0\n",
    "\n",
    "\n",
    "for idx, expval in enumerate(exp):\n",
    "    #print(cellglob)\n",
    "    for cell in notebook.tqdm(range(ncells[idx])):\n",
    "        cat = 0\n",
    "        for category in categories:            \n",
    "            for trial, val in enumerate(ids[idx][category][0]):\n",
    "                aligned_F = np.empty((1,maxlength)).squeeze()\n",
    "                aligned_F.fill(np.NaN)\n",
    "                aligned_Fneu = np.empty((1,maxlength)).squeeze()\n",
    "                aligned_Fneu.fill(np.NaN)\n",
    "                aligned_spks = np.empty((1,maxlength)).squeeze()\n",
    "                aligned_spks.fill(np.NaN)\n",
    "                aligned_stimdata = np.empty((1,maxlength)).squeeze()\n",
    "                aligned_stimdata.fill(np.NaN)\n",
    "                slice_range = np.arange(ids[idx][category][0][trial].astype(int)-prestim_frames[idx].astype(int),ids[idx][category][1][trial].astype(int)+poststim_frames[idx].astype(int))\n",
    "                aligned_stimdata[0:len(slice_range)] = auxdata[ids[idx]['FrameTimes_level'][slice_range],stimops['Stims_chan']]\n",
    "                aligned_F[0:len(slice_range)] = F[idx][cell,slice_range]\n",
    "                aligned_Fneu[0:len(slice_range)] = Fneu[idx][cell,slice_range]\n",
    "                aligned_spks[0:len(slice_range)] = spks[idx][cell,slice_range]\n",
    "\n",
    "                time = np.arange(0, aligned_F.shape[0] * 1 / (ids[idx]['framerate_auxderived'] / level), 1 / (ids[idx]['framerate_auxderived'] / level) ) - prestim[idx]\n",
    "                aux_time = np.arange(0, aligned_stimdata.shape[0] * 1 / (ids[idx]['framerate_auxderived'] / level), 1 / (ids[idx]['framerate_auxderived'] / level)  ) - prestim[idx]\n",
    "\n",
    "                layer = load_df[load_df['experiment'] == int(expval)]['Layer'].to_numpy(),\n",
    "\n",
    "                data_dict[i] = {\n",
    "                                        'experimentator': experimentator[0],\n",
    "                                        'mouse': mouse[0],\n",
    "                                        'date': date[0],\n",
    "                                        'experiment': experiment[0],\n",
    "                                        'cell': cellglob,\n",
    "                                        'layer': Layer[0],\n",
    "                                        'elevation': Elevation[0],\n",
    "                                        'time': time,\n",
    "                                        'auxtime':aux_time,\n",
    "                                        'aux_files': aux_files[0],\n",
    "                                        'aligned_stimdata': aligned_stimdata,\n",
    "                                        'trial':trial,\n",
    "                                        'Stimulus_direction': ids[idx][stimDir_categories[cat]][trial],\n",
    "                                        'Stimulus_ID': ids[idx][stimID_categories[cat]][trial],\n",
    "                                        'Number_of_stims': ids[idx]['NumStim'],\n",
    "                                        'Number_of_trials': ids[idx]['TotTrialNum'],\n",
    "                                        'aligned_F': aligned_F,\n",
    "                                        'aligned_spks': aligned_spks,\n",
    "                                        'aligned_Fneu': aligned_Fneu,\n",
    "                                        'category': category,\n",
    "                                        'adata_s2ppath': adata_s2ppath[0],\n",
    "                                        'SI_level': level,\n",
    "                                        'SI_zoom': zoom,\n",
    "                                        'SI_framerate': framerate,\n",
    "                                        'SI_framerate_aux_derived': ids[idx]['framerate_auxderived'][0],\n",
    "                                        'SI_channels': channels,\n",
    "                                        'SI_volumes': volumes,\n",
    "                                        'SI_frames': frames,\n",
    "                                        'SI_frames_per_file': frames_per_file,\n",
    "                                        'SI_tiffpath': adata_tiffpath[0],\n",
    "                                        'SI_single_tiff_file': single_tiff_file[0]\n",
    "                                        }\n",
    "                i += 1\n",
    "            cat += 1\n",
    "        cellglob += 1\n",
    "dataframe = pd.DataFrame.from_dict(data_dict, orient = 'index') #MUCH faster than df.append or df.concat! But it does not throw each timepoint in a different row\n",
    "# TODO\n",
    "# EXTRACT ODI SIG ETC HE`RE!\n",
    "# - include Fneu, dF/F (-Fneu), reconvolved\n",
    "# - functionalize\n",
    "# - aggregate over all recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdc7c04d822a410495a284ed81d45946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=892.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df070bdb1b394d569a54469c21a2ff3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=315.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "dataframe = []\n",
    "maxlength = np.empty(3 * len(exp))\n",
    "jump = 0;\n",
    "\n",
    "for idx, val in enumerate(exp):\n",
    "# allocate PSTH array\n",
    "    maxlength[jump + idx] = np.int(np.ceil(np.diff(ids[idx][\"Contra\"][:], axis = 0).mean() + prestim_frames[idx] + poststim_frames[idx]))\n",
    "    maxlength[jump + idx + 1 ] = np.int(np.ceil(np.diff(ids[idx][\"Ipsi\"][:], axis = 0).mean() + prestim_frames[idx] + poststim_frames[idx]))\n",
    "    maxlength[jump + idx + 2 ] = np.int(np.ceil(np.diff(ids[idx][\"Bino\"][:], axis = 0).mean() + prestim_frames[idx] + poststim_frames[idx]))\n",
    "    jump = jump + 2\n",
    "\n",
    "maxlength = np.int(np.max(maxlength))\n",
    "# for cell in tqdm(np.random.randint(0,ncells,5)):\n",
    "\n",
    "cellglob = 0\n",
    "data_dict = {}\n",
    "i = 0\n",
    "\n",
    "\n",
    "for idx, expval in enumerate(exp[0:2]):\n",
    "    #print(cellglob)\n",
    "    for cell in notebook.tqdm(range(ncells[idx])):\n",
    "        cat = 0\n",
    "        for category in categories:            \n",
    "            for trial, val in enumerate(ids[idx][category][0]):\n",
    "                aligned_F = np.empty((1,maxlength)).squeeze()\n",
    "                aligned_F.fill(np.NaN)\n",
    "                aligned_Fneu = np.empty((1,maxlength)).squeeze()\n",
    "                aligned_Fneu.fill(np.NaN)\n",
    "                aligned_spks = np.empty((1,maxlength)).squeeze()\n",
    "                aligned_spks.fill(np.NaN)\n",
    "                aligned_stimdata = np.empty((1,maxlength)).squeeze()\n",
    "                aligned_stimdata.fill(np.NaN)\n",
    "                slice_range = np.arange(ids[idx][category][0][trial].astype(int)-prestim_frames[idx].astype(int),ids[idx][category][1][trial].astype(int)+poststim_frames[idx].astype(int))\n",
    "                aligned_stimdata[0:len(slice_range)] = auxdata[ids[idx]['FrameTimes_level'][slice_range],stimops['Stims_chan']]\n",
    "                aligned_F[0:len(slice_range)] = F[idx][cell,slice_range]\n",
    "                aligned_Fneu[0:len(slice_range)] = Fneu[idx][cell,slice_range]\n",
    "                aligned_spks[0:len(slice_range)] = spks[idx][cell,slice_range]\n",
    "\n",
    "                time = np.arange(0, aligned_F.shape[0] * 1 / (ids[idx]['framerate_auxderived'] / level), 1 / (ids[idx]['framerate_auxderived'] / level) ) - prestim[idx]\n",
    "                aux_time = np.arange(0, aligned_stimdata.shape[0] * 1 / (ids[idx]['framerate_auxderived'] / level), 1 / (ids[idx]['framerate_auxderived'] / level)  ) - prestim[idx]\n",
    "\n",
    "                layer = load_df[load_df['experiment'] == int(expval)]['Layer'].to_numpy(),\n",
    "\n",
    "                dfs.append(pd.DataFrame({\n",
    "                                        'experimentator': experimentator[0],\n",
    "                                        'mouse': mouse[0],\n",
    "                                        'date': date[0],\n",
    "                                        'experiment': experiment[0],\n",
    "                                        'cell': cellglob,\n",
    "                                        'layer': Layer[0],\n",
    "                                        'elevation': Elevation[0],\n",
    "                                        'time': time,\n",
    "                                        'auxtime':aux_time,\n",
    "                                        'aux_files': aux_files[0],\n",
    "                                        'aligned_stimdata': aligned_stimdata,\n",
    "                                        'trial':trial,\n",
    "                                        'Stimulus_direction': ids[idx][stimDir_categories[cat]][trial],\n",
    "                                        'Stimulus_ID': ids[idx][stimID_categories[cat]][trial],\n",
    "                                        'Number_of_stims': ids[idx]['NumStim'],\n",
    "                                        'Number_of_trials': ids[idx]['TotTrialNum'],\n",
    "                                        'aligned_F': aligned_F,\n",
    "                                        'aligned_spks': aligned_spks,\n",
    "                                        'aligned_Fneu': aligned_Fneu,\n",
    "                                        'category': category,\n",
    "                                        'adata_s2ppath': adata_s2ppath[0],\n",
    "                                        'SI_level': level,\n",
    "                                        'SI_zoom': zoom,\n",
    "                                        'SI_framerate': framerate,\n",
    "                                        'SI_framerate_aux_derived': ids[idx]['framerate_auxderived'][0],\n",
    "                                        'SI_channels': channels,\n",
    "                                        'SI_volumes': volumes,\n",
    "                                        'SI_frames': frames,\n",
    "                                        'SI_frames_per_file': frames_per_file,\n",
    "                                        'SI_tiffpath': adata_tiffpath[0],\n",
    "                                        'SI_single_tiff_file': single_tiff_file[0]\n",
    "                                        }))\n",
    "                i += 1\n",
    "            cat += 1\n",
    "        cellglob += 1\n",
    "    #dataframe = pd.concat(dfs, axis=0)\n",
    "#dataframe = pd.DataFrame.from_dict(data_dict, orient = 'index') #MUCH faster than df.append or df.concat! But it does not throw each timepoint in a different row\n",
    "# TODO\n",
    "# - include Fneu, dF/F (-Fneu), reconvolved\n",
    "# - functionalize\n",
    "# - aggregate over all recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.concat(dfs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-3a9d35a5f7e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/miniconda3/envs/suite2p/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mfrom_dict\u001b[0;34m(cls, data, orient, dtype, columns)\u001b[0m\n\u001b[1;32m   1235\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m                 \u001b[0;31m# TODO speed up Series case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1237\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1238\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_from_nested_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "dataframe = pd.DataFrame.from_dict(dfs, 'index') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experimentator</th>\n",
       "      <th>mouse</th>\n",
       "      <th>date</th>\n",
       "      <th>experiment</th>\n",
       "      <th>cell</th>\n",
       "      <th>layer</th>\n",
       "      <th>elevation</th>\n",
       "      <th>time</th>\n",
       "      <th>auxtime</th>\n",
       "      <th>aux_files</th>\n",
       "      <th>aligned_stimdata</th>\n",
       "      <th>trial</th>\n",
       "      <th>Stimulus_direction</th>\n",
       "      <th>Stimulus_ID</th>\n",
       "      <th>Number_of_stims</th>\n",
       "      <th>Number_of_trials</th>\n",
       "      <th>aligned_F</th>\n",
       "      <th>aligned_spks</th>\n",
       "      <th>aligned_Fneu</th>\n",
       "      <th>category</th>\n",
       "      <th>adata_s2ppath</th>\n",
       "      <th>SI_level</th>\n",
       "      <th>SI_zoom</th>\n",
       "      <th>SI_framerate</th>\n",
       "      <th>SI_framerate_aux_derived</th>\n",
       "      <th>SI_channels</th>\n",
       "      <th>SI_volumes</th>\n",
       "      <th>SI_frames</th>\n",
       "      <th>SI_frames_per_file</th>\n",
       "      <th>SI_tiffpath</th>\n",
       "      <th>SI_single_tiff_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>David Laubender</td>\n",
       "      <td>DL_191024_6</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>62283</td>\n",
       "      <td>0</td>\n",
       "      <td>L1</td>\n",
       "      <td>positive degrees</td>\n",
       "      <td>-0.6560</td>\n",
       "      <td>-0.6560</td>\n",
       "      <td>/Volumes/David Laubender/Data/imaging data/DL_...</td>\n",
       "      <td>0.010850</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>96.865204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.069138</td>\n",
       "      <td>Ipsi</td>\n",
       "      <td>/Volumes/David Laubender/Data/imaging data/DL_...</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>30.487805</td>\n",
       "      <td>1</td>\n",
       "      <td>19000</td>\n",
       "      <td>19000</td>\n",
       "      <td>500</td>\n",
       "      <td>/Volumes/David Laubender/Data/imaging data/DL_...</td>\n",
       "      <td>/Volumes/David Laubender/Data/imaging data/DL_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>David Laubender</td>\n",
       "      <td>DL_191024_6</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>62283</td>\n",
       "      <td>0</td>\n",
       "      <td>L1</td>\n",
       "      <td>positive degrees</td>\n",
       "      <td>-0.5248</td>\n",
       "      <td>-0.5248</td>\n",
       "      <td>/Volumes/David Laubender/Data/imaging data/DL_...</td>\n",
       "      <td>0.011816</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>107.142532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.355553</td>\n",
       "      <td>Ipsi</td>\n",
       "      <td>/Volumes/David Laubender/Data/imaging data/DL_...</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>30.487805</td>\n",
       "      <td>1</td>\n",
       "      <td>19000</td>\n",
       "      <td>19000</td>\n",
       "      <td>500</td>\n",
       "      <td>/Volumes/David Laubender/Data/imaging data/DL_...</td>\n",
       "      <td>/Volumes/David Laubender/Data/imaging data/DL_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Laubender</td>\n",
       "      <td>DL_191024_6</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>62283</td>\n",
       "      <td>0</td>\n",
       "      <td>L1</td>\n",
       "      <td>positive degrees</td>\n",
       "      <td>-0.3936</td>\n",
       "      <td>-0.3936</td>\n",
       "      <td>/Volumes/David Laubender/Data/imaging data/DL_...</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>85.735123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.190132</td>\n",
       "      <td>Ipsi</td>\n",
       "      <td>/Volumes/David Laubender/Data/imaging data/DL_...</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>30.487805</td>\n",
       "      <td>1</td>\n",
       "      <td>19000</td>\n",
       "      <td>19000</td>\n",
       "      <td>500</td>\n",
       "      <td>/Volumes/David Laubender/Data/imaging data/DL_...</td>\n",
       "      <td>/Volumes/David Laubender/Data/imaging data/DL_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>David Laubender</td>\n",
       "      <td>DL_191024_6</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>62283</td>\n",
       "      <td>0</td>\n",
       "      <td>L1</td>\n",
       "      <td>positive degrees</td>\n",
       "      <td>-0.2624</td>\n",
       "      <td>-0.2624</td>\n",
       "      <td>/Volumes/David Laubender/Data/imaging data/DL_...</td>\n",
       "      <td>0.011816</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>70.549423</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.069141</td>\n",
       "      <td>Ipsi</td>\n",
       "      <td>/Volumes/David Laubender/Data/imaging data/DL_...</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>30.487805</td>\n",
       "      <td>1</td>\n",
       "      <td>19000</td>\n",
       "      <td>19000</td>\n",
       "      <td>500</td>\n",
       "      <td>/Volumes/David Laubender/Data/imaging data/DL_...</td>\n",
       "      <td>/Volumes/David Laubender/Data/imaging data/DL_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>David Laubender</td>\n",
       "      <td>DL_191024_6</td>\n",
       "      <td>2019-12-01</td>\n",
       "      <td>62283</td>\n",
       "      <td>0</td>\n",
       "      <td>L1</td>\n",
       "      <td>positive degrees</td>\n",
       "      <td>-0.1312</td>\n",
       "      <td>-0.1312</td>\n",
       "      <td>/Volumes/David Laubender/Data/imaging data/DL_...</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>78.950951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.676540</td>\n",
       "      <td>Ipsi</td>\n",
       "      <td>/Volumes/David Laubender/Data/imaging data/DL_...</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>30.487805</td>\n",
       "      <td>1</td>\n",
       "      <td>19000</td>\n",
       "      <td>19000</td>\n",
       "      <td>500</td>\n",
       "      <td>/Volumes/David Laubender/Data/imaging data/DL_...</td>\n",
       "      <td>/Volumes/David Laubender/Data/imaging data/DL_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    experimentator        mouse        date experiment  cell layer  \\\n",
       "0  David Laubender  DL_191024_6  2019-12-01      62283     0    L1   \n",
       "1  David Laubender  DL_191024_6  2019-12-01      62283     0    L1   \n",
       "2  David Laubender  DL_191024_6  2019-12-01      62283     0    L1   \n",
       "3  David Laubender  DL_191024_6  2019-12-01      62283     0    L1   \n",
       "4  David Laubender  DL_191024_6  2019-12-01      62283     0    L1   \n",
       "\n",
       "          elevation    time  auxtime  \\\n",
       "0  positive degrees -0.6560  -0.6560   \n",
       "1  positive degrees -0.5248  -0.5248   \n",
       "2  positive degrees -0.3936  -0.3936   \n",
       "3  positive degrees -0.2624  -0.2624   \n",
       "4  positive degrees -0.1312  -0.1312   \n",
       "\n",
       "                                           aux_files  aligned_stimdata  trial  \\\n",
       "0  /Volumes/David Laubender/Data/imaging data/DL_...          0.010850      0   \n",
       "1  /Volumes/David Laubender/Data/imaging data/DL_...          0.011816      0   \n",
       "2  /Volumes/David Laubender/Data/imaging data/DL_...          0.011494      0   \n",
       "3  /Volumes/David Laubender/Data/imaging data/DL_...          0.011816      0   \n",
       "4  /Volumes/David Laubender/Data/imaging data/DL_...          0.011494      0   \n",
       "\n",
       "   Stimulus_direction  Stimulus_ID  Number_of_stims  Number_of_trials  \\\n",
       "0                90.0            3               12                 6   \n",
       "1                90.0            3               12                 6   \n",
       "2                90.0            3               12                 6   \n",
       "3                90.0            3               12                 6   \n",
       "4                90.0            3               12                 6   \n",
       "\n",
       "    aligned_F  aligned_spks  aligned_Fneu category  \\\n",
       "0   96.865204           0.0     40.069138     Ipsi   \n",
       "1  107.142532           0.0     49.355553     Ipsi   \n",
       "2   85.735123           0.0     41.190132     Ipsi   \n",
       "3   70.549423           0.0     49.069141     Ipsi   \n",
       "4   78.950951           0.0     44.676540     Ipsi   \n",
       "\n",
       "                                       adata_s2ppath  SI_level  SI_zoom  \\\n",
       "0  /Volumes/David Laubender/Data/imaging data/DL_...         4       25   \n",
       "1  /Volumes/David Laubender/Data/imaging data/DL_...         4       25   \n",
       "2  /Volumes/David Laubender/Data/imaging data/DL_...         4       25   \n",
       "3  /Volumes/David Laubender/Data/imaging data/DL_...         4       25   \n",
       "4  /Volumes/David Laubender/Data/imaging data/DL_...         4       25   \n",
       "\n",
       "   SI_framerate  SI_framerate_aux_derived  SI_channels  SI_volumes  SI_frames  \\\n",
       "0            30                 30.487805            1       19000      19000   \n",
       "1            30                 30.487805            1       19000      19000   \n",
       "2            30                 30.487805            1       19000      19000   \n",
       "3            30                 30.487805            1       19000      19000   \n",
       "4            30                 30.487805            1       19000      19000   \n",
       "\n",
       "   SI_frames_per_file                                        SI_tiffpath  \\\n",
       "0                 500  /Volumes/David Laubender/Data/imaging data/DL_...   \n",
       "1                 500  /Volumes/David Laubender/Data/imaging data/DL_...   \n",
       "2                 500  /Volumes/David Laubender/Data/imaging data/DL_...   \n",
       "3                 500  /Volumes/David Laubender/Data/imaging data/DL_...   \n",
       "4                 500  /Volumes/David Laubender/Data/imaging data/DL_...   \n",
       "\n",
       "                                 SI_single_tiff_file  \n",
       "0  /Volumes/David Laubender/Data/imaging data/DL_...  \n",
       "1  /Volumes/David Laubender/Data/imaging data/DL_...  \n",
       "2  /Volumes/David Laubender/Data/imaging data/DL_...  \n",
       "3  /Volumes/David Laubender/Data/imaging data/DL_...  \n",
       "4  /Volumes/David Laubender/Data/imaging data/DL_...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save dataframe here\n",
    "dataframe.to_pickle('layer1_and_4_mac_grat_all.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPLODING to single line - SLOW!\n",
    "dataframe = dataframe.apply(pd.Series.explode).reset_index(drop=True) #exploding this takes time, though..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save dataframe here\n",
    "dataframe.to_pickle('layer1_and_4_mac_grat_exp_all_slow.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save stim Ids here\n",
    "with open('Grat_ids_new.pkl', 'wb') as handle:\n",
    "    pickle.dump(ids, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boilerplate cells to play around with panda extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe[(dataframe['category'] == 'Ipsi') & (dataframe['Stimulus_ID'] == 12) & (dataframe['cell'] == 0)].aligned_spks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp[(['category'] == 'Ipsi') & (['Stimulus_ID'] == 1)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp[(exp['category'] == 'Bino') & (exp['cell'] == 20) & (exp['Stimulus_ID'] == 3) ].aligned_spks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp[exp[(['category'] == 'Ipsi') & (['Stimulus_ID'] == '1')]].groupby(['time', 'cell'], as_index=False).aligned_spks.mean().pivot(index = 'time', columns='cell').mean(axis = 1).plot()\n",
    "plt.subplot(2,3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allcells_Ipsi_mean = dataframe[dataframe['category'] == 'Ipsi']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe[(dataframe['category'] == 'Ipsi') & (dataframe['Stimulus_ID'] == 1) & (dataframe['cell'] == 0).ipynb_checkpoints/.gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'Simple' one-liners to get trial averages over all cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe[(['category'] == 'Ipsi') & (['Stimulus_ID'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe[(dataframe['category'] == 'Ipsi') & (dataframe['Stimulus_ID'] == '1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe[dataframe['Stimulus_ID'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['Stimulus_ID'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp[exp['category'] == 'Ipsi'].groupby(['time', 'cell'], as_index=False).aligned_spks.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allcells_Ipsi_mean = exp.loc[exp.loc[:,'category'] == 'Ipsi'].groupby(['time', 'cell'], as_index=False).aligned_spks.mean().pivot(index = 'time', columns='cell')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.subplot(2,3,1)\n",
    "dataframe[dataframe[([:,'category'] == 'Ipsi') & ([:,'Stimulus_ID'] == '1')]].groupby(['time', 'cell'], as_index=False).aligned_spks.mean().pivot(index = 'time', columns='cell').mean(axis = 1).plot()\n",
    "plt.subplot(2,3,2)\n",
    "dataframe.loc[dataframe.loc[:,'category'] == 'Contra'].groupby(['time', 'cell'], as_index=False).aligned_spks.mean().pivot(index = 'time', columns='cell').mean(axis = 1).plot()\n",
    "plt.subplot(2,3,3)\n",
    "dataframe.loc[dataframe.loc[:,'category'] == 'Bino'].groupby(['time', 'cell'], as_index=False).aligned_spks.mean().pivot(index = 'time', columns='cell').mean(axis = 1).plot()\n",
    "plt.subplot(2,3,4)\n",
    "dataframe.loc[dataframe.loc[:,'category'] == 'Ipsi'].groupby(['time', 'cell'], as_index=False).aligned_F.mean().pivot(index = 'time', columns='cell').mean(axis = 1).plot()\n",
    "plt.subplot(2,3,5)\n",
    "dataframe.loc[dataframe.loc[:,'category'] == 'Contra'].groupby(['time', 'cell'], as_index=False).aligned_F.mean().pivot(index = 'time', columns='cell').mean(axis = 1).plot()\n",
    "plt.subplot(2,3,6)\n",
    "dataframe.loc[dataframe.loc[:,'category'] == 'Bino'].groupby(['time', 'cell'], as_index=False).aligned_F.mean().pivot(index = 'time', columns='cell').mean(axis = 1).plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate sorted mean-cell responses / zscores or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate sorted mean-cell responses / zscores or not\n",
    "\n",
    "allcells_Ipsi_mean = dataframe.loc[dataframe.loc[:,'category'] == 'Ipsi'].groupby(['time', 'cell'], as_index=False).aligned_spks.mean().pivot(index = 'time', columns='cell')\n",
    "allcells_Ipsi_mean_zscored = allcells_Ipsi_mean.transform((lambda x : z_score(x)))\n",
    "sortidx = allcells_Ipsi_mean_zscored.max().sort_values(ascending=False).index\n",
    "allcells_Ipsi_mean_sort_zscored = allcells_Ipsi_mean_zscored.reindex(sortidx, axis = 1)\n",
    "\n",
    "allcells_Contra_mean = dataframe.loc[dataframe.loc[:,'category'] == 'Contra'].groupby(['time', 'cell'], as_index=False).aligned_spks.mean().pivot(index = 'time', columns='cell')\n",
    "allcells_Contra_mean_zscored = allcells_Contra_mean.transform((lambda x : z_score(x)))\n",
    "sortidx = allcells_Contra_mean_zscored.max().sort_values(ascending=False).index\n",
    "allcells_Contra_mean_sort_zscored = allcells_Contra_mean_zscored.reindex(sortidx, axis = 1)\n",
    "\n",
    "allcells_Bino_mean = dataframe.loc[dataframe.loc[:,'category'] == 'Bino'].groupby(['time', 'cell'], as_index=False).aligned_spks.mean().pivot(index = 'time', columns='cell')\n",
    "allcells_Bino_mean_zscored = allcells_Bino_mean.transform((lambda x : z_score(x)))\n",
    "sortidx = allcells_Bino_mean_zscored.max().sort_values(ascending=False).index\n",
    "allcells_Bino_mean_sort_zscored = allcells_Bino_mean_zscored.reindex(sortidx, axis = 1)\n",
    "\n",
    "\n",
    "allcells_Ipsi_mean = dataframe.loc[dataframe.loc[:,'category'] == 'Ipsi'].groupby(['time', 'cell'], as_index=False).aligned_spks.mean().pivot(index = 'time', columns='cell')\n",
    "sortidx2 = allcells_Ipsi_mean.max().sort_values(ascending=False).index\n",
    "allcells_Ipsi_mean_sort = allcells_Ipsi_mean.reindex(sortidx2, axis = 1)\n",
    "\n",
    "allcells_Contra_mean = dataframe.loc[dataframe.loc[:,'category'] == 'Contra'].groupby(['time', 'cell'], as_index=False).aligned_spks.mean().pivot(index = 'time', columns='cell')\n",
    "sortidx2 = allcells_Contra_mean.max().sort_values(ascending=False).index\n",
    "allcells_Contra_mean_sort = allcells_Contra_mean.reindex(sortidx2, axis = 1)\n",
    "\n",
    "allcells_Bino_mean = dataframe.loc[dataframe.loc[:,'category'] == 'Bino'].groupby(['time', 'cell'], as_index=False).aligned_spks.mean().pivot(index = 'time', columns='cell')\n",
    "sortidx2 = allcells_Bino_mean.max().sort_values(ascending=False).index\n",
    "allcells_Bino_mean_sort = allcells_Bino_mean.reindex(sortidx2, axis = 1)\n",
    "\n",
    "\n",
    "# allcells_Ipsi_mean = dataframe.loc[dataframe.loc[:,'category'] == 'Ipsi'].groupby(['time', 'cell'], as_index=False).aligned_F.mean().pivot(index = 'time', columns='cell')\n",
    "# allcells_Ipsi_mean_zscored = allcells_Ipsi_mean.transform((lambda x : z_score(x)))\n",
    "# sortidx = allcells_Ipsi_mean_zscored.max().sort_values(ascending=False).index\n",
    "# allcells_Ipsi_mean_sort_zscored = allcells_Ipsi_mean_zscored.reindex(sortidx, axis = 1)\n",
    "\n",
    "# allcells_Contra_mean = dataframe.loc[dataframe.loc[:,'category'] == 'Contra'].groupby(['time', 'cell'], as_index=False).aligned_F.mean().pivot(index = 'time', columns='cell')\n",
    "# allcells_Contra_mean_zscored = allcells_Contra_mean.transform((lambda x : z_score(x)))\n",
    "# sortidx = allcells_Contra_mean_zscored.max().sort_values(ascending=False).index\n",
    "# allcells_Contra_mean_sort_zscored = allcells_Contra_mean_zscored.reindex(sortidx, axis = 1)\n",
    "\n",
    "# allcells_Bino_mean = dataframe.loc[dataframe.loc[:,'category'] == 'Bino'].groupby(['time', 'cell'], as_index=False).aligned_F.mean().pivot(index = 'time', columns='cell')\n",
    "# allcells_Bino_mean_zscored = allcells_Bino_mean.transform((lambda x : z_score(x)))\n",
    "# sortidx = allcells_Bino_mean_zscored.max().sort_values(ascending=False).index\n",
    "# allcells_Bino_mean_sort_zscored = allcells_Bino_mean_zscored.reindex(sortidx, axis = 1)\n",
    "\n",
    "\n",
    "# allcells_Ipsi_mean = dataframe.loc[dataframe.loc[:,'category'] == 'Ipsi'].groupby(['time', 'cell'], as_index=False).aligned_F.mean().pivot(index = 'time', columns='cell')\n",
    "# sortidx2 = allcells_Ipsi_mean.max().sort_values(ascending=False).index\n",
    "# allcells_Ipsi_mean_sort = allcells_Ipsi_mean.reindex(sortidx2, axis = 1)\n",
    "\n",
    "# allcells_Contra_mean = dataframe.loc[dataframe.loc[:,'category'] == 'Contra'].groupby(['time', 'cell'], as_index=False).aligned_F.mean().pivot(index = 'time', columns='cell')\n",
    "# sortidx2 = allcells_Contra_mean.max().sort_values(ascending=False).index\n",
    "# allcells_Contra_mean_sort = allcells_Contra_mean.reindex(sortidx2, axis = 1)\n",
    "\n",
    "# allcells_Bino_mean = dataframe.loc[dataframe.loc[:,'category'] == 'Bino'].groupby(['time', 'cell'], as_index=False).aligned_F.mean().pivot(index = 'time', columns='cell')\n",
    "# allcells_Bino_mean_zscored = allcells_Bino_mean.transform((lambda x : z_score(x)))\n",
    "# sortidx2 = allcells_Bino_mean.max().sort_values(ascending=False).index\n",
    "# allcells_Bino_mean_sort = allcells_Bino_mean.reindex(sortidx2, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot maps\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "\n",
    "with sns.axes_style('white'):\n",
    "    plt.subplot(2,3,1)\n",
    "    plt.imshow(allcells_Ipsi_mean_sort_zscored.T, vmax = 3, vmin = -0.5, aspect = 'auto', cmap = 'Reds')\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('bouton')\n",
    "    plt.title('Ipsi')\n",
    "    plt.vlines([prestim_frames[idx], maxlength - poststim_frames[idx]],0,ncells-1, 'k')\n",
    "    \n",
    "    plt.subplot(2,3,2)\n",
    "    plt.imshow(allcells_Contra_mean_sort_zscored.T, vmax = 3, vmin = -0.5, aspect = 'auto', cmap = 'Blues')\n",
    "    plt.xlabel('time')\n",
    "    plt.title('Contra')\n",
    "    plt.vlines([prestim_frames[idx], maxlength - poststim_frames[idx]],0,ncells-1, 'k')\n",
    "        \n",
    "    plt.subplot(2,3,3)\n",
    "    plt.imshow(allcells_Bino_mean_sort_zscored.T, vmax = 3, vmin = -0.5, aspect = 'auto', cmap = 'gray_r')\n",
    "    plt.xlabel('time [s]')\n",
    "    plt.colorbar(label='zscore')\n",
    "    plt.title('Bino')\n",
    "    plt.vlines([prestim_frames[idx], maxlength - poststim_frames[idx]],0,ncells-1, 'k')\n",
    "    \n",
    "    plt.subplot(2,3,4)\n",
    "    plt.imshow(allcells_Ipsi_mean_sort.T, vmax = 4, vmin = -.5, aspect = 'auto', cmap = 'Reds')\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('bouton')\n",
    "    plt.title('Ipsi')\n",
    "    plt.vlines([prestim_frames[idx], maxlength - poststim_frames[idx]],0,ncells-1, 'k')\n",
    "    \n",
    "    plt.subplot(2,3,5)\n",
    "    plt.imshow(allcells_Contra_mean_sort.T, vmax = 4, vmin = -.5, aspect = 'auto', cmap = 'Blues')\n",
    "    plt.xlabel('time')\n",
    "    plt.title('Contra')\n",
    "    plt.vlines([prestim_frames[idx], maxlength - poststim_frames[idx]],0,ncells-1, 'k')\n",
    "    \n",
    "    plt.subplot(2,3,6)\n",
    "    plt.imshow(allcells_Bino_mean_sort.T, vmax = 4, vmin = -.5, aspect = 'auto', cmap = 'gray_r')\n",
    "    plt.xlabel('time [s]')\n",
    "    plt.title('Bino')\n",
    "    plt.colorbar(label='deconvolved F [a.u.]')\n",
    "    plt.vlines([prestim_frames[idx], maxlength - poststim_frames[idx]],0,ncells-1, 'k')\n",
    "    \n",
    "    \n",
    "    \n",
    "#     plt.subplot(2,3,4)\n",
    "#     plt.imshow(allcells_Ipsi_mean_sort.T, vmax = 150, vmin = 30, aspect = 'auto', cmap = 'Reds')\n",
    "#     plt.xlabel('time')\n",
    "#     plt.ylabel('bouton')\n",
    "#     plt.title('Ipsi')\n",
    "#     plt.vlines([prestim_frames, maxlength - poststim_frames],0,ncells-1, 'k')\n",
    "    \n",
    "#     plt.subplot(2,3,5)\n",
    "#     plt.imshow(allcells_Contra_mean_sort.T, vmax = 150, vmin = 30, aspect = 'auto', cmap = 'Blues')\n",
    "#     plt.xlabel('time')\n",
    "#     plt.title('Contra')\n",
    "#     plt.vlines([prestim_frames, maxlength - poststim_frames],0,ncells-1, 'k')\n",
    "    \n",
    "#     plt.subplot(2,3,6)\n",
    "#     plt.imshow(allcells_Bino_mean_sort.T, vmax = 150, vmin = 30, aspect = 'auto', cmap = 'gray_r')\n",
    "#     plt.xlabel('time [s]')\n",
    "#     plt.title('Bino')\n",
    "#     plt.colorbar(label='F')\n",
    "#     plt.vlines([prestim_frames, maxlength - poststim_frames],0,ncells-1, 'k')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rastermap sortings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all cells\n",
    "sp_ipsi = allcells_Ipsi_mean_zscored.to_numpy()\n",
    "sp_contra = allcells_Contra_mean_zscored.to_numpy()\n",
    "sp_bino = allcells_Bino_mean_zscored.to_numpy()\n",
    "\n",
    "sp_all = np.concatenate((allcells_Contra_mean.to_numpy(), allcells_Ipsi_mean.to_numpy(), allcells_Bino_mean.to_numpy()), axis = 0)\n",
    "\n",
    "sp_ipsi[np.isnan(sp_ipsi)] = 0\n",
    "sp_contra[np.isnan(sp_contra)] = 0\n",
    "sp_bino[np.isnan(sp_bino)] = 0\n",
    "\n",
    "sp_all[np.isnan(sp_all)] = 0\n",
    "\n",
    "sp_all = zscore(sp_all) # needs to be done in numpy to be element-wise here - I collapsed the major categories. I dont think I can do that in pandas straight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "model_ipsi = rm.mapping.Rastermap(n_components=1).fit(sp_ipsi.T)\n",
    "model_contra = rm.mapping.Rastermap(n_components=1).fit(sp_contra.T)\n",
    "model_bino = rm.mapping.Rastermap(n_components=1).fit(sp_bino.T)\n",
    "model_all = rm.mapping.Rastermap(n_components=1).fit(sp_all.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### sort neurons and smooth across neurons \n",
    "smooth = False\n",
    "timesmooth = False\n",
    "\n",
    "if smooth:\n",
    "    isort = np.argsort(model_all.embedding[:,0])   \n",
    "    Sm_ipsi = gaussian_filter1d(sp_ipsi.T[isort,:], np.minimum(3,int(sp_ipsi.shape[0]*0.005)), axis=0)\n",
    "    # isort = np.argsort(model_contra.embedding[:,0])\n",
    "    Sm_contra = gaussian_filter1d(sp_contra.T[isort,:], np.minimum(3,int(sp_contra.shape[0]*0.005)), axis=0)\n",
    "    # isort = np.argsort(model_bino.embedding[:,0])\n",
    "    Sm_bino = gaussian_filter1d(sp_bino.T[isort,:], np.minimum(3,int(sp_bino.shape[0]*0.005)), axis=0)\n",
    "    Sm_all  = gaussian_filter1d(sp_all.T[isort,:], np.minimum(3,int(sp_ipsi.shape[0]*0.005)), axis=0)\n",
    "#     Sm_all= sp_all.T[isort,:]\n",
    "else:\n",
    "    isort = np.argsort(model_bino.embedding[:,0])\n",
    "    Sm_ipsi = sp_ipsi.T[isort,:]\n",
    "    # isort = np.argsort(model_contra.embedding[:,0])\n",
    "    Sm_contra = sp_contra.T[isort,:]\n",
    "    # isort = np.argsort(model_bino.embedding[:,0])\n",
    "    Sm_bino = sp_bino.T[isort,:]\n",
    "    Sm_all  = sp_all.T[isort,:]\n",
    "    \n",
    "if timesmooth:\n",
    "    sigma = 0.5\n",
    "# (optional) smooth in time\n",
    "    Sm_contra = gaussian_filter1d(Sm_contra, sigma, axis=1)\n",
    "    Sm_ipsi = gaussian_filter1d(Sm_ipsi, sigma, axis=1)\n",
    "    Sm_bino = gaussian_filter1d(Sm_bino, sigma, axis=1)\n",
    "    Sm_all = gaussian_filter1d(Sm_all, sigma, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### auxdata and timebase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_range = np.arange(ids[0]['Ipsi'][0][1].astype(int)-prestim_frames[0].astype(int),ids[0]['Ipsi'][1][1].astype(int)+poststim_frames[0].astype(int)+1)\n",
    "# slice_range = np.arange(ids[category][0][trial].astype(int)-prestim_frames.astype(int),ids[category][1][trial].astype(int)+poststim_frames.astype(int))\n",
    "\n",
    "aligned_stimdata = auxdata[ids[0]['FrameTimes_level'][slice_range],stimops['Stims_chan']]\n",
    "# aligned_stimdata_concat = np.tile(auxdata[ids['FrameTimes_level'][slice_range],stimops['Stims_chan']], (0,3))\n",
    "aux_time = np.arange(0, aligned_stimdata.shape[0] * 1 / (ids[0]['framerate_auxderived'] / level), 1 / (ids[0]['framerate_auxderived'] / level) ) - prestim[0]\n",
    "\n",
    "aligned_stimdata_full = ids[0]['auxdata'][ids[0]['FrameTimes_level'][slice_range[0]]:ids[0]['FrameTimes_level'][slice_range[-1]],stimops['Stims_chan']]\n",
    "aligned_stimdata_full_concat = np.tile(aligned_stimdata_full, (1,3)).T\n",
    "\n",
    "aux_time_full = np.arange(0, aligned_stimdata_full.shape[0] * 1 / ids[0]['aux_samplingfreq'] , 1 / ids[0]['aux_samplingfreq']    ) - prestim[0]\n",
    "aux_time_full_concat = np.arange(0, aligned_stimdata_full_concat.shape[0] * 1 / ids[0]['aux_samplingfreq'] , 1 / ids[0]['aux_samplingfreq']   ) - prestim[0]\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(aux_time, aligned_stimdata)\n",
    "# plt.plot(aux_time_full_concat, aligned_stimdata_full_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seperately sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### view neuron sorting\n",
    "\n",
    "# aligned_stimdata = auxdata[ids['FrameTimes_level'][slice_range][0]:ids['FrameTimes_level'][slice_range][-1],stimops['Stims_chan']]\n",
    "# aux_time = np.arange(0, aligned_stimdata.shape[0] * 1 / aux_samplingfreq, 1 / aux_samplingfreq  ) - prestim\n",
    "\n",
    "fs = ids[0]['framerate_auxderived'] / level\n",
    "vmin_glob = -.5\n",
    "vmax_glob = 2.5\n",
    "ncells = cellglob \n",
    "with sns.axes_style('white'):\n",
    "    xl = [-prestim[0],Sm_contra.shape[1]/fs-prestim[0]]\n",
    "    \n",
    "    fig8 = plt.figure(figsize=(20,16), constrained_layout=True)\n",
    "    gs1 = fig8.add_gridspec(nrows=8, ncols=3)\n",
    "    \n",
    "    fig8.add_subplot(gs1[1:, :-2])      \n",
    "    fig8_ax=plt.imshow(Sm_contra, vmin=vmin_glob,vmax=vmax_glob,aspect='auto',extent=[-prestim[0],Sm_contra.shape[1]/fs-prestim[0], 0,Sm_contra.shape[0]], cmap = 'Blues')\n",
    "    plt.xlabel('time (s)', fontsize=18)    \n",
    "    \n",
    "    plt.vlines([prestim_frames[0] / fs-prestim[0], maxlength / fs - poststim_frames[0] / fs -prestim[0] ],0,ncells-1, 'k')\n",
    "    plt.ylabel('boutons', fontsize=18)     \n",
    "        \n",
    "    f8_ax2 = fig8.add_subplot(gs1[1:, 1:-1])\n",
    "    ax=plt.imshow(Sm_ipsi, vmin=vmin_glob,vmax=vmax_glob,aspect='auto',extent=[-prestim[0],Sm_ipsi.shape[1]/fs-prestim[0], 0,Sm_ipsi.shape[0]], cmap = 'Reds')\n",
    "    plt.xlabel('time (s)', fontsize=18)\n",
    "    \n",
    "    plt.vlines([prestim_frames[0] / fs-prestim[0], maxlength / fs - poststim_frames[0] / fs -prestim[0] ],0,ncells-1, 'k')\n",
    "        \n",
    "    f8_ax3 = fig8.add_subplot(gs1[1:, 2:])\n",
    "    ax=plt.imshow(Sm_bino, vmin=vmin_glob,vmax=vmax_glob,aspect='auto',extent=[-prestim[0],Sm_bino.shape[1]/fs-prestim[0], 0,Sm_bino.shape[0]], cmap = 'gray_r')\n",
    "    plt.xlabel('time (s)', fontsize=18)\n",
    "    \n",
    "    plt.vlines([prestim_frames[0] / fs-prestim[0], maxlength / fs - poststim_frames[0] / fs -prestim[0]],0,ncells-1, 'k')\n",
    "\n",
    "#    plt.colorbar(label='deconvolved F [a.u.]')\n",
    "   \n",
    "    f8_ax4 = fig8.add_subplot(gs1[:1, :-2])    \n",
    "    plt.plot(aux_time_full, aligned_stimdata_full, 'k')\n",
    "#     plt.vlines([prestim_frames / fs-prestim, maxlength / fs - poststim_frames / fs -prestim],0,4, 'k')\n",
    "    f8_ax4.set_xlim(*xl)\n",
    "    f8_ax4.axis('off')\n",
    "    plt.title('Contra')\n",
    "    \n",
    "    f8_ax5 = fig8.add_subplot(gs1[:1, 1:-1])\n",
    "    plt.plot(aux_time_full, aligned_stimdata_full, 'k')\n",
    "    f8_ax5.set_xlim(*xl)\n",
    "    f8_ax5.axis('off')\n",
    "    plt.title('Ipsi')\n",
    "\n",
    "    \n",
    "    f8_ax6 = fig8.add_subplot(gs1[:1, 2:])\n",
    "    plt.plot(aux_time_full, aligned_stimdata_full, 'k')\n",
    "    f8_ax6.set_xlim(*xl)\n",
    "    f8_ax6.axis('off')\n",
    "    plt.title('Bino')    \n",
    "    \n",
    "#     plt.tight_layout()           \n",
    "    plt.suptitle('z-scored deconvolved Chirp PSTHs - rastermap embedding (sorted on Bino, smoothened over boutons) - exp' + exp[0])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('separate.eps', format='eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concatenated figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### view neuron sorting\n",
    "\n",
    "# aligned_stimdata = auxdata[ids['FrameTimes_level'][slice_range][0]:ids['FrameTimes_level'][slice_range][-1],stimops['Stims_chan']]\n",
    "# aux_time = np.arange(0, aligned_stimdata.shape[0] * 1 / aux_samplingfreq, 1 / aux_samplingfreq  ) - prestim\n",
    "\n",
    "fs = ids[0]['framerate_auxderived'] / level\n",
    "vmin_glob = -.5\n",
    "vmax_glob = 2.5\n",
    "\n",
    "with sns.axes_style('white'):\n",
    "    xl = [-prestim[0],Sm_all.shape[1]/fs - prestim[0]]\n",
    "    \n",
    "    fig9 = plt.figure(figsize=(20,20), constrained_layout=True)\n",
    "    \n",
    "    gs1 = fig9.add_gridspec(nrows=12, ncols=3)\n",
    "    \n",
    "    fig9.add_subplot(gs1[1:, :])      \n",
    "    fig9_ax=plt.imshow(Sm_all, vmin=vmin_glob,vmax=vmax_glob,aspect='auto',extent=[-prestim[0],Sm_all.shape[1]/fs-prestim[0], 0,Sm_all.shape[0]], cmap = 'gray_r')\n",
    "    plt.xlabel('time (s)', fontsize=18)    \n",
    "    \n",
    "#     plt.vlines([prestim_frames / fs-prestim, maxlength / fs - poststim_frames / fs -prestim ],0,ncells-1, 'k')\n",
    "    plt.ylabel('boutons', fontsize=18)     \n",
    "    \n",
    "    plt.vlines([aux_time_full[-1],  +aux_time_full[-1] *2 + poststim[0]],0,ncells-1, 'r')\n",
    "    plt.vlines([prestim_frames[0] / fs-prestim[0], maxlength / fs - poststim_frames[0] / fs -prestim[0]],0,ncells-1, 'b')\n",
    "    \n",
    "    plt.vlines([aux_time_full[-1] + (prestim_frames[0] / fs),  aux_time_full[-1] + (maxlength / fs - poststim_frames[0] / fs ) ],0,ncells-1, 'b')\n",
    "    plt.vlines([2 * aux_time_full[-1] + (prestim_frames[0] / fs) + prestim[0],  2 * aux_time_full[-1] + (maxlength / fs - poststim_frames[0] / fs ) + prestim[0]],0,ncells-1, 'b')\n",
    "#     plt.plot(aux_time_full_concat, aligned_stimdata_full_concat, 'k')\n",
    "    \n",
    "#     plt.colorbar(label='deconvolved F [zscored]')\n",
    "#     plt.colorbar(label='deconvolved F [a.u.]')\n",
    "   \n",
    "    f9_ax4 = fig9.add_subplot(gs1[:1, :])    \n",
    "    plt.plot(aux_time_full_concat, aligned_stimdata_full_concat, 'k')\n",
    "#     plt.vlines([prestim_frames / fs-prestim, maxlength / fs - poststim_frames / fs -prestim],0,4, 'k')\n",
    "    f9_ax4.set_xlim(*xl)\n",
    "    f9_ax4.axis('off')\n",
    "#     plt.title('Contra                                    Ipsi                                    Bino')\n",
    "    plt.text(aux_time_full[-1] / 2 - 2, 5 , 'Contra', fontsize=16)\n",
    "    plt.text(aux_time_full[-1] * 1.5-2, 5 , 'Ipsi', fontsize=16)\n",
    "    plt.text(aux_time_full[-1] * 2.5-2, 5 , 'Bino', fontsize=16)   \n",
    "    \n",
    "#     plt.tight_layout()           \n",
    "    plt.suptitle('z-scored deconvolved F - Chirp PSTHs - rastermap embedding (smoothened over boutons) - exp' + exp[0])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('all.eps', format='eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMF on PSTHs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = 29\n",
    "compstr = ['Comp ' + str(idx) for idx in range(components)]\n",
    "\n",
    "nmf = NMF(n_components=components, solver=\"mu\")\n",
    "\n",
    "# sp_all[sp_all < 0] = 0\n",
    "sp_contra[sp_contra < 0] = 0\n",
    "\n",
    "W = nmf.fit_transform(sp_contra.T)\n",
    " \n",
    "H = nmf.components_\n",
    "\n",
    "comp_df_H = pd.DataFrame(H.T, columns=compstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sm_all = nmf.inverse_transform(W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = components\n",
    "cols = int(np.ceil(components / rows))\n",
    "\n",
    "fig, axs = plt.subplots(rows,cols, figsize=(15, rows*2), facecolor='w', edgecolor='k')\n",
    "# fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "\n",
    "k = 0\n",
    "\n",
    "for ax, d in zip(axs.ravel(), H):\n",
    "    k += 1\n",
    "    ax.plot(time, d)\n",
    "#     ax.plot(d)\n",
    "    ax.set_title('component' + str(k))\n",
    "    ax.vlines([prestim_frames[0] / fs-prestim[0], maxlength / fs - poststim_frames[0] / fs -prestim[0]],0,4, 'k')\n",
    "# plt.figure() \n",
    "# for x in \n",
    "# sns.heatmap(data = comp_df_H.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style('white'):\n",
    "    \n",
    "    xl = [-prestim[0],Sm_all.shape[1]/fs - prestim[0]]\n",
    "    \n",
    "    fig10 = plt.figure(figsize=(20,20), constrained_layout=True)\n",
    "    \n",
    "    gs1 = fig10.add_gridspec(nrows=12, ncols=3)\n",
    "    \n",
    "    fig10.add_subplot(gs1[1:, :])      \n",
    "    fig10_ax=plt.imshow(Sm_all, vmin=vmin_glob,vmax=vmax_glob,aspect='auto',extent=[-prestim[0],Sm_all.shape[1]/fs-prestim[0], 0,Sm_all.shape[0]], cmap = 'gray_r')\n",
    "    plt.xlabel('time (s)', fontsize=18)    \n",
    "    \n",
    "#     plt.vlines([prestim_frames / fs-prestim, maxlength / fs - poststim_frames / fs -prestim ],0,ncells-1, 'k')\n",
    "    plt.ylabel('boutons', fontsize=18)     \n",
    "    \n",
    "    plt.vlines([aux_time_full[-1],  +aux_time_full[-1] *2 + poststim[0]],0,ncells-1, 'r')\n",
    "    plt.vlines([prestim_frames[0] / fs-prestim[0], maxlength / fs - poststim_frames[0] / fs -prestim[0]],0,ncells-1, 'b')\n",
    "    \n",
    "    plt.vlines([aux_time_full[-1] + (prestim_frames[0] / fs),  aux_time_full[-1] + (maxlength / fs - poststim_frames[0] / fs ) ],0,ncells-1, 'b')\n",
    "    plt.vlines([2 * aux_time_full[-1] + (prestim_frames[0] / fs) + prestim[0],  2 * aux_time_full[-1] + (maxlength / fs - poststim_frames[0] / fs ) + prestim[0]],0,ncells-1, 'b')\n",
    "#     plt.plot(aux_time_full_concat, aligned_stimdata_full_concat, 'k')\n",
    "    \n",
    "#     plt.colorbar(label='deconvolved F [zscored]')\n",
    "#    plt.colorbar(label='deconvolved F [a.u.]')\n",
    "   \n",
    "    f10_ax4 = fig10.add_subplot(gs1[:1, :])    \n",
    "    plt.plot(aux_time_full_concat, aligned_stimdata_full_concat, 'k')\n",
    "#     plt.vlines([prestim_frames / fs-prestim, maxlength / fs - poststim_frames / fs -prestim],0,4, 'k')\n",
    "    f10_ax4.set_xlim(*xl)\n",
    "    f10_ax4.axis('off')\n",
    "#     plt.title('Contra                                    Ipsi                                    Bino')\n",
    "    plt.text(aux_time_full[-1] / 2 - 2, 5 , 'Contra', fontsize=16)\n",
    "    plt.text(aux_time_full[-1] * 1.5-2, 5 , 'Ipsi', fontsize=16)\n",
    "    plt.text(aux_time_full[-1] * 2.5-2, 5 , 'Bino', fontsize=16)  \n",
    "    \n",
    "#     plt.tight_layout()           \n",
    "    plt.suptitle('z-scored deconvolved F - Chirp PSTHs - rastermap embedding (smoothened over boutons) - exp' + exp[0])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rastermap embedding exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = rm.mapping.Rastermap(n_components=2, n_X=40,  nPC=400, init='pca')\n",
    "embedding = model_contra.fit_transform(sp_contra.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(embedding*40)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding[isort]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = sp_contra.T\n",
    "\n",
    "NN, NT = S.shape \n",
    "\n",
    "# reshape and sum S across neurons to get \"components\"\n",
    "nc = 100\n",
    "NC = int(np.floor(NN / nc))\n",
    "Sp = np.reshape(S[isort][:nc*NC], (NC, nc, NT))\n",
    "Sp = Sp.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sp = np.reshape(S[isort][:nc*NC], (NC, nc, NT))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S[isort][:nc*NC].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results here\n",
    "cmap = plt.get_cmap('gist_ncar')\n",
    "cmap = cmap(np.linspace(0,.97,32))\n",
    "cmap = cmap[np.random.permutation(32),:]\n",
    "plt.figure(figsize=(6,6))\n",
    "# each point is colored based on stimulus identity\n",
    "istim = np.ones(len(sp_ipsi.T), dtype = 'int')\n",
    "plt.scatter(out2[:,0],out2[:,1],color=cmap[istim,:],marker='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(melted_aux[[:,0]], melted_aux[[0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_aux.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Panda convert to long form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted = dataframe.melt(id_vars=['category', 'time', 'trial', 'cell'], value_vars=['aligned_F'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### generating trial numpy array from single cell and condition\n",
    "\n",
    "arr = melted.loc[(melted.loc[:,'trial'] < 8) & (melted.loc[:,'cell'] == 1) & (melted.loc[:,'category'] == 'Bino'),'value'].to_numpy()\n",
    "arr = arr.reshape(8,maxlength)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Panda slicing examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot single cell including individual trials and means - seaborn and other\n",
    "\n",
    "# generating trial dataframe from single cell and condtion - SINGLE TRIAL\n",
    "subselected_orig = melted.loc[(melted.loc[:,'trial'] == 1) & (melted.loc[:,'cell'] == 1) & (melted.loc[:,'category'] == 'Contra'),['time', 'value', 'trial']]\n",
    "\n",
    "# generating trial dataframe from single cell and condtion - ALL TRIALS\n",
    "subselected_orig = melted.loc[(melted.loc[:,'cell'] == 1) & (melted.loc[:,'category'] == 'Contra'),['time', 'value', 'trial']]\n",
    "\n",
    "# reshape ('pivot') to index over time and have single trial columns\n",
    "subselected = subselected_orig.pivot(index = 'time', columns='trial', values='value')\n",
    "\n",
    "# reshape ('pivot') to index over time and have single trial columns - zscore on the fly\n",
    "# subselected = subselected_orig.pivot(index = 'time', columns='trial', values='value').transform((lambda x : zscore(x)))\n",
    "\n",
    "subselected = (subselected - subselected.mean())/subselected.std(ddof=0)\n",
    "\n",
    "# generate mean from that\n",
    "\n",
    "subselected_mean = subselected.mean(axis = 1)\n",
    "\n",
    "# plot seaborn original frame and pivoted mean and trials next to eachother\n",
    "fig = plt.figure()\n",
    "plt.subplot(1,3,1)\n",
    "sns.lineplot(x = 'time', y = 'value', data = subselected, ci = 'sd')\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(subselected, 'k')\n",
    "plt.plot(subselected_mean, 'r')\n",
    "plt.subplot(1,3,3)\n",
    "# sns.heatmap(subselected, cmap = 'cubehelix')\n",
    "plt.imshow(subselected.T, aspect = 'auto',  cmap = 'cubehelix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subselected = subselected_orig.pivot(index = 'time', columns='trial', values='value')\n",
    "subselected = (subselected - subselected.mean())/subselected.std(ddof=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot all trials of a single cell concatenated\n",
    "\n",
    "fig = plt.figure()\n",
    "melted.loc[(melted.loc[:,'cell'] == 1) & (melted.loc[:,'category'] == 'Contra'),'value'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "sns.set()\n",
    "with sns.axes_style('white'):\n",
    "#     plt.imshow(arr, aspect = 'auto',  cmap = 'cubehelix')\n",
    "    sns.heatmap(subselected_orig, cmap = 'cubehelix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot individual cells as line plots and group by condition\n",
    "\n",
    "g = sns.FacetGrid(melted, col='category', hue='category', row='cell', sharey='row', margin_titles=True)\n",
    "g.map(sns.lineplot, 'time', 'value', ci='sd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.clf()\n",
    "g = sns.relplot(x=\"time\", y=\"value\",\n",
    "                 col=\"category\", row = 'cell', hue=\"category\", style=\"category\",\n",
    "                 kind=\"line\", data=melted, estimator=None, facet_kws={'sharey': True, 'sharex': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show cells\n",
    "im = np.zeros((ops['Ly'], ops['Lx']))\n",
    "ncells = len(stat)\n",
    "\n",
    "for n in range(0,ncells):\n",
    "    ypix = stat[n]['ypix'][~stat[n]['overlap']]\n",
    "    xpix = stat[n]['xpix'][~stat[n]['overlap']]\n",
    "    im[ypix,xpix] = n+1\n",
    "fig = plt.figure(figsize=(7,4))\n",
    "plt.imshow(im)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops['tau'] = .7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show mean image\n",
    "fig = plt.figure(figsize=(8,3))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(ops[\"meanImg\"])\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(ops[\"meanImgE\"])\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(ops[\"Vcorr\"])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops['tau'] = 0.5\n",
    "bouton = 11;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efilt = np.exp(- np.linspace(0,50,200) / (ops['tau'] * ops['fs']))\n",
    "#efilt /= efilt.sum()\n",
    "sout = convolve(spks[bouton,:], efilt)\n",
    "sout = sout[:spks.shape[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,4))\n",
    "plt.plot(F[bouton]-Fneu[bouton] * .7)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sout)\n",
    "plt.tight_layout()\n",
    "plt.show\n",
    "#plt.plot(F[10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(spks[11])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "plt.imshow(spks[:100, :5000], vmax = 3, vmin = -0.5, aspect='auto', cmap = 'gray_r')\n",
    "plt.title('sample of the neural data matrix')\n",
    "plt.ylabel('boutons') \n",
    "plt.xlabel('time [samples]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToDo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- batch run different deconvolution settings using this code snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute deconvolution\n",
    "from suite2p import dcnv\n",
    "import numpy as np\n",
    "\n",
    "tau = 1.0 # timescale of indicator\n",
    "fs = 30.0 # sampling rate in Hz\n",
    "neucoeff = 0.7 # neuropil coefficient\n",
    "# for computing and subtracting baseline\n",
    "baseline = 'maximin' # take the running max of the running min after smoothing with gaussian\n",
    "sig_baseline = 10.0 # in bins, standard deviation of gaussian with which to smooth\n",
    "win_baseline = 60.0 # in seconds, window in which to compute max/min filters\n",
    "\n",
    "ops = {'tau': tau, 'fs': fs, 'neucoeff': neucoeff,\n",
    "       'baseline': baseline, 'sig_baseline': sig_baseline, 'win_baseline': win_baseline}\n",
    "\n",
    "# load traces and subtract neuropil\n",
    "F = np.load('F.npy')\n",
    "Fneu = np.load('Fneu.npy')\n",
    "Fc = F - ops['neucoeff'] * Fneu\n",
    "\n",
    "# baseline operation\n",
    "Fc = dcnv.preprocess(Fc, ops)\n",
    "\n",
    "# get spikes\n",
    "spks = dcnv.oasis(Fc, ops)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
