{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n",
    "from suite2p import run_s2p\n",
    "ops = run_s2p.default_ops() # populates ops with the default options\n",
    "# option to import from github folder\n",
    "# sys.path.insert(0, 'C:/Users/trose/Documents/GitHub/suite2p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# own imports\n",
    "from ScanImageTiffReader import ScanImageTiffReader\n",
    "from helpers import parse_SI_header as pSI #own\n",
    "from shutil import copy, rmtree\n",
    "from tqdm import tqdm\n",
    "#import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File handling (PC / Mac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ['62282', '62283', '62284', '62285', '62286', '62287', '62288', '62289', '62290', '62291', '62292', '62293', '62304', '62305', '62306', '62307', '62308', '62309', '62359', '62360', '62361', '62362', '62363', '62364']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ['62335']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.platform == \"win32\":\n",
    "    main_root = 'I:/David Laubender/Data/imaging data/DL_191106_2/ImagingData/2019-12-14/' #location of original data\n",
    "    ftemp = 'C:/temp/trose/suite2ptemp'        #fast disk\n",
    "    if len(exp)>1:\n",
    "        froot = 'C:/temp/trose/s2p_tiff/'      #temp drive for concatenating exp tiffs\n",
    "        fsave =  froot \n",
    "    else:\n",
    "        froot = main_root                      #No concatenation of experiments -> can work on NW drive\n",
    "        fsave = froot\n",
    "elif sys.platform == \"darwin\":\n",
    "    main_root = '/Volumes/archive_bonhoeffer_group$/David Laubender/Data/imaging data/DL_191106_2/ImagingData/2019-12-14/' #location of original data\n",
    "    ftemp = '/Users/trose/Data/temp/'          #fast disk\n",
    "    if len(exp)>1:\n",
    "        froot = '/Users/trose/Data/s2p_tiff/'  #temp drive for concatenating exp tiffs\n",
    "        fsave =  froot \n",
    "    else:\n",
    "        froot = main_root                      #No concatenation of experiments -> can work on NW drive\n",
    "        fsave = froot\n",
    "else: \n",
    "    print('Unkknown Platform')\n",
    "\n",
    "fsave_tmp = froot + '/suite2p_exp' + exp[0]\n",
    "ftemp_tmp = ftemp + '/suite2p'\n",
    "\n",
    "Path(fsave_tmp).mkdir(parents=True, exist_ok=True)\n",
    "Path(ftemp_tmp).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62335\n"
     ]
    }
   ],
   "source": [
    "for ids,val in enumerate(exp):\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copied I:\\David Laubender\\Data\\imaging data\\DL_191106_2\\ImagingData\\2019-12-14\\exp62335_DL_002_001.tif to C:/temp/trose/s2p_tiff/\n",
      "copied I:\\David Laubender\\Data\\imaging data\\DL_191106_2\\ImagingData\\2019-12-14\\exp62335_DL_002_002.tif to C:/temp/trose/s2p_tiff/\n",
      "copied I:\\David Laubender\\Data\\imaging data\\DL_191106_2\\ImagingData\\2019-12-14\\exp62336_DL_003_001.tif to C:/temp/trose/s2p_tiff/\n",
      "copied I:\\David Laubender\\Data\\imaging data\\DL_191106_2\\ImagingData\\2019-12-14\\exp62336_DL_003_002.tif to C:/temp/trose/s2p_tiff/\n"
     ]
    }
   ],
   "source": [
    "# Copy all tiffs to a temp folder for concatenated handling\n",
    "if len(exp)>1:\n",
    "    files_fullpath = []\n",
    "    readfiles = 2\n",
    "    for val in exp:\n",
    "        files = list(Path(main_root).rglob('exp'+val+'*.tif')) #recursive search over main_root\n",
    "        files = sorted(files)\n",
    "        files = files[0:readfiles]\n",
    "        for n,f in enumerate(files):\n",
    "            copy(files[n], froot)\n",
    "            targetstring = [str(files[n]), str(froot)]\n",
    "            print('copied {} to {}'.format(*targetstring))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I:/David Laubender/Data/imaging data/DL_191106_2/ImagingData/2019-12-14/'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_fullpath = []\n",
    "files_name = []\n",
    "readfiles = 5\n",
    "\n",
    "for val in exp:\n",
    "    #files = list(Path(froot).glob('exp'+val+'*.tif'))\n",
    "    files = list(Path(froot).rglob('exp'+val+'*.tif')) #recursive\n",
    "    files = files[0:readfiles]\n",
    "    #files = glob.glob(os.path.join(froot, 'exp'+val+'*.tif'))\n",
    "    for n,f in enumerate(files):\n",
    "        #files[n] = os.path.basename(f)\n",
    "        files_fullpath.append(str(files[n]))\n",
    "        files_name.append(f.name)\n",
    "\n",
    "    \n",
    "files_fullpath = sorted(files_fullpath)\n",
    "files_name = sorted(files_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I:\\\\David Laubender\\\\Data\\\\imaging data\\\\DL_191106_2\\\\ImagingData\\\\2019-12-14'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.dirname(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ScanImageTiffReader(files_fullpath[0]) as reader:\n",
    "    header = (reader.description(0))\n",
    "    mov_dim = (reader.shape())\n",
    "    \n",
    "level = pSI.parse_SI_header_level(header)\n",
    "zoom = pSI.parse_SI_header_zoom(header)\n",
    "framerate = pSI.parse_SI_header_FrameRate(header)\n",
    "channels = pSI.parse_SI_header_Channels(header)\n",
    "volumes = pSI.parse_SI_header_Volumes(header)\n",
    "frames = pSI.parse_SI_header_Frames(header)\n",
    "frames_per_file = pSI.parse_SI_header_FramesPerFile(header)\n",
    "\n",
    "# account for multilevel acq where frames is 1\n",
    "if frames < volumes:\n",
    "    frames = volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_frames = np.linspace(0, 49, 50)\n",
    "np.save(fsave_tmp + '/bad_frames.npy', bad_frames)\n",
    "np.save(ftemp_tmp + '/bad_frames.npy', bad_frames)\n",
    "#np.save(ftemp + '/bad_frames.npy', bad_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = {\n",
    "      'h5py': [], # a single h5 file path\n",
    "      'h5py_key': 'data', # file paths\n",
    "      'look_one_level_down': False, # whether to look in ALL subfolders when searching for tiffs\n",
    "      'data_path': [froot],  # a list of folders with tiffs\n",
    "                             # (or folder of folders with tiffs if look_one_level_down is True, or subfolders is not empty)\n",
    "      'delete_bin': False,\n",
    "      'save_path0': fsave,\n",
    "      'fast_disk': ftemp,\n",
    "      'subfolders': [], # choose subfolders of 'data_path' to look in (optional)\n",
    "\n",
    "      # main settings\n",
    "      'nplanes': level, # each tiff has these many planes in sequence\n",
    "      'nchannels': channels, # each tiff has these many channels per plane\n",
    "      'functional_chan': 1, # this channel is used to extract functional ROIs (1-based)\n",
    "      'tau':  1., # this is the main parameter for deconvolution\n",
    "      'fs': framerate / level,  # sampling rate (PER PLANE - e.g. if you have 12 planes then this should be around 2.5)\n",
    "      'preclassify': 0, # apply classifier before signal extraction with probability 0.5 (turn off with value 0)\n",
    "      'frames_include:': -1,  #default: -1) if greater than zero, only frames_include frames are processed. useful for testing parameters on a subset of data.\n",
    "      # output settings\n",
    "      'save_mat': True, # whether to save output as matlab files\n",
    "      'combined': True, # combine multiple planes into a single result /single canvas for GUI\n",
    "\n",
    "      'num_workers': 0, # 0 to select num_cores, -1 to disable parallelism, N to enforce value\n",
    "      'num_workers_roi': 0, # 0 to select number of planes, -1 to disable parallelism, N to enforce value\n",
    "      'force_sktiff': False,\n",
    "      # bidirectional phase offset\n",
    "      'do_bidiphase': True,\n",
    "      'bidiphase': 0,\n",
    "\n",
    "      # registration settings\n",
    "      'do_registration': 2, # whether to register data (2 forces re-registration)\n",
    "      'two_step_registration:': True, #default: False) whether or not to run registration twice (for low SNR data). keep_movie_raw must be True for this to work.\n",
    "      'keep_movie_raw': True,\n",
    "      'nimg_init': 400, # subsampled frames for finding reference image\n",
    "      'batch_size': 800, # number of frames per batch\n",
    "      'maxregshift': 0.05, # max allowed registration shift, as a fraction of frame max(width and height)\n",
    "      'align_by_chan' : 1, # when multi-channel, you can align by non-functional channel (1-based)\n",
    "      'reg_tif': True, # whether to save registered tiffs\n",
    "      'reg_tif_chan2': False, # whether to save channel 2 registered tiffs\n",
    "      'subpixel' : 10, # precision of subpixel registration (1/subpixel steps)\n",
    "      'smooth_sigma': 1.5, # ~1 good for 2P recordings, recommend >5 for 1P recordings\n",
    "      'smooth_sigma_time': 2, # default: 0) standard deviation in time frames of the gaussian used to smooth the data before phase correlation is computed. Might need this to be set to 1 or 2 for low SNR data.\n",
    "      'th_badframes': 2, # this parameter determines which frames to exclude when determining cropping - set it smaller to exclude more frames\n",
    "      'pad_fft': False,\n",
    "\n",
    "      # non rigid registration settings\n",
    "      'nonrigid': True, # whether to use nonrigid registration\n",
    "      'block_size': [128, 128], # block size to register (** keep this a multiple of 2 **)\n",
    "      'snr_thresh': 1.5, # if any nonrigid block is below this threshold, it gets smoothed until above this threshold. 1.0 results in no smoothing\n",
    "      'maxregshiftNR': 8, # maximum pixel shift allowed for nonrigid, relative to rigid\n",
    "\n",
    "      # cell detection settings\n",
    "      'roidetect': True, # whether or not to run ROI extraction\n",
    "      'spatial_scale': 0, # 0: multi-scale; 1: 6 pixels, 2: 12 pixels, 3: 24 pixels, 4: 48 pixels\n",
    "      'diameter': [9,12], #this is the main parameter for cell detection, 2-dimensional if Y and X are different (e.g. [6 12])\n",
    "      'connected': False, # whether or not to keep ROIs fully connected (set to 0 for dendrites)\n",
    "      'nbinned': 5000, # max number of binned frames for cell detection\n",
    "      'max_iterations': 50, # maximum number of iterations to do cell detection\n",
    "      'threshold_scaling': 2.0, # adjust the automatically determined threshold by this scalar multiplier\n",
    "      'max_overlap': 0.9, # cells with more overlap than this get removed during triage, before refinement\n",
    "      'high_pass': 100, # running mean subtraction with window of size 'high_pass' (use low values for 1P)\n",
    "      'smooth_masks': True, # default: True) whether to smooth masks in final pass of cell detection. This is useful especially if you are in a high noise regime.\n",
    "\n",
    "      # ROI extraction parameters\n",
    "      'sparse_mode': False, #default: False) whether or not to use sparse_mode cell detection\n",
    "      'inner_neuropil_radius': 2, # number of pixels to keep between ROI and neuropil donut\n",
    "      'min_neuropil_pixels': 350, # minimum number of pixels in the neuropil\n",
    "      'allow_overlap': False, # pixels that are overlapping are thrown out (False) or added to both ROIs (True)\n",
    "\n",
    "      # channel 2 detection settings (stat[n]['chan2'], stat[n]['not_chan2'])\n",
    "      'chan2_thres': 0.65, # minimum for detection of brightness on channel 2\n",
    "\n",
    "      # deconvolution settings\n",
    "      'baseline': 'maximin', # baselining mode (can also choose 'prctile')\n",
    "      'win_baseline': 60., # window for maximin\n",
    "      'sig_baseline': 10., # smoothing constant for gaussian filter\n",
    "      'prctile_baseline': 8.,# optional (whether to use a percentile baseline)\n",
    "      'neucoeff': .7,  # neuropil coefficient\n",
    "\n",
    "\n",
    "      # List of tiffs to be loaded\n",
    "      'tiff_list': files_name # list of tiffs in folder * data_path *!\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'h5py': [], 'h5py_key': 'data', 'look_one_level_down': False, 'data_path': ['I:/David Laubender/Data/imaging data/DL_191106_2/ImagingData/2019-12-14/'], 'delete_bin': False, 'save_path0': 'I:/David Laubender/Data/imaging data/DL_191106_2/ImagingData/2019-12-14/', 'fast_disk': 'C:/temp/trose/suite2ptemp', 'subfolders': [], 'nplanes': 4, 'nchannels': 1, 'functional_chan': 1, 'tau': 1.0, 'fs': 7.5, 'preclassify': 0, 'frames_include:': -1, 'save_mat': True, 'combined': True, 'num_workers': 0, 'num_workers_roi': 0, 'force_sktiff': False, 'do_bidiphase': True, 'bidiphase': 0, 'do_registration': 2, 'two_step_registration:': True, 'keep_movie_raw': True, 'nimg_init': 400, 'batch_size': 800, 'maxregshift': 0.05, 'align_by_chan': 1, 'reg_tif': True, 'reg_tif_chan2': False, 'subpixel': 10, 'smooth_sigma': 1.5, 'smooth_sigma_time': 2, 'th_badframes': 2, 'pad_fft': False, 'nonrigid': True, 'block_size': [128, 128], 'snr_thresh': 1.5, 'maxregshiftNR': 8, 'roidetect': True, 'spatial_scale': 0, 'diameter': [9, 12], 'connected': False, 'nbinned': 5000, 'max_iterations': 50, 'threshold_scaling': 2.0, 'max_overlap': 0.9, 'high_pass': 100, 'smooth_masks': True, 'sparse_mode': False, 'inner_neuropil_radius': 2, 'min_neuropil_pixels': 350, 'allow_overlap': False, 'chan2_thres': 0.65, 'baseline': 'maximin', 'win_baseline': 60.0, 'sig_baseline': 10.0, 'prctile_baseline': 8.0, 'neucoeff': 0.7, 'tiff_list': ['exp62335_DL_002_030.tif', 'exp62335_DL_002_073.tif', 'exp62335_DL_002_113.tif', 'exp62335_DL_002_136.tif', 'exp62335_DL_002_149.tif']}\n",
      "tif\n",
      "** Found 5 tifs - converting to binary **\n",
      "time 26.02 sec. Wrote tifs to binaries for 4 planes\n",
      "do_registration>1 => forcing registration\n",
      ">>>>>>>>>>>>>>>>>>>>> PLANE 0 <<<<<<<<<<<<<<<<<<<<<<\n",
      "----------- REGISTRATION\n",
      "registering 600 frames\n",
      "NOTE: estimated bidiphase offset from data: 0 pixels\n",
      "Reference frame, 100.78 sec.\n",
      "600/600 frames, 60.70 sec.\n",
      "bad frames file path: I:\\David Laubender\\Data\\imaging data\\DL_191106_2\\ImagingData\\2019-12-14\\bad_frames.npy\n",
      "----------- Total 162.25 sec\n",
      "----------- ROI DETECTION AND EXTRACTION\n",
      "Binning movie in chunks of length 08\n",
      "Binned movie [62,502,489], 1.22 sec.\n",
      "ROIs: 142, cost: 0.5387, time: 16.5651\n",
      "ROIs: 176, cost: 0.5307, time: 20.5741\n",
      "ROIs: 178, cost: 0.5299, time: 22.7501\n",
      "Binning movie in chunks of length 08\n",
      "Binned movie [62,502,489], 1.15 sec.\n",
      "ROIs: 178, cost: 0.5644, time: 25.2541\n",
      "ROIs: 178, cost: 0.5510, time: 27.1141\n",
      "ROIs: 178, cost: 0.5505, time: 28.5412\n",
      "Found 178 ROIs, 35.73 sec\n",
      "NOTE: applying classifier c:\\users\\trose\\documents\\github\\suite2p\\suite2p\\extraction\\../classifiers/classifier_user.npy\n",
      "After removing overlaps, 178 ROIs remain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Miniconda3\\envs\\suite2p\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masks made in 6.71 sec.\n",
      "Extracted fluorescence from 178 ROIs in 600 frames, 3.40 sec.\n",
      "----------- Total 59.93 sec.\n",
      "----------- SPIKE DECONVOLUTION\n",
      "----------- Total 28.92 sec.\n",
      "Plane 0 processed in 256.70 sec (can open in GUI).\n",
      "total = 282.79 sec.\n",
      ">>>>>>>>>>>>>>>>>>>>> PLANE 1 <<<<<<<<<<<<<<<<<<<<<<\n",
      "----------- REGISTRATION\n",
      "registering 600 frames\n",
      "NOTE: estimated bidiphase offset from data: 0 pixels\n",
      "Reference frame, 99.93 sec.\n",
      "600/600 frames, 61.33 sec.\n",
      "bad frames file path: I:\\David Laubender\\Data\\imaging data\\DL_191106_2\\ImagingData\\2019-12-14\\bad_frames.npy\n",
      "----------- Total 162.55 sec\n",
      "----------- ROI DETECTION AND EXTRACTION\n",
      "Binning movie in chunks of length 08\n",
      "Binned movie [62,502,489], 1.18 sec.\n",
      "ROIs: 145, cost: 0.5350, time: 17.1941\n",
      "ROIs: 175, cost: 0.5278, time: 21.1711\n",
      "ROIs: 179, cost: 0.5265, time: 23.7291\n",
      "Binning movie in chunks of length 08\n",
      "Binned movie [62,502,489], 1.16 sec.\n",
      "ROIs: 179, cost: 0.5543, time: 26.6381\n",
      "ROIs: 179, cost: 0.5407, time: 28.4971\n",
      "ROIs: 179, cost: 0.5400, time: 30.0461\n",
      "Found 179 ROIs, 37.32 sec\n",
      "NOTE: applying classifier c:\\users\\trose\\documents\\github\\suite2p\\suite2p\\extraction\\../classifiers/classifier_user.npy\n",
      "After removing overlaps, 178 ROIs remain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Miniconda3\\envs\\suite2p\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masks made in 6.45 sec.\n",
      "Extracted fluorescence from 178 ROIs in 600 frames, 3.46 sec.\n",
      "----------- Total 61.22 sec.\n",
      "----------- SPIKE DECONVOLUTION\n",
      "----------- Total 30.74 sec.\n",
      "Plane 1 processed in 260.02 sec (can open in GUI).\n",
      "total = 542.81 sec.\n",
      ">>>>>>>>>>>>>>>>>>>>> PLANE 2 <<<<<<<<<<<<<<<<<<<<<<\n",
      "----------- REGISTRATION\n",
      "registering 600 frames\n",
      "NOTE: estimated bidiphase offset from data: 1 pixels\n",
      "Reference frame, 102.69 sec.\n",
      "600/600 frames, 68.39 sec.\n",
      "bad frames file path: I:\\David Laubender\\Data\\imaging data\\DL_191106_2\\ImagingData\\2019-12-14\\bad_frames.npy\n",
      "----------- Total 172.31 sec\n",
      "----------- ROI DETECTION AND EXTRACTION\n",
      "Binning movie in chunks of length 08\n",
      "Binned movie [62,502,487], 1.17 sec.\n",
      "ROIs: 127, cost: 0.5354, time: 17.9820\n",
      "ROIs: 150, cost: 0.5286, time: 21.4710\n",
      "ROIs: 152, cost: 0.5276, time: 23.8710\n",
      "Binning movie in chunks of length 08\n",
      "Binned movie [62,502,487], 1.15 sec.\n",
      "ROIs: 152, cost: 0.5584, time: 26.3700\n",
      "ROIs: 152, cost: 0.5449, time: 28.2550\n",
      "ROIs: 152, cost: 0.5442, time: 29.7080\n",
      "Found 152 ROIs, 37.03 sec\n",
      "NOTE: applying classifier c:\\users\\trose\\documents\\github\\suite2p\\suite2p\\extraction\\../classifiers/classifier_user.npy\n",
      "After removing overlaps, 152 ROIs remain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Miniconda3\\envs\\suite2p\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masks made in 6.41 sec.\n",
      "Extracted fluorescence from 152 ROIs in 600 frames, 3.62 sec.\n",
      "----------- Total 61.03 sec.\n",
      "----------- SPIKE DECONVOLUTION\n",
      "----------- Total 32.67 sec.\n",
      "Plane 2 processed in 270.61 sec (can open in GUI).\n",
      "total = 813.42 sec.\n",
      ">>>>>>>>>>>>>>>>>>>>> PLANE 3 <<<<<<<<<<<<<<<<<<<<<<\n",
      "----------- REGISTRATION\n",
      "registering 600 frames\n",
      "NOTE: estimated bidiphase offset from data: 1 pixels\n",
      "Reference frame, 108.36 sec.\n",
      "600/600 frames, 66.74 sec.\n",
      "bad frames file path: I:\\David Laubender\\Data\\imaging data\\DL_191106_2\\ImagingData\\2019-12-14\\bad_frames.npy\n",
      "----------- Total 176.65 sec\n",
      "----------- ROI DETECTION AND EXTRACTION\n",
      "Binning movie in chunks of length 08\n",
      "Binned movie [75,502,483], 1.51 sec.\n",
      "ROIs: 141, cost: 0.5336, time: 20.3660\n",
      "ROIs: 162, cost: 0.5284, time: 23.8330\n",
      "ROIs: 164, cost: 0.5277, time: 26.4800\n",
      "Binning movie in chunks of length 08\n",
      "Binned movie [75,502,483], 1.35 sec.\n",
      "ROIs: 164, cost: 0.5537, time: 29.4800\n",
      "ROIs: 164, cost: 0.5438, time: 31.5360\n",
      "ROIs: 164, cost: 0.5434, time: 33.0210\n",
      "Found 164 ROIs, 39.97 sec\n",
      "NOTE: applying classifier c:\\users\\trose\\documents\\github\\suite2p\\suite2p\\extraction\\../classifiers/classifier_user.npy\n",
      "After removing overlaps, 162 ROIs remain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Miniconda3\\envs\\suite2p\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masks made in 5.94 sec.\n",
      "Extracted fluorescence from 162 ROIs in 600 frames, 3.69 sec.\n",
      "----------- Total 63.98 sec.\n",
      "----------- SPIKE DECONVOLUTION\n",
      "----------- Total 33.71 sec.\n",
      "Plane 3 processed in 279.52 sec (can open in GUI).\n",
      "total = 1092.95 sec.\n",
      "TOTAL RUNTIME 1116.48 sec\n"
     ]
    }
   ],
   "source": [
    "opsEnd = run_s2p.run_s2p(ops=ops, db=db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert notebook to *.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook suite2p_axon_workflow.ipynb to script\n",
      "[NbConvertApp] Writing 9850 bytes to suite2p_axon_workflow.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script suite2p_axon_workflow.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trash collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat = np.load(ftemp +'/std_ops/ops_dendrite.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set your options for running\n",
    "ops = run_s2p.default_ops() # populates ops with the default options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opspath = 'C:/temp/trose/David Laubender/Data/imaging data/DL_191106_2/ImagingData/2019-12-14/suite2p/suite2p/plane0/ops.npy'\n",
    "\n",
    "stato = np.load(opspath, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stat.conj().transpose())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
