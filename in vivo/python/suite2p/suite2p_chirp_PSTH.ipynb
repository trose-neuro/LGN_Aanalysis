{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "%matplotlib widget\n",
    "import seaborn as sns\n",
    "sns.set()  # set plot styles\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path, PureWindowsPath, PurePosixPath\n",
    "from scipy.signal import convolve\n",
    "from scipy.stats import zscore\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "# from scipy.stats import zscore ### Cave! scipy zscore does not handle NaN!\n",
    "from ScanImageTiffReader import ScanImageTiffReader\n",
    "from helpers import parse_SI_header as pSI #own\n",
    "from tqdm import tqdm, notebook\n",
    "\n",
    "import rastermap as rm\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aux loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_auxdata(filename):    \n",
    "    \"\"\" Loads .lvd aux data file - Pieter Goltstein 2020\"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        # Reset file index\n",
    "        f.seek(0)\n",
    "        # Get meta data\n",
    "        samplingfreq = np.fromfile(f, dtype='>f8', count=1)\n",
    "        print(\"Aux sampling frequency = {}Hz\".format(samplingfreq))\n",
    "        n_channels = int(np.fromfile(f, dtype='>f8', count=1))\n",
    "        print(\"# channels = {}\".format(n_channels))\n",
    "        timestamp = np.fromfile(f, dtype='>f8', count=1)\n",
    "        print(\"timestamp = {}\".format(timestamp))\n",
    "        max_input = np.fromfile(f, dtype='>f8', count=1)\n",
    "        print(\"max input = {} V\".format(max_input))\n",
    "        # Read aux data\n",
    "        auxdata = np.fromfile(f, dtype='>f8')\n",
    "        n_datapoints = int(auxdata.shape[0]/n_channels)\n",
    "        print(\"number of aux datapoints = {}\".format(n_datapoints))\n",
    "        auxdata = np.reshape(auxdata,(n_datapoints,n_channels))\n",
    "        return auxdata, samplingfreq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frame extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_times(auxdata, Frames_chan):\n",
    "    \"\"\" extracts frame onset times \"\"\"\n",
    "    len_aux = len(auxdata)\n",
    "    pos = np.argwhere(auxdata[0:,Frames_chan] > 0.75 * np.max(auxdata[range(0,len_aux),Frames_chan ])) # work on diff of indices rather than on raw diff to prevent multi-smaple detection in up/ downstrokes\n",
    "    diffpos = np.argwhere(np.diff(pos[0:,0]) > 1)\n",
    "    frame_times = pos[diffpos,0]\n",
    "    \n",
    "    if  len(frame_times)==0:\n",
    "        print('get_frame_times WARNING: no frames found')\n",
    "        frame_times = 1;\n",
    "        return frame_times\n",
    "    \n",
    "    # find onset of first frame\n",
    "    pos_first = np.argwhere(auxdata[0:,Frames_chan] < 0.5 * np.max(auxdata[range(0,len_aux), Frames_chan]))\n",
    "    diffpos_first = np.argwhere(np.diff(pos_first[0:,0]) > 1)\n",
    "    frame_times = np.append(diffpos_first[0], frame_times)\n",
    "    \n",
    "    return frame_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHIRP - stimulus bound extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stimIDs_chirp(auxdata, stimops):\n",
    "    \"\"\" extracts chirp onset times \"\"\"\n",
    "    \n",
    "    Frames_chan = stimops['Frames_chan']\n",
    "    Stims_chan = stimops['Stims_chan']\n",
    "    eye1_chan = stimops['eye1_chan']\n",
    "    eye2_chan = stimops['eye2_chan']\n",
    "    level = stimops['level']\n",
    "    minsample_delta = stimops['minsample_delta']\n",
    "    \n",
    "    frame_times         = get_frame_times(auxdata,Frames_chan)\n",
    "    frame_times_level   = frame_times[range(0,len(frame_times),level)]\n",
    "\n",
    "    \n",
    "    StimOn = auxdata[frame_times_level, Stims_chan]>0.8\n",
    "\n",
    "    # generate cleaned eye binaries\n",
    "    Eye1On = auxdata[frame_times_level,eye1_chan]*-1+ np.max(auxdata[frame_times_level,eye1_chan])>0.8\n",
    "    Eye2On = auxdata[frame_times_level,eye2_chan]>0.8\n",
    "    Eye2On[-1] = 1 \n",
    "    bino = Eye1On == Eye2On\n",
    "\n",
    "    Eye1On_only = Eye1On != bino\n",
    "    Eye2On_only = Eye2On != bino\n",
    "    Eye1On_only[-1] = False\n",
    "    Eye2On_only[-1] = False\n",
    "    bino[0] = False\n",
    "    bino[-1] = False\n",
    "\n",
    "    # generate cleaned bino binary\n",
    "    bino_onsets_temp  = np.argwhere(np.diff(np.multiply(bino, 1)) > 0)\n",
    "    bino_offsets_temp = np.argwhere(np.diff(np.multiply(bino, 1)) < 0)\n",
    "\n",
    "    bino_onsets  = bino_onsets_temp[np.argwhere(bino_offsets_temp[0:,0] - bino_onsets_temp[0:,0] > minsample_delta)]\n",
    "    bino_offsets = bino_offsets_temp[np.argwhere(bino_offsets_temp[0:,0] - bino_onsets_temp[0:,0] > minsample_delta)]                              \n",
    "\n",
    "    bino_clean = np.full(( len(frame_times_level)), False) \n",
    "\n",
    "    for i in range(len(bino_onsets)):\n",
    "        bino_clean[range(bino_onsets[i,0,0], bino_offsets[i,0,0])] = True\n",
    "\n",
    "    # extract chirp stim on and offsets\n",
    "    chirp_onsets_temp  = np.argwhere(np.diff(np.multiply(StimOn, 1)) > 0)\n",
    "    chirp_offsets_temp = np.argwhere(np.diff(np.multiply(StimOn, 1)) < 0)\n",
    "\n",
    "    chirp_on  = np.argwhere(np.diff(chirp_onsets_temp[0:,0]) > minsample_delta) + 1\n",
    "    chirp_off = np.argwhere(np.diff(chirp_offsets_temp[0:,0]) > minsample_delta)\n",
    "\n",
    "    chirp_on  = np.append(0, chirp_on)\n",
    "    chirp_off = np.append(chirp_off, len(chirp_offsets_temp) - 1)\n",
    "\n",
    "    chirp_onsets  = chirp_onsets_temp[chirp_on]\n",
    "    chirp_offsets = chirp_offsets_temp[chirp_off]\n",
    "\n",
    "    ids = { \n",
    "    'Contra':   [np.intersect1d(chirp_onsets, np.argwhere(Eye1On_only)), np.intersect1d(chirp_offsets, np.argwhere(Eye1On_only))],\n",
    "    'Ipsi': [np.intersect1d(chirp_onsets, np.argwhere(Eye2On_only)), np.intersect1d(chirp_offsets, np.argwhere(Eye2On_only))],\n",
    "    'Bino':   [np.intersect1d(chirp_onsets, np.argwhere(bino_clean)), np.intersect1d(chirp_offsets, np.argwhere(bino_clean))],\n",
    "    'FrameTimes_level': frame_times_level,\n",
    "    'FrameTimes':       frame_times,\n",
    "    }\n",
    "    \n",
    "    return ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### on-the-fly panda function definition of zscore that handles NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score(df): return (df-df.mean())/df.std(ddof=0)\n",
    "# def m_mean(df): return df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-specific folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sys.platform == \"darwin\":\n",
    "    ### Mac\n",
    "    #main_root = '/private/tmp/trose/archive_bonhoeffer_group$/David Laubender/Data/imaging data/DL_191024_6/ImagingData/' #location of original data\n",
    "    main_root = '/Volumes/David Laubender/Data/imaging data/DL_191024_6/ImagingData/' #location of original data\n",
    "    adata     = '/private/tmp/trose/archive_bonhoeffer_group$/David Laubender/adata' #location of saved analyzed data\n",
    "    ftemp     = '/Users/trose/Data/temp' #fast disk (local ssd for s2p binary files) \n",
    "    ftiff     = '/Users/trose/Data/s2p_tiff' #fast disk folder for concatenated tiffs (if needed)\n",
    "    xlpath    = '/Users/trose/Data/temp/LGNexperiments.xlsx' \n",
    "elif sys.platform == \"win32\":\n",
    "#     main_root = 'I:/David Laubender/Data/imaging data/DL_191106_2/ImagingData' #location of original data\n",
    "    main_root = 'I:/David Laubender/Data/imaging data/DL_191024_6/ImagingData' #location of original data    \n",
    "    adata     = 'I:/David Laubender/adata' #location of saved analyzed data\n",
    "    ftemp     = 'C:/temp/trose/suite2ptemp' #fast disk (local ssd for s2p binary files  \n",
    "    ftiff     = 'C:/temp/trose/s2p_tiff' #fast disk folder for concatenated tiffs (if needed)\n",
    "    xlpath    = 'C:\\\\temp\\data\\LGNexperiments.xlsx' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read excel file into panda dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(xlpath, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split comments column into Layer and elevation columns and drop mixed column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Layer', 'Elevation']] = df.comments.str.rsplit(',', expand = True)\n",
    "df = df.drop(['comments'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  boolean combination of search strings (here: Euler stim only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[(df['experiment type'] == 'euler' ) & (df['Layer'] == 'L1')]\n",
    "# load_df = df[(df['experiment type'] == 'euler' ) & (df['Layer'] == 'L1') & (df['Elevation']==' positive degrees')]\n",
    "#load_df = df[(df['experiment type'] == 'euler' ) & (df['Layer'] == 'L4')]\n",
    "\n",
    "load_df = df[(df['experiment type'] == 'euler' )]\n",
    "exp=list(map(str,load_df.experiment))\n",
    "main_root=list(map(str,load_df.folder))\n",
    "# list(main_root)\n",
    "# list(exp)\n",
    "#exp = [exp[0]]\n",
    "#main_root = [main_root[0]]\n",
    "#main_root_old = main_root[0]\n",
    "\n",
    "if sys.platform == \"darwin\":\n",
    "    main_root_mac = []\n",
    "    for idx, val in enumerate(exp):\n",
    "        main_root_mac.append(str(Path('/Volumes/', *PureWindowsPath(main_root[idx]).parts[1:])))\n",
    "    main_root = main_root_mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp = ['62283', '62284', '62285', '62286', '62287', '62288', '62289', '62290']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp = ['62336']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7900ceded0f249749c10f05fa072bc64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "adata_s2ppath = []\n",
    "adata_tiffpath = []\n",
    "aux_files = []\n",
    "single_tiff_file =[]\n",
    "experimentator = []\n",
    "mouse = []\n",
    "date = []\n",
    "experiment = []\n",
    "\n",
    "for idx, val in notebook.tqdm(enumerate(exp)):\n",
    "    s2pdir = list(Path(main_root[idx]).rglob('suite2p_exp'+val+'/')) #recursive\n",
    "    tifffile = list(Path(os.path.join(*Path(s2pdir[0]).parts[0:-3], 'ImagingData', Path(s2pdir[0]).parts[-2])).glob('exp'+val+'*.tif')) #recursive search over main_root    \n",
    "    experimentator.append(Path(s2pdir[0]).parts[-7])\n",
    "    mouse.append(Path(s2pdir[0]).parts[-4])\n",
    "    date.append(Path(s2pdir[0]).parts[-2])\n",
    "    experiment.append(val)\n",
    "    Layer = load_df[load_df['experiment'] == int(val)]['Layer'].str.strip().to_numpy()\n",
    "    Elevation = load_df[load_df['experiment'] == int(val)]['Elevation'].str.strip().to_numpy()\n",
    "    try:\n",
    "        adata_s2ppath.append(os.path.join(s2pdir[0], 'suite2p', 'combined'))\n",
    "        adata_tiffpath.append(os.path.dirname(s2pdir[0]))\n",
    "        aux_files.append(*Path(os.path.join(*Path(s2pdir[0]).parts[0:-3], 'data', Path(s2pdir[0]).parts[-2])).glob('exp'+val+'*.lvd'))\n",
    "        single_tiff_file.append(str(tifffile[0]))\n",
    "    except:\n",
    "        print(val + ' not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parse first tiff of exp for imaging specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ScanImageTiffReader(single_tiff_file[0]) as reader:\n",
    "    header = (reader.description(0))\n",
    "    mov_dim = (reader.shape())\n",
    "    \n",
    "level = pSI.parse_SI_header_level(header)\n",
    "zoom = pSI.parse_SI_header_zoom(header)\n",
    "framerate = pSI.parse_SI_header_FrameRate(header)\n",
    "channels = pSI.parse_SI_header_Channels(header)\n",
    "volumes = pSI.parse_SI_header_Volumes(header)\n",
    "frames = pSI.parse_SI_header_Frames(header)\n",
    "frames_per_file = pSI.parse_SI_header_FramesPerFile(header)\n",
    "\n",
    "# account for multilevel acq where frames is 1\n",
    "if frames < volumes:\n",
    "    frames = volumes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract chirp stim timebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimops = {\n",
    "    'Frames_chan': 3,\n",
    "    'Stims_chan': 7,\n",
    "    'eye1_chan': 16,\n",
    "    'eye2_chan': 17,\n",
    "    'level': level, # extract from SI file in the future\n",
    "    'minsample_delta': 100 \n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d6cfea276104b939907405235389691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/David Laubender/Data/imaging data/DL_191024_6/data/2019-12-01/exp62284_DL_0014.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912011e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 6256640\n",
      "extracting stimIDs\n",
      "/Volumes/David Laubender/Data/imaging data/DL_191024_6/data/2019-12-01/exp62287_DL_0023.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912012e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 6257152\n",
      "extracting stimIDs\n",
      "/Volumes/David Laubender/Data/imaging data/DL_191024_6/data/2019-12-04/exp62290_DL_0025.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912041e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 6256384\n",
      "extracting stimIDs\n",
      "/Volumes/David Laubender/Data/imaging data/DL_191024_6/data/2019-12-04/exp62293_DL_0034.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912041e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 6257408\n",
      "extracting stimIDs\n",
      "/Volumes/David Laubender/Data/imaging data/DL_191024_6/data/2019-12-08/exp62308_DL_0032.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912081e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 6257408\n",
      "extracting stimIDs\n",
      "/Volumes/David Laubender/Data/imaging data/DL_191024_6/data/2019-12-08/exp62309_DL_0038.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912081e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 6257408\n",
      "extracting stimIDs\n",
      "/Volumes/David Laubender/Data/imaging data/DL_191024_6/data/2019-12-18/exp62361_DL_0014.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912181e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 6059776\n",
      "extracting stimIDs\n",
      "/Volumes/David Laubender/Data/imaging data/DL_191024_6/data/2019-12-18/exp62364_DL_0023.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912181e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 6060544\n",
      "extracting stimIDs\n",
      "/Volumes/David Laubender/Data/imaging data/DL_191024_4/data/2019-11-26/exp62256_DL_0011.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01911261e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 5796096\n",
      "extracting stimIDs\n",
      "/Volumes/David Laubender/Data/imaging data/DL_191024_4/data/2019-11-26/exp62260_DL_0020.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01911262e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 6257408\n",
      "extracting stimIDs\n",
      "/Volumes/David Laubender/Data/imaging data/DL_191024_4/data/2019-11-29/exp62265_DL_0015.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01911291e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 6256384\n",
      "extracting stimIDs\n",
      "/Volumes/David Laubender/Data/imaging data/DL_191024_4/data/2019-11-29/exp62268_DL_0026.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01911291e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 6256896\n",
      "extracting stimIDs\n",
      "/Volumes/David Laubender/Data/imaging data/DL_191106_1/data/2019-12-16/exp62349_DL_0035.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912161e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 6060032\n",
      "extracting stimIDs\n",
      "/Volumes/David Laubender/Data/imaging data/DL_191106_1/data/2019-12-16/exp62352_DL_0042.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912162e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 6060544\n",
      "extracting stimIDs\n",
      "/Volumes/David Laubender/Data/imaging data/DL_191106_2/data/2019-12-14/exp62336_DL_0024.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912141e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 6059520\n",
      "extracting stimIDs\n",
      "/Volumes/David Laubender/Data/imaging data/DL_191106_2/data/2019-12-14/exp62339_DL_0038.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912141e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 6060032\n",
      "extracting stimIDs\n",
      "/Volumes/David Laubender/Data/imaging data/DL_191106_2/data/2019-12-17/exp62357_DL_0024.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912171e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 6060288\n",
      "extracting stimIDs\n",
      "/Volumes/David Laubender/Data/imaging data/DL_191106_2/data/2019-12-17/exp62358_DL_0029.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912171e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 6060544\n",
      "extracting stimIDs\n",
      "/Volumes/David Laubender/Data/imaging data/DL_191106_2/data/2020-01-22/exp62400_DL_0017.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.02001221e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 6059776\n",
      "extracting stimIDs\n",
      "/Volumes/David Laubender/Data/imaging data/DL_191106_2/data/2020-01-22/exp62403_DL_0032.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.02001222e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 6060288\n",
      "extracting stimIDs\n",
      "/Volumes/David Laubender/Data/imaging data/DL_191106_2/data/2019-12-21/exp62379_DL_0015.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912211e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 6059520\n",
      "extracting stimIDs\n",
      "/Volumes/David Laubender/Data/imaging data/DL_191106_2/data/2019-12-21/exp62382_DL_0029.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912212e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 6060800\n",
      "extracting stimIDs\n",
      "/Volumes/David Laubender/Data/imaging data/DL_191106_4/data/2019-12-07/exp62300_DL_0021.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912071e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 6256896\n",
      "extracting stimIDs\n",
      "/Volumes/David Laubender/Data/imaging data/DL_191106_4/data/2019-12-07/exp62303_DL_0032.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912071e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 6257664\n",
      "extracting stimIDs\n",
      "/Volumes/David Laubender/Data/imaging data/DL_191106_4/data/2019-12-10/exp62318_DL_0018.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912101e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 6059520\n",
      "extracting stimIDs\n",
      "/Volumes/David Laubender/Data/imaging data/DL_191106_4/data/2019-12-10/exp62321_DL_0030.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912101e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 6060544\n",
      "extracting stimIDs\n",
      "/Volumes/David Laubender/Data/imaging data/DL_191106_4/data/2019-12-19/exp62367_DL_0018.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912191e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 6059776\n",
      "extracting stimIDs\n",
      "/Volumes/David Laubender/Data/imaging data/DL_191106_4/data/2019-12-19/exp62370_DL_0029.lvd\n",
      "Aux sampling frequency = [5000.]Hz\n",
      "# channels = 19\n",
      "timestamp = [2.01912192e+13]\n",
      "max input = [10.] V\n",
      "number of aux datapoints = 6060544\n",
      "extracting stimIDs\n",
      "\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "ids = {}\n",
    "for idx, val in notebook.tqdm(enumerate(exp)):\n",
    "    aux_filename = str(aux_files[idx])\n",
    "    print(aux_filename)\n",
    "    [auxdata, aux_samplingfreq] = load_auxdata(aux_filename)\n",
    "    print('extracting stimIDs')\n",
    "    ids[idx] = get_stimIDs_chirp(auxdata, stimops)\n",
    "    ids[idx]['aux_filename'] = aux_filename\n",
    "    if idx == 0:\n",
    "        ids[idx]['auxdata'] = auxdata\n",
    "    else:\n",
    "        ids[idx]['auxdata'] = []\n",
    "    ids[idx]['aux_samplingfreq'] = aux_samplingfreq\n",
    "    ids[idx]['framerate_auxderived'] = aux_samplingfreq / np.median(np.diff(ids[idx]['FrameTimes']))\n",
    "print('DONE!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot aux_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### raw aux plus stimbounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # only works if all auxdaa is put into ids dictionary (not with the first slice only)\n",
    "# fig = plt.figure(figsize=(8,6))\n",
    "# jump = 0\n",
    "# for idx, val in enumerate(exp):\n",
    "#     plt.subplot(len(exp)*3 +1 ,1,idx+jump+1)\n",
    "#     plotdata = ids[idx]['auxdata'][ids[idx]['FrameTimes_level'],stimops['Stims_chan']]\n",
    "#     plt.plot(plotdata), plt.ylabel('Stims_chan') \n",
    "#     plt.vlines([ids[idx]['Ipsi'][0]],-1,6, 'r')\n",
    "#     plt.vlines([ids[idx]['Ipsi'][1]],-1,6, 'r')\n",
    "#     plt.vlines([ids[idx]['Contra'][0]],-1,6, 'b')\n",
    "#     plt.vlines([ids[idx]['Contra'][1]],-1,6, 'b')\n",
    "#     plt.vlines([ids[idx]['Bino'][0]],-1,6, 'k')\n",
    "#     plt.vlines([ids[idx]['Bino'][1]],-1,6, 'k')\n",
    "#     plt.subplot(len(exp)*3+1 ,1,idx+jump+2)\n",
    "#     plt.plot(ids[idx]['auxdata'][ids[idx]['FrameTimes_level'],stimops['eye1_chan']]), plt.ylabel('eye1_chan') \n",
    "#     plt.subplot(len(exp)*3+1 ,1,idx+jump+3)\n",
    "#     plt.plot(ids[idx]['auxdata'][ids[idx]['FrameTimes_level'],stimops['eye2_chan']]), plt.ylabel('eye2_chan') \n",
    "#     plt.show()\n",
    "#     jump = jump+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(8,6))\n",
    "# plt.subplot(1,1,1)\n",
    "# plt.plot(ids[idx]['auxdata'][:,stimops['Stims_chan']]), plt.ylabel('Stims_chan') \n",
    "# plt.vlines(ids[idx]['FrameTimes_level'][ids[idx]['Ipsi'][0]],-1,6, 'r')\n",
    "# plt.vlines(ids[idx]['FrameTimes_level'][ids[idx]['Ipsi'][1]],-1,6, 'k')\n",
    "# # plt.vlines(ids['Ipsi'][1],-1,6, 'r')\n",
    "# # plt.vlines(ids['Contra'][0],-1,6, 'b')\n",
    "# # plt.vlines(ids['Contra'][1],-1,6, 'b')\n",
    "# # plt.vlines(ids['Bino'][0],-1,6, 'k')\n",
    "# # plt.vlines(ids['Bino'][1],-1,6, 'k')\n",
    "# # plt.subplot(3,1,2)\n",
    "# # plt.plot(auxdata[ids['FrameTimes_level'],stimops['eye1_chan']]), plt.ylabel('eye1_chan') \n",
    "# # plt.subplot(3,1,3)\n",
    "# # plt.plot(auxdata[ids['FrameTimes_level'],stimops['eye2_chan']]), plt.ylabel('eye2_chan') \n",
    "# plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make PSTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = {}\n",
    "Fneu = {}\n",
    "spks = {}\n",
    "stat = {}\n",
    "ops = {}\n",
    "iscell = {}\n",
    "\n",
    "for idx, val in enumerate(exp):\n",
    "    F[idx] = np.load(os.path.join(adata_s2ppath[idx],'F.npy'))\n",
    "    Fneu[idx] = np.load(os.path.join(adata_s2ppath[idx],'Fneu.npy'))\n",
    "    spks[idx] = np.load(os.path.join(adata_s2ppath[idx],'spks.npy'))\n",
    "#     stat[idx] = np.load(os.path.join(adata_s2ppath[0],'stat.npy'), allow_pickle=True)\n",
    "#     ops[idx] = np.load(os.path.join(adata_s2ppath[0],'ops.npy'), allow_pickle=True).item()\n",
    "    iscell[idx] = np.load(os.path.join(adata_s2ppath[idx],'iscell.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop non-cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, val in tqdm(enumerate(exp)):\n",
    "    old_len = len(F[idx])\n",
    "    F[idx] = F[idx][iscell[idx][:,0]==1,:]\n",
    "    Fneu[idx] =Fneu[idx][iscell[idx][:,0]==1,:]\n",
    "    spks[idx] = spks[idx][iscell[idx][:,0]==1,:]\n",
    "    print('exp' + val + ' dropped ' + str(old_len - len(F[idx])) + ' non-boutons (out of ' + str(old_len) + ')' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PANDAS: generate seaborn-compatible, stimulus-chopped long-form pandas and plot (maybe not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['Ipsi', 'Contra', 'Bino'] #ids.keys()\n",
    "ncells = {}\n",
    "prestim = {}\n",
    "poststim = {}\n",
    "prestim_frames = {}\n",
    "poststim_frames = {}\n",
    "\n",
    "for idx, val in enumerate(exp):\n",
    "    ncells[idx] = F[idx].shape[0]\n",
    "    prestim[idx]  = 1 / (ids[idx]['framerate_auxderived']  / level) * 5 #seconds before stimulus\n",
    "    poststim[idx] = 1 / (ids[idx]['framerate_auxderived']  / level) * 5 #seconds after stimulus\n",
    "\n",
    "    prestim_frames[idx] = np.round(prestim[idx]  * (ids[idx]['framerate_auxderived']  / level))\n",
    "    poststim_frames[idx] = np.round(prestim[idx]  * (ids[idx]['framerate_auxderived']  / level))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "dataframe = []\n",
    "maxlength = np.empty(3 * len(exp))\n",
    "jump = 0;\n",
    "\n",
    "for idx, val in enumerate(exp):\n",
    "# allocate PSTH array\n",
    "    maxlength[jump + idx] = np.int(np.ceil(np.diff(ids[idx][\"Contra\"][:], axis = 0).mean() + prestim_frames[idx] + poststim_frames[idx]))\n",
    "    maxlength[jump + idx + 1 ] = np.int(np.ceil(np.diff(ids[idx][\"Ipsi\"][:], axis = 0).mean() + prestim_frames[idx] + poststim_frames[idx]))\n",
    "    maxlength[jump + idx + 2 ] = np.int(np.ceil(np.diff(ids[idx][\"Bino\"][:], axis = 0).mean() + prestim_frames[idx] + poststim_frames[idx]))\n",
    "    jump = jump + 2\n",
    "\n",
    "maxlength = np.int(np.max(maxlength))\n",
    "# for cell in tqdm(np.random.randint(0,ncells,5)):\n",
    "\n",
    "cellglob = 0\n",
    "\n",
    "for idx, expval in enumerate(exp):\n",
    "    #print(cellglob)\n",
    "    for cell in tqdm(range(ncells[idx])):\n",
    "        for category in categories:\n",
    "            for trial, val in enumerate(ids[idx][category][0]):\n",
    "\n",
    "                aligned_F = np.empty((1,maxlength)).squeeze()\n",
    "                aligned_F.fill(np.NaN)\n",
    "                aligned_Fneu = np.empty((1,maxlength)).squeeze()\n",
    "                aligned_Fneu.fill(np.NaN)\n",
    "                aligned_spks = np.empty((1,maxlength)).squeeze()\n",
    "                aligned_spks.fill(np.NaN)\n",
    "                aligned_stimdata = np.empty((1,maxlength)).squeeze()\n",
    "                aligned_stimdata.fill(np.NaN)\n",
    "\n",
    "                slice_range = np.arange(ids[idx][category][0][trial].astype(int)-prestim_frames[idx].astype(int),ids[idx][category][1][trial].astype(int)+poststim_frames[idx].astype(int))\n",
    "\n",
    "                aligned_stimdata[0:len(slice_range)] = auxdata[ids[idx]['FrameTimes_level'][slice_range],stimops['Stims_chan']]\n",
    "    #             aligned_stimdata = auxdata[ids['FrameTimes_level'][slice_range][0]:ids['FrameTimes_level'][slice_range][-1],stimops['Stims_chan']]\n",
    "\n",
    "                aligned_F[0:len(slice_range)] = F[idx][cell,slice_range]\n",
    "                aligned_Fneu[0:len(slice_range)] = Fneu[idx][cell,slice_range]\n",
    "                aligned_spks[0:len(slice_range)] = spks[idx][cell,slice_range]\n",
    "\n",
    "                time = np.arange(0, aligned_F.shape[0] * 1 / (ids[idx]['framerate_auxderived'] / level), 1 / (ids[idx]['framerate_auxderived'] / level) ) - prestim[idx]\n",
    "                aux_time = np.arange(0, aligned_stimdata.shape[0] * 1 / (ids[idx]['framerate_auxderived'] / level), 1 / (ids[idx]['framerate_auxderived'] / level)  ) - prestim[idx]\n",
    "                \n",
    "                layer = load_df[load_df['experiment'] == int(expval)]['Layer'].to_numpy(),\n",
    "                \n",
    "                dfs.append(pd.DataFrame({\n",
    "                                        'experimentator': experimentator[0],\n",
    "                                        'mouse': mouse[0],\n",
    "                                        'date': date[0],\n",
    "                                        'experiment': experiment[0],\n",
    "                                        'cell': cellglob,\n",
    "                                        'layer': Layer[0],\n",
    "                                        'elevation': Elevation[0],\n",
    "                                        'time': time,\n",
    "                                        'auxtime':aux_time,\n",
    "                                        'aux_files': aux_files[0],\n",
    "                                        'aligned_stimdata': aligned_stimdata,\n",
    "                                        'trial':trial,\n",
    "                                        'aligned_F': aligned_F,\n",
    "                                        'aligned_spks': aligned_spks,\n",
    "                                        'aligned_Fneu': aligned_Fneu,\n",
    "                                        'category': category,\n",
    "                                        'adata_s2ppath': adata_s2ppath[0],\n",
    "                                        'SI_level': level,\n",
    "                                        'SI_zoom': zoom,\n",
    "                                        'SI_framerate': framerate,\n",
    "                                        'SI_framerate_aux_derived': ids[idx]['framerate_auxderived'][0],\n",
    "                                        'SI_channels': channels,\n",
    "                                        'SI_volumes': volumes,\n",
    "                                        'SI_frames': frames,\n",
    "                                        'SI_frames_per_file': frames_per_file,\n",
    "                                        'SI_tiffpath': adata_tiffpath[0],\n",
    "                                        'SI_single_tiff_file': single_tiff_file[0]\n",
    "\n",
    "                                        }))\n",
    "        cellglob += 1\n",
    "    dataframe = pd.concat(dfs, axis=0)\n",
    "    \n",
    "\n",
    "# TODO\n",
    "# - include Fneu, dF/F (-Fneu), reconvolved\n",
    "# - functionalize\n",
    "# - aggregate over all recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save dataframe here\n",
    "dataframe.to_pickle('layer1_and_4_mac.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save stimids here\n",
    "with open('Chirp_ids_new.pkl', 'wb') as handle:\n",
    "    pickle.dump(ids, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'Simple' one-liners to get trial averages over all cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.subplot(2,3,1)\n",
    "dataframe.loc[dataframe.loc[:,'category'] == 'Ipsi'].groupby(['time', 'cell'], as_index=False).aligned_spks.mean().pivot(index = 'time', columns='cell').mean(axis = 1).plot()\n",
    "plt.subplot(2,3,2)\n",
    "dataframe.loc[dataframe.loc[:,'category'] == 'Contra'].groupby(['time', 'cell'], as_index=False).aligned_spks.mean().pivot(index = 'time', columns='cell').mean(axis = 1).plot()\n",
    "plt.subplot(2,3,3)\n",
    "dataframe.loc[dataframe.loc[:,'category'] == 'Bino'].groupby(['time', 'cell'], as_index=False).aligned_spks.mean().pivot(index = 'time', columns='cell').mean(axis = 1).plot()\n",
    "plt.subplot(2,3,4)\n",
    "dataframe.loc[dataframe.loc[:,'category'] == 'Ipsi'].groupby(['time', 'cell'], as_index=False).aligned_F.mean().pivot(index = 'time', columns='cell').mean(axis = 1).plot()\n",
    "plt.subplot(2,3,5)\n",
    "dataframe.loc[dataframe.loc[:,'category'] == 'Contra'].groupby(['time', 'cell'], as_index=False).aligned_F.mean().pivot(index = 'time', columns='cell').mean(axis = 1).plot()\n",
    "plt.subplot(2,3,6)\n",
    "dataframe.loc[dataframe.loc[:,'category'] == 'Bino'].groupby(['time', 'cell'], as_index=False).aligned_F.mean().pivot(index = 'time', columns='cell').mean(axis = 1).plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate sorted mean-cell responses / zscores or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate sorted mean-cell responses / zscores or not\n",
    "\n",
    "allcells_Ipsi_mean = dataframe.loc[dataframe.loc[:,'category'] == 'Ipsi'].groupby(['time', 'cell'], as_index=False).aligned_spks.mean().pivot(index = 'time', columns='cell')\n",
    "allcells_Ipsi_mean_zscored = allcells_Ipsi_mean.transform((lambda x : z_score(x)))\n",
    "sortidx = allcells_Ipsi_mean_zscored.max().sort_values(ascending=False).index\n",
    "allcells_Ipsi_mean_sort_zscored = allcells_Ipsi_mean_zscored.reindex(sortidx, axis = 1)\n",
    "\n",
    "allcells_Contra_mean = dataframe.loc[dataframe.loc[:,'category'] == 'Contra'].groupby(['time', 'cell'], as_index=False).aligned_spks.mean().pivot(index = 'time', columns='cell')\n",
    "allcells_Contra_mean_zscored = allcells_Contra_mean.transform((lambda x : z_score(x)))\n",
    "sortidx = allcells_Contra_mean_zscored.max().sort_values(ascending=False).index\n",
    "allcells_Contra_mean_sort_zscored = allcells_Contra_mean_zscored.reindex(sortidx, axis = 1)\n",
    "\n",
    "allcells_Bino_mean = dataframe.loc[dataframe.loc[:,'category'] == 'Bino'].groupby(['time', 'cell'], as_index=False).aligned_spks.mean().pivot(index = 'time', columns='cell')\n",
    "allcells_Bino_mean_zscored = allcells_Bino_mean.transform((lambda x : z_score(x)))\n",
    "sortidx = allcells_Bino_mean_zscored.max().sort_values(ascending=False).index\n",
    "allcells_Bino_mean_sort_zscored = allcells_Bino_mean_zscored.reindex(sortidx, axis = 1)\n",
    "\n",
    "\n",
    "allcells_Ipsi_mean = dataframe.loc[dataframe.loc[:,'category'] == 'Ipsi'].groupby(['time', 'cell'], as_index=False).aligned_spks.mean().pivot(index = 'time', columns='cell')\n",
    "sortidx2 = allcells_Ipsi_mean.max().sort_values(ascending=False).index\n",
    "allcells_Ipsi_mean_sort = allcells_Ipsi_mean.reindex(sortidx2, axis = 1)\n",
    "\n",
    "allcells_Contra_mean = dataframe.loc[dataframe.loc[:,'category'] == 'Contra'].groupby(['time', 'cell'], as_index=False).aligned_spks.mean().pivot(index = 'time', columns='cell')\n",
    "sortidx2 = allcells_Contra_mean.max().sort_values(ascending=False).index\n",
    "allcells_Contra_mean_sort = allcells_Contra_mean.reindex(sortidx2, axis = 1)\n",
    "\n",
    "allcells_Bino_mean = dataframe.loc[dataframe.loc[:,'category'] == 'Bino'].groupby(['time', 'cell'], as_index=False).aligned_spks.mean().pivot(index = 'time', columns='cell')\n",
    "sortidx2 = allcells_Bino_mean.max().sort_values(ascending=False).index\n",
    "allcells_Bino_mean_sort = allcells_Bino_mean.reindex(sortidx2, axis = 1)\n",
    "\n",
    "\n",
    "# allcells_Ipsi_mean = dataframe.loc[dataframe.loc[:,'category'] == 'Ipsi'].groupby(['time', 'cell'], as_index=False).aligned_F.mean().pivot(index = 'time', columns='cell')\n",
    "# allcells_Ipsi_mean_zscored = allcells_Ipsi_mean.transform((lambda x : z_score(x)))\n",
    "# sortidx = allcells_Ipsi_mean_zscored.max().sort_values(ascending=False).index\n",
    "# allcells_Ipsi_mean_sort_zscored = allcells_Ipsi_mean_zscored.reindex(sortidx, axis = 1)\n",
    "\n",
    "# allcells_Contra_mean = dataframe.loc[dataframe.loc[:,'category'] == 'Contra'].groupby(['time', 'cell'], as_index=False).aligned_F.mean().pivot(index = 'time', columns='cell')\n",
    "# allcells_Contra_mean_zscored = allcells_Contra_mean.transform((lambda x : z_score(x)))\n",
    "# sortidx = allcells_Contra_mean_zscored.max().sort_values(ascending=False).index\n",
    "# allcells_Contra_mean_sort_zscored = allcells_Contra_mean_zscored.reindex(sortidx, axis = 1)\n",
    "\n",
    "# allcells_Bino_mean = dataframe.loc[dataframe.loc[:,'category'] == 'Bino'].groupby(['time', 'cell'], as_index=False).aligned_F.mean().pivot(index = 'time', columns='cell')\n",
    "# allcells_Bino_mean_zscored = allcells_Bino_mean.transform((lambda x : z_score(x)))\n",
    "# sortidx = allcells_Bino_mean_zscored.max().sort_values(ascending=False).index\n",
    "# allcells_Bino_mean_sort_zscored = allcells_Bino_mean_zscored.reindex(sortidx, axis = 1)\n",
    "\n",
    "\n",
    "# allcells_Ipsi_mean = dataframe.loc[dataframe.loc[:,'category'] == 'Ipsi'].groupby(['time', 'cell'], as_index=False).aligned_F.mean().pivot(index = 'time', columns='cell')\n",
    "# sortidx2 = allcells_Ipsi_mean.max().sort_values(ascending=False).index\n",
    "# allcells_Ipsi_mean_sort = allcells_Ipsi_mean.reindex(sortidx2, axis = 1)\n",
    "\n",
    "# allcells_Contra_mean = dataframe.loc[dataframe.loc[:,'category'] == 'Contra'].groupby(['time', 'cell'], as_index=False).aligned_F.mean().pivot(index = 'time', columns='cell')\n",
    "# sortidx2 = allcells_Contra_mean.max().sort_values(ascending=False).index\n",
    "# allcells_Contra_mean_sort = allcells_Contra_mean.reindex(sortidx2, axis = 1)\n",
    "\n",
    "# allcells_Bino_mean = dataframe.loc[dataframe.loc[:,'category'] == 'Bino'].groupby(['time', 'cell'], as_index=False).aligned_F.mean().pivot(index = 'time', columns='cell')\n",
    "# allcells_Bino_mean_zscored = allcells_Bino_mean.transform((lambda x : z_score(x)))\n",
    "# sortidx2 = allcells_Bino_mean.max().sort_values(ascending=False).index\n",
    "# allcells_Bino_mean_sort = allcells_Bino_mean.reindex(sortidx2, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot maps\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "\n",
    "with sns.axes_style('white'):\n",
    "    plt.subplot(2,3,1)\n",
    "    plt.imshow(allcells_Ipsi_mean_sort_zscored.T, vmax = 3, vmin = -0.5, aspect = 'auto', cmap = 'Reds')\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('bouton')\n",
    "    plt.title('Ipsi')\n",
    "    plt.vlines([prestim_frames[idx], maxlength - poststim_frames[idx]],0,ncells-1, 'k')\n",
    "    \n",
    "    plt.subplot(2,3,2)\n",
    "    plt.imshow(allcells_Contra_mean_sort_zscored.T, vmax = 3, vmin = -0.5, aspect = 'auto', cmap = 'Blues')\n",
    "    plt.xlabel('time')\n",
    "    plt.title('Contra')\n",
    "    plt.vlines([prestim_frames[idx], maxlength - poststim_frames[idx]],0,ncells-1, 'k')\n",
    "        \n",
    "    plt.subplot(2,3,3)\n",
    "    plt.imshow(allcells_Bino_mean_sort_zscored.T, vmax = 3, vmin = -0.5, aspect = 'auto', cmap = 'gray_r')\n",
    "    plt.xlabel('time [s]')\n",
    "    plt.colorbar(label='zscore')\n",
    "    plt.title('Bino')\n",
    "    plt.vlines([prestim_frames[idx], maxlength - poststim_frames[idx]],0,ncells-1, 'k')\n",
    "    \n",
    "    plt.subplot(2,3,4)\n",
    "    plt.imshow(allcells_Ipsi_mean_sort.T, vmax = 4, vmin = -.5, aspect = 'auto', cmap = 'Reds')\n",
    "    plt.xlabel('time')\n",
    "    plt.ylabel('bouton')\n",
    "    plt.title('Ipsi')\n",
    "    plt.vlines([prestim_frames[idx], maxlength - poststim_frames[idx]],0,ncells-1, 'k')\n",
    "    \n",
    "    plt.subplot(2,3,5)\n",
    "    plt.imshow(allcells_Contra_mean_sort.T, vmax = 4, vmin = -.5, aspect = 'auto', cmap = 'Blues')\n",
    "    plt.xlabel('time')\n",
    "    plt.title('Contra')\n",
    "    plt.vlines([prestim_frames[idx], maxlength - poststim_frames[idx]],0,ncells-1, 'k')\n",
    "    \n",
    "    plt.subplot(2,3,6)\n",
    "    plt.imshow(allcells_Bino_mean_sort.T, vmax = 4, vmin = -.5, aspect = 'auto', cmap = 'gray_r')\n",
    "    plt.xlabel('time [s]')\n",
    "    plt.title('Bino')\n",
    "    plt.colorbar(label='deconvolved F [a.u.]')\n",
    "    plt.vlines([prestim_frames[idx], maxlength - poststim_frames[idx]],0,ncells-1, 'k')\n",
    "    \n",
    "    \n",
    "    \n",
    "#     plt.subplot(2,3,4)\n",
    "#     plt.imshow(allcells_Ipsi_mean_sort.T, vmax = 150, vmin = 30, aspect = 'auto', cmap = 'Reds')\n",
    "#     plt.xlabel('time')\n",
    "#     plt.ylabel('bouton')\n",
    "#     plt.title('Ipsi')\n",
    "#     plt.vlines([prestim_frames, maxlength - poststim_frames],0,ncells-1, 'k')\n",
    "    \n",
    "#     plt.subplot(2,3,5)\n",
    "#     plt.imshow(allcells_Contra_mean_sort.T, vmax = 150, vmin = 30, aspect = 'auto', cmap = 'Blues')\n",
    "#     plt.xlabel('time')\n",
    "#     plt.title('Contra')\n",
    "#     plt.vlines([prestim_frames, maxlength - poststim_frames],0,ncells-1, 'k')\n",
    "    \n",
    "#     plt.subplot(2,3,6)\n",
    "#     plt.imshow(allcells_Bino_mean_sort.T, vmax = 150, vmin = 30, aspect = 'auto', cmap = 'gray_r')\n",
    "#     plt.xlabel('time [s]')\n",
    "#     plt.title('Bino')\n",
    "#     plt.colorbar(label='F')\n",
    "#     plt.vlines([prestim_frames, maxlength - poststim_frames],0,ncells-1, 'k')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rastermap sortings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all cells\n",
    "sp_ipsi = allcells_Ipsi_mean_zscored.to_numpy()\n",
    "sp_contra = allcells_Contra_mean_zscored.to_numpy()\n",
    "sp_bino = allcells_Bino_mean_zscored.to_numpy()\n",
    "\n",
    "sp_all = np.concatenate((allcells_Contra_mean.to_numpy(), allcells_Ipsi_mean.to_numpy(), allcells_Bino_mean.to_numpy()), axis = 0)\n",
    "\n",
    "sp_ipsi[np.isnan(sp_ipsi)] = 0\n",
    "sp_contra[np.isnan(sp_contra)] = 0\n",
    "sp_bino[np.isnan(sp_bino)] = 0\n",
    "\n",
    "sp_all[np.isnan(sp_all)] = 0\n",
    "\n",
    "sp_all = zscore(sp_all, axis = 1, nan_policy = 'omit') # needs to be done in numpy to be element-wise here - I collapsed the major categories. I dont think I can do that in pandas straight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "model_ipsi = rm.mapping.Rastermap(n_components=1).fit(sp_ipsi.T)\n",
    "model_contra = rm.mapping.Rastermap(n_components=1).fit(sp_contra.T)\n",
    "model_bino = rm.mapping.Rastermap(n_components=1).fit(sp_bino.T)\n",
    "model_all = rm.mapping.Rastermap(n_components=1).fit(sp_all.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### sort neurons and smooth across neurons \n",
    "smooth = True\n",
    "timesmooth = True\n",
    "\n",
    "if smooth:\n",
    "    isort = np.argsort(model_all.embedding[:,0])   \n",
    "    Sm_ipsi = gaussian_filter1d(sp_ipsi.T[isort,:], np.minimum(3,int(sp_ipsi.shape[0]*0.005)), axis=0)\n",
    "    # isort = np.argsort(model_contra.embedding[:,0])\n",
    "    Sm_contra = gaussian_filter1d(sp_contra.T[isort,:], np.minimum(3,int(sp_contra.shape[0]*0.005)), axis=0)\n",
    "    # isort = np.argsort(model_bino.embedding[:,0])\n",
    "    Sm_bino = gaussian_filter1d(sp_bino.T[isort,:], np.minimum(3,int(sp_bino.shape[0]*0.005)), axis=0)\n",
    "    Sm_all  = gaussian_filter1d(sp_all.T[isort,:], np.minimum(3,int(sp_ipsi.shape[0]*0.005)), axis=0)\n",
    "#     Sm_all= sp_all.T[isort,:]\n",
    "else:\n",
    "    isort = np.argsort(model_bino.embedding[:,0])\n",
    "    Sm_ipsi = sp_ipsi.T[isort,:]\n",
    "    # isort = np.argsort(model_contra.embedding[:,0])\n",
    "    Sm_contra = sp_contra.T[isort,:]\n",
    "    # isort = np.argsort(model_bino.embedding[:,0])\n",
    "    Sm_bino = sp_bino.T[isort,:]\n",
    "    Sm_all  = sp_all.T[isort,:]\n",
    "    \n",
    "if timesmooth:\n",
    "    sigma = 0.5\n",
    "# (optional) smooth in time\n",
    "    Sm_contra = gaussian_filter1d(Sm_contra, sigma, axis=1)\n",
    "    Sm_ipsi = gaussian_filter1d(Sm_ipsi, sigma, axis=1)\n",
    "    Sm_bino = gaussian_filter1d(Sm_bino, sigma, axis=1)\n",
    "    Sm_all = gaussian_filter1d(Sm_all, sigma, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### auxdata and timebase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_range = np.arange(ids[0]['Ipsi'][0][1].astype(int)-prestim_frames[0].astype(int),ids[0]['Ipsi'][1][1].astype(int)+poststim_frames[0].astype(int)+1)\n",
    "# slice_range = np.arange(ids[category][0][trial].astype(int)-prestim_frames.astype(int),ids[category][1][trial].astype(int)+poststim_frames.astype(int))\n",
    "\n",
    "aligned_stimdata = auxdata[ids[0]['FrameTimes_level'][slice_range],stimops['Stims_chan']]\n",
    "# aligned_stimdata_concat = np.tile(auxdata[ids['FrameTimes_level'][slice_range],stimops['Stims_chan']], (0,3))\n",
    "aux_time = np.arange(0, aligned_stimdata.shape[0] * 1 / (ids[0]['framerate_auxderived'] / level), 1 / (ids[0]['framerate_auxderived'] / level) ) - prestim[0]\n",
    "\n",
    "aligned_stimdata_full = ids[0]['auxdata'][ids[0]['FrameTimes_level'][slice_range[0]]:ids[0]['FrameTimes_level'][slice_range[-1]],stimops['Stims_chan']]\n",
    "aligned_stimdata_full_concat = np.tile(aligned_stimdata_full, (1,3)).T\n",
    "\n",
    "aux_time_full = np.arange(0, aligned_stimdata_full.shape[0] * 1 / ids[0]['aux_samplingfreq'] , 1 / ids[0]['aux_samplingfreq']    ) - prestim[0]\n",
    "aux_time_full_concat = np.arange(0, aligned_stimdata_full_concat.shape[0] * 1 / ids[0]['aux_samplingfreq'] , 1 / ids[0]['aux_samplingfreq']   ) - prestim[0]\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(aux_time, aligned_stimdata)\n",
    "# plt.plot(aux_time_full_concat, aligned_stimdata_full_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seperately sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### view neuron sorting\n",
    "\n",
    "# aligned_stimdata = auxdata[ids['FrameTimes_level'][slice_range][0]:ids['FrameTimes_level'][slice_range][-1],stimops['Stims_chan']]\n",
    "# aux_time = np.arange(0, aligned_stimdata.shape[0] * 1 / aux_samplingfreq, 1 / aux_samplingfreq  ) - prestim\n",
    "\n",
    "fs = ids[0]['framerate_auxderived'] / level\n",
    "vmin_glob = -.5\n",
    "vmax_glob = 2.5\n",
    "ncells = cellglob \n",
    "with sns.axes_style('white'):\n",
    "    xl = [-prestim[0],Sm_contra.shape[1]/fs-prestim[0]]\n",
    "    \n",
    "    fig8 = plt.figure(figsize=(20,16), constrained_layout=True)\n",
    "    gs1 = fig8.add_gridspec(nrows=8, ncols=3)\n",
    "    \n",
    "    fig8.add_subplot(gs1[1:, :-2])      \n",
    "    fig8_ax=plt.imshow(Sm_contra, vmin=vmin_glob,vmax=vmax_glob,aspect='auto',extent=[-prestim[0],Sm_contra.shape[1]/fs-prestim[0], 0,Sm_contra.shape[0]], cmap = 'Blues')\n",
    "    plt.xlabel('time (s)', fontsize=18)    \n",
    "    \n",
    "    plt.vlines([prestim_frames[0] / fs-prestim[0], maxlength / fs - poststim_frames[0] / fs -prestim[0] ],0,ncells-1, 'k')\n",
    "    plt.ylabel('boutons', fontsize=18)     \n",
    "        \n",
    "    f8_ax2 = fig8.add_subplot(gs1[1:, 1:-1])\n",
    "    ax=plt.imshow(Sm_ipsi, vmin=vmin_glob,vmax=vmax_glob,aspect='auto',extent=[-prestim[0],Sm_ipsi.shape[1]/fs-prestim[0], 0,Sm_ipsi.shape[0]], cmap = 'Reds')\n",
    "    plt.xlabel('time (s)', fontsize=18)\n",
    "    \n",
    "    plt.vlines([prestim_frames[0] / fs-prestim[0], maxlength / fs - poststim_frames[0] / fs -prestim[0] ],0,ncells-1, 'k')\n",
    "        \n",
    "    f8_ax3 = fig8.add_subplot(gs1[1:, 2:])\n",
    "    ax=plt.imshow(Sm_bino, vmin=vmin_glob,vmax=vmax_glob,aspect='auto',extent=[-prestim[0],Sm_bino.shape[1]/fs-prestim[0], 0,Sm_bino.shape[0]], cmap = 'gray_r')\n",
    "    plt.xlabel('time (s)', fontsize=18)\n",
    "    \n",
    "    plt.vlines([prestim_frames[0] / fs-prestim[0], maxlength / fs - poststim_frames[0] / fs -prestim[0]],0,ncells-1, 'k')\n",
    "\n",
    "#    plt.colorbar(label='deconvolved F [a.u.]')\n",
    "   \n",
    "    f8_ax4 = fig8.add_subplot(gs1[:1, :-2])    \n",
    "    plt.plot(aux_time_full, aligned_stimdata_full, 'k')\n",
    "#     plt.vlines([prestim_frames / fs-prestim, maxlength / fs - poststim_frames / fs -prestim],0,4, 'k')\n",
    "    f8_ax4.set_xlim(*xl)\n",
    "    f8_ax4.axis('off')\n",
    "    plt.title('Contra')\n",
    "    \n",
    "    f8_ax5 = fig8.add_subplot(gs1[:1, 1:-1])\n",
    "    plt.plot(aux_time_full, aligned_stimdata_full, 'k')\n",
    "    f8_ax5.set_xlim(*xl)\n",
    "    f8_ax5.axis('off')\n",
    "    plt.title('Ipsi')\n",
    "\n",
    "    \n",
    "    f8_ax6 = fig8.add_subplot(gs1[:1, 2:])\n",
    "    plt.plot(aux_time_full, aligned_stimdata_full, 'k')\n",
    "    f8_ax6.set_xlim(*xl)\n",
    "    f8_ax6.axis('off')\n",
    "    plt.title('Bino')    \n",
    "    \n",
    "#     plt.tight_layout()           \n",
    "    plt.suptitle('z-scored deconvolved Chirp PSTHs - rastermap embedding (sorted on Bino, smoothened over boutons) - exp' + exp[0])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('separate.eps', format='eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concatenated figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### view neuron sorting\n",
    "\n",
    "# aligned_stimdata = auxdata[ids['FrameTimes_level'][slice_range][0]:ids['FrameTimes_level'][slice_range][-1],stimops['Stims_chan']]\n",
    "# aux_time = np.arange(0, aligned_stimdata.shape[0] * 1 / aux_samplingfreq, 1 / aux_samplingfreq  ) - prestim\n",
    "\n",
    "fs = ids[0]['framerate_auxderived'] / level\n",
    "vmin_glob = -.5\n",
    "vmax_glob = 2.5\n",
    "\n",
    "with sns.axes_style('white'):\n",
    "    xl = [-prestim[0],Sm_all.shape[1]/fs - prestim[0]]\n",
    "    \n",
    "    fig9 = plt.figure(figsize=(20,20), constrained_layout=True)\n",
    "    \n",
    "    gs1 = fig9.add_gridspec(nrows=12, ncols=3)\n",
    "    \n",
    "    fig9.add_subplot(gs1[1:, :])      \n",
    "    fig9_ax=plt.imshow(Sm_all, vmin=vmin_glob,vmax=vmax_glob,aspect='auto',extent=[-prestim[0],Sm_all.shape[1]/fs-prestim[0], 0,Sm_all.shape[0]], cmap = 'gray_r')\n",
    "    plt.xlabel('time (s)', fontsize=18)    \n",
    "    \n",
    "#     plt.vlines([prestim_frames / fs-prestim, maxlength / fs - poststim_frames / fs -prestim ],0,ncells-1, 'k')\n",
    "    plt.ylabel('boutons', fontsize=18)     \n",
    "    \n",
    "    plt.vlines([aux_time_full[-1],  +aux_time_full[-1] *2 + poststim[0]],0,ncells-1, 'r')\n",
    "    plt.vlines([prestim_frames[0] / fs-prestim[0], maxlength / fs - poststim_frames[0] / fs -prestim[0]],0,ncells-1, 'b')\n",
    "    \n",
    "    plt.vlines([aux_time_full[-1] + (prestim_frames[0] / fs),  aux_time_full[-1] + (maxlength / fs - poststim_frames[0] / fs ) ],0,ncells-1, 'b')\n",
    "    plt.vlines([2 * aux_time_full[-1] + (prestim_frames[0] / fs) + prestim[0],  2 * aux_time_full[-1] + (maxlength / fs - poststim_frames[0] / fs ) + prestim[0]],0,ncells-1, 'b')\n",
    "#     plt.plot(aux_time_full_concat, aligned_stimdata_full_concat, 'k')\n",
    "    \n",
    "#     plt.colorbar(label='deconvolved F [zscored]')\n",
    "#     plt.colorbar(label='deconvolved F [a.u.]')\n",
    "   \n",
    "    f9_ax4 = fig9.add_subplot(gs1[:1, :])    \n",
    "    plt.plot(aux_time_full_concat, aligned_stimdata_full_concat, 'k')\n",
    "#     plt.vlines([prestim_frames / fs-prestim, maxlength / fs - poststim_frames / fs -prestim],0,4, 'k')\n",
    "    f9_ax4.set_xlim(*xl)\n",
    "    f9_ax4.axis('off')\n",
    "#     plt.title('Contra                                    Ipsi                                    Bino')\n",
    "    plt.text(aux_time_full[-1] / 2 - 2, 5 , 'Contra', fontsize=16)\n",
    "    plt.text(aux_time_full[-1] * 1.5-2, 5 , 'Ipsi', fontsize=16)\n",
    "    plt.text(aux_time_full[-1] * 2.5-2, 5 , 'Bino', fontsize=16)   \n",
    "    \n",
    "#     plt.tight_layout()           \n",
    "    plt.suptitle('z-scored deconvolved F - Chirp PSTHs - rastermap embedding (smoothened over boutons) - exp' + exp[0])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('all.eps', format='eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMF on PSTHs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = 29\n",
    "compstr = ['Comp ' + str(idx) for idx in range(components)]\n",
    "\n",
    "nmf = NMF(n_components=components, solver=\"mu\")\n",
    "\n",
    "# sp_all[sp_all < 0] = 0\n",
    "sp_contra[sp_contra < 0] = 0\n",
    "\n",
    "W = nmf.fit_transform(sp_contra.T)\n",
    " \n",
    "H = nmf.components_\n",
    "\n",
    "comp_df_H = pd.DataFrame(H.T, columns=compstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sm_all = nmf.inverse_transform(W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = components\n",
    "cols = int(np.ceil(components / rows))\n",
    "\n",
    "fig, axs = plt.subplots(rows,cols, figsize=(15, rows*2), facecolor='w', edgecolor='k')\n",
    "# fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "\n",
    "k = 0\n",
    "\n",
    "for ax, d in zip(axs.ravel(), H):\n",
    "    k += 1\n",
    "    ax.plot(time, d)\n",
    "#     ax.plot(d)\n",
    "    ax.set_title('component' + str(k))\n",
    "    ax.vlines([prestim_frames[0] / fs-prestim[0], maxlength / fs - poststim_frames[0] / fs -prestim[0]],0,4, 'k')\n",
    "# plt.figure() \n",
    "# for x in \n",
    "# sns.heatmap(data = comp_df_H.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style('white'):\n",
    "    \n",
    "    xl = [-prestim[0],Sm_all.shape[1]/fs - prestim[0]]\n",
    "    \n",
    "    fig10 = plt.figure(figsize=(20,20), constrained_layout=True)\n",
    "    \n",
    "    gs1 = fig10.add_gridspec(nrows=12, ncols=3)\n",
    "    \n",
    "    fig10.add_subplot(gs1[1:, :])      \n",
    "    fig10_ax=plt.imshow(Sm_all, vmin=vmin_glob,vmax=vmax_glob,aspect='auto',extent=[-prestim[0],Sm_all.shape[1]/fs-prestim[0], 0,Sm_all.shape[0]], cmap = 'gray_r')\n",
    "    plt.xlabel('time (s)', fontsize=18)    \n",
    "    \n",
    "#     plt.vlines([prestim_frames / fs-prestim, maxlength / fs - poststim_frames / fs -prestim ],0,ncells-1, 'k')\n",
    "    plt.ylabel('boutons', fontsize=18)     \n",
    "    \n",
    "    plt.vlines([aux_time_full[-1],  +aux_time_full[-1] *2 + poststim[0]],0,ncells-1, 'r')\n",
    "    plt.vlines([prestim_frames[0] / fs-prestim[0], maxlength / fs - poststim_frames[0] / fs -prestim[0]],0,ncells-1, 'b')\n",
    "    \n",
    "    plt.vlines([aux_time_full[-1] + (prestim_frames[0] / fs),  aux_time_full[-1] + (maxlength / fs - poststim_frames[0] / fs ) ],0,ncells-1, 'b')\n",
    "    plt.vlines([2 * aux_time_full[-1] + (prestim_frames[0] / fs) + prestim[0],  2 * aux_time_full[-1] + (maxlength / fs - poststim_frames[0] / fs ) + prestim[0]],0,ncells-1, 'b')\n",
    "#     plt.plot(aux_time_full_concat, aligned_stimdata_full_concat, 'k')\n",
    "    \n",
    "#     plt.colorbar(label='deconvolved F [zscored]')\n",
    "#    plt.colorbar(label='deconvolved F [a.u.]')\n",
    "   \n",
    "    f10_ax4 = fig10.add_subplot(gs1[:1, :])    \n",
    "    plt.plot(aux_time_full_concat, aligned_stimdata_full_concat, 'k')\n",
    "#     plt.vlines([prestim_frames / fs-prestim, maxlength / fs - poststim_frames / fs -prestim],0,4, 'k')\n",
    "    f10_ax4.set_xlim(*xl)\n",
    "    f10_ax4.axis('off')\n",
    "#     plt.title('Contra                                    Ipsi                                    Bino')\n",
    "    plt.text(aux_time_full[-1] / 2 - 2, 5 , 'Contra', fontsize=16)\n",
    "    plt.text(aux_time_full[-1] * 1.5-2, 5 , 'Ipsi', fontsize=16)\n",
    "    plt.text(aux_time_full[-1] * 2.5-2, 5 , 'Bino', fontsize=16)  \n",
    "    \n",
    "#     plt.tight_layout()           \n",
    "    plt.suptitle('z-scored deconvolved F - Chirp PSTHs - rastermap embedding (smoothened over boutons) - exp' + exp[0])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rastermap embedding exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = rm.mapping.Rastermap(n_components=2, n_X=40,  nPC=400, init='pca')\n",
    "embedding = model_contra.fit_transform(sp_contra.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(embedding*40)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding[isort]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = sp_contra.T\n",
    "\n",
    "NN, NT = S.shape \n",
    "\n",
    "# reshape and sum S across neurons to get \"components\"\n",
    "nc = 100\n",
    "NC = int(np.floor(NN / nc))\n",
    "Sp = np.reshape(S[isort][:nc*NC], (NC, nc, NT))\n",
    "Sp = Sp.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sp = np.reshape(S[isort][:nc*NC], (NC, nc, NT))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S[isort][:nc*NC].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results here\n",
    "cmap = plt.get_cmap('gist_ncar')\n",
    "cmap = cmap(np.linspace(0,.97,32))\n",
    "cmap = cmap[np.random.permutation(32),:]\n",
    "plt.figure(figsize=(6,6))\n",
    "# each point is colored based on stimulus identity\n",
    "istim = np.ones(len(sp_ipsi.T), dtype = 'int')\n",
    "plt.scatter(out2[:,0],out2[:,1],color=cmap[istim,:],marker='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(melted_aux[[:,0]], melted_aux[[0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_aux.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Panda convert to long form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted = dataframe.melt(id_vars=['category', 'time', 'trial', 'cell'], value_vars=['aligned_F'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### generating trial numpy array from single cell and condition\n",
    "\n",
    "arr = melted.loc[(melted.loc[:,'trial'] < 8) & (melted.loc[:,'cell'] == 1) & (melted.loc[:,'category'] == 'Bino'),'value'].to_numpy()\n",
    "arr = arr.reshape(8,maxlength)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Panda slicing examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot single cell including individual trials and means - seaborn and other\n",
    "\n",
    "# generating trial dataframe from single cell and condtion - SINGLE TRIAL\n",
    "subselected_orig = melted.loc[(melted.loc[:,'trial'] == 1) & (melted.loc[:,'cell'] == 1) & (melted.loc[:,'category'] == 'Contra'),['time', 'value', 'trial']]\n",
    "\n",
    "# generating trial dataframe from single cell and condtion - ALL TRIALS\n",
    "subselected_orig = melted.loc[(melted.loc[:,'cell'] == 1) & (melted.loc[:,'category'] == 'Contra'),['time', 'value', 'trial']]\n",
    "\n",
    "# reshape ('pivot') to index over time and have single trial columns\n",
    "subselected = subselected_orig.pivot(index = 'time', columns='trial', values='value')\n",
    "\n",
    "# reshape ('pivot') to index over time and have single trial columns - zscore on the fly\n",
    "# subselected = subselected_orig.pivot(index = 'time', columns='trial', values='value').transform((lambda x : zscore(x)))\n",
    "\n",
    "subselected = (subselected - subselected.mean())/subselected.std(ddof=0)\n",
    "\n",
    "# generate mean from that\n",
    "\n",
    "subselected_mean = subselected.mean(axis = 1)\n",
    "\n",
    "# plot seaborn original frame and pivoted mean and trials next to eachother\n",
    "fig = plt.figure()\n",
    "plt.subplot(1,3,1)\n",
    "sns.lineplot(x = 'time', y = 'value', data = subselected, ci = 'sd')\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(subselected, 'k')\n",
    "plt.plot(subselected_mean, 'r')\n",
    "plt.subplot(1,3,3)\n",
    "# sns.heatmap(subselected, cmap = 'cubehelix')\n",
    "plt.imshow(subselected.T, aspect = 'auto',  cmap = 'cubehelix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subselected = subselected_orig.pivot(index = 'time', columns='trial', values='value')\n",
    "subselected = (subselected - subselected.mean())/subselected.std(ddof=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot all trials of a single cell concatenated\n",
    "\n",
    "fig = plt.figure()\n",
    "melted.loc[(melted.loc[:,'cell'] == 1) & (melted.loc[:,'category'] == 'Contra'),'value'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "sns.set()\n",
    "with sns.axes_style('white'):\n",
    "#     plt.imshow(arr, aspect = 'auto',  cmap = 'cubehelix')\n",
    "    sns.heatmap(subselected_orig, cmap = 'cubehelix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot individual cells as line plots and group by condition\n",
    "\n",
    "g = sns.FacetGrid(melted, col='category', hue='category', row='cell', sharey='row', margin_titles=True)\n",
    "g.map(sns.lineplot, 'time', 'value', ci='sd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.clf()\n",
    "g = sns.relplot(x=\"time\", y=\"value\",\n",
    "                 col=\"category\", row = 'cell', hue=\"category\", style=\"category\",\n",
    "                 kind=\"line\", data=melted, estimator=None, facet_kws={'sharey': True, 'sharex': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show cells\n",
    "im = np.zeros((ops['Ly'], ops['Lx']))\n",
    "ncells = len(stat)\n",
    "\n",
    "for n in range(0,ncells):\n",
    "    ypix = stat[n]['ypix'][~stat[n]['overlap']]\n",
    "    xpix = stat[n]['xpix'][~stat[n]['overlap']]\n",
    "    im[ypix,xpix] = n+1\n",
    "fig = plt.figure(figsize=(7,4))\n",
    "plt.imshow(im)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops['tau'] = .7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show mean image\n",
    "fig = plt.figure(figsize=(8,3))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(ops[\"meanImg\"])\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(ops[\"meanImgE\"])\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(ops[\"Vcorr\"])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops['tau'] = 0.5\n",
    "bouton = 11;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efilt = np.exp(- np.linspace(0,50,200) / (ops['tau'] * ops['fs']))\n",
    "#efilt /= efilt.sum()\n",
    "sout = convolve(spks[bouton,:], efilt)\n",
    "sout = sout[:spks.shape[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,4))\n",
    "plt.plot(F[bouton]-Fneu[bouton] * .7)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sout)\n",
    "plt.tight_layout()\n",
    "plt.show\n",
    "#plt.plot(F[10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(spks[11])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "plt.imshow(spks[:100, :5000], vmax = 3, vmin = -0.5, aspect='auto', cmap = 'gray_r')\n",
    "plt.title('sample of the neural data matrix')\n",
    "plt.ylabel('boutons') \n",
    "plt.xlabel('time [samples]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToDo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- batch run different deconvolution settings using this code snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute deconvolution\n",
    "from suite2p import dcnv\n",
    "import numpy as np\n",
    "\n",
    "tau = 1.0 # timescale of indicator\n",
    "fs = 30.0 # sampling rate in Hz\n",
    "neucoeff = 0.7 # neuropil coefficient\n",
    "# for computing and subtracting baseline\n",
    "baseline = 'maximin' # take the running max of the running min after smoothing with gaussian\n",
    "sig_baseline = 10.0 # in bins, standard deviation of gaussian with which to smooth\n",
    "win_baseline = 60.0 # in seconds, window in which to compute max/min filters\n",
    "\n",
    "ops = {'tau': tau, 'fs': fs, 'neucoeff': neucoeff,\n",
    "       'baseline': baseline, 'sig_baseline': sig_baseline, 'win_baseline': win_baseline}\n",
    "\n",
    "# load traces and subtract neuropil\n",
    "F = np.load('F.npy')\n",
    "Fneu = np.load('Fneu.npy')\n",
    "Fc = F - ops['neucoeff'] * Fneu\n",
    "\n",
    "# baseline operation\n",
    "Fc = dcnv.preprocess(Fc, ops)\n",
    "\n",
    "# get spikes\n",
    "spks = dcnv.oasis(Fc, ops)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
